{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Data Analytics &amp; AI Documentation","text":"<p>Welcome to the Data Analytics &amp; AI Documentation page of Synapxe, your hub for all technical resources, guidelines, and best practices. As a pioneering health tech company, we are committed to leveraging the power of data analytics and artificial intelligence to revolutionize the healthcare industry, enhance patient outcomes, and drive innovation.</p>"},{"location":"#our-mission","title":"Our Mission","text":"<p>At [Your Company Name], our mission is to harness cutting-edge technology to provide innovative solutions that improve health and wellbeing. We believe in the transformative potential of data and AI to deliver personalized, efficient, and effective healthcare services.</p>"},{"location":"#what-youll-find-here","title":"What You'll Find Here","text":"<ul> <li>Comprehensive Guides: Step-by-step tutorials and detailed guides to help you navigate our data analytics and AI platforms.</li> <li>API Documentation: In-depth documentation for our APIs, enabling seamless integration and utilization of our tools.</li> <li>Best Practices: Recommendations and best practices for implementing data analytics and AI in healthcare settings.</li> <li>Case Studies: Real-world examples of how our technology is being used to make a difference in healthcare.</li> <li>Technical Support: Resources and contact information for technical assistance and support.</li> </ul>"},{"location":"#why-data-analytics-ai-in-healthcare","title":"Why Data Analytics &amp; AI in Healthcare?","text":"<p>The integration of data analytics and AI in healthcare offers immense opportunities to enhance patient care, streamline operations, and enable predictive insights. From personalized treatment plans to early disease detection, our technology empowers healthcare providers to make data-driven decisions that can save lives and improve health outcomes.</p>"},{"location":"#join-us-in-transforming-healthcare","title":"Join Us in Transforming Healthcare","text":"<p>We invite healthcare professionals, data scientists, developers, and innovators to explore our documentation and join us on our journey to transform healthcare through data and AI. Whether you're integrating our APIs, developing new applications, or seeking to understand how AI can be applied to healthcare, you'll find the resources you need right here.</p>"},{"location":"blog/","title":"Articles","text":""},{"location":"blog/2024/08/26/best-practices-in-retrieval-augmented-generation/","title":"Best Practices in Retrieval-Augmented Generation","text":"<p>Generative Large Language Models (LLMs) are prone to generating outdated information or fabricating facts. Retrieval-Augmented Generation (RAG) techniques combine the strengths of pre-training and retrieval-based models to mitigate these issues, enhancing model performance.</p> <p>By integrating relevant, up-to-date information, RAG improves the accuracy and reliability of responses. Additionally, RAG enables rapid deployment of applications without the need to update model parameters, provided that query-related documents are available.</p> <p>This article delves into optimal practices for RAG, aiming to balance performance and efficiency.</p> Retrieval-augmented generation workflow."},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/","title":"Sentence Transformers for Sentence Similarity","text":"<p>In this article, we will take a look at the history leading up to the creation of Sentence Transformers, the shortcomings of past architectures across various Natural Language Processing (NLP) tasks (mainly sentence similarity) and how Sentence Transformers tackle these problems.</p>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#introduction","title":"Introduction","text":"Overview history of Sentence Transformer."},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#recurrent-networks","title":"Recurrent Networks","text":"From left to right: Vector-to-sequence, Sequence-to-vector and Sequence-to-sequence. <p>Clearly, Recurrent Neural Networks (RNNs) are versatile but for language problems, they have their disadvantages:</p> <p>Disadvantages:</p> <ol> <li>Slow to train and slow at inference</li> <li>This is because the input words are processed one at a time, sequentially. Therefore, longer      sentences just take a longer time.</li> <li>Do not truly understand context</li> <li>RNNs only learn about a word based on the words that came before it. In reality, the context of      a word depends on the sentence as a whole.</li> <li>Bidirectional Long Short-Term Memory (LSTMs) try to address this but even here, the left to      right and right to left context are learned separately and are concatenated so some of the true      context are lost.</li> </ol>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#transformer-networks","title":"Transformer Networks","text":"The encoder-decoder structure of the Transformer architecture. Taken from \u201cAttention Is All You Need\u201c. A sentence passing through the Transformer generating an embedding vector for each word. <p>For English to French translation, we pass in the entire English sentence into the encoder simultaneously. Then, we get the corresponding word vectors simultaneously. These word vectors encode the meaning of the word and they are better than RNNs because they understand bidirectional context through attention units.</p> <p>Now we pass these vectors into the decoder along with the previously generated French words to generate the next French word in the sentence. We keep passing the French words that were generated into the decoder until we hit the end of sentence.</p> <p>Transformers work well for sequence to sequence problems but for the specific natural language problems like question answering and text summarization, even Transformers have drawbacks related to one fact \u2014 language is complicated.</p> <p>Disadvantages:</p> <ol> <li>Need a lot of data</li> <li>Architecture may not be complex enough</li> <li>Transformers may not be complex enough to understand patterns to solve these language problems.      After all, Transformers weren\u2019t designed to be language models so the word representations      generated can still be improved.</li> </ol>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#bert-networks","title":"BERT Networks","text":"<p>BERT was introduced to extend the capabilities of the Transformer. BERT was built with the ideology that different Natural Language Processing (NLP) problems all rely on the same fundamental understanding of language.</p> Overall pre-training and fine-tuning procedures for BERT. Apart from output layers, the same architectures are used in both pre-training and fine-tuning. The same pre-trained model parameters are used to initialize models for different down-stream tasks. During fine-tuning, all parameters are fine-tuned. [CLS] is a special symbol added in front of every input example, and [SEP] is a special separator token (e.g. separating questions/answers)."},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#phases","title":"Phases","text":"<p>BERT undergoes two phases of training:</p> <ol> <li>Pre-Training: Understand Language</li> <li>Fine Tuning: Understand Language specific tasks</li> </ol>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#advantages-over-transformers","title":"Advantages over Transformers","text":"<ol> <li>Needing a lot of data \u2192 Fine tuning does not require obscene amounts of data</li> <li>Architecture may not be complex enough \u2192 BERT is a stack of Transformer encoders and is    therefore known as B\u200bidirectional E\u200bncoder R\u200bepresentations from    T\u200bransformers.</li> <li>Bidirectional: It is bidirectional since it understands the context of words looking both      ways via attention.</li> <li>Encoder &amp; Transformers: Since BERT is essentially a stack of the encoder part of the      Transformer.</li> <li>Representations: Since BERT is pre-trained to be a language model, it better understands      word representations. This means the output word vectors from BERT better encapsulates the      meaning of the words in sentences.</li> </ol> Various NLP tasks. <p>The big takeaway here is that BERT can now solve a host of complex language specific problems except for one type.</p> <p> !!! example \"\ud83d\udcad Imagine\"</p> <pre><code>Imagine you\u2019re a Data Scientist at Quora which is a question answer site and you want to design a system that find related questions to the one that is currently being asked. How would we solve this with BERT?\n\n&lt;figure markdown=\"span\"&gt;\n  ![quora](../../assets/images/quora.png){ width=500 }\n  &lt;figcaption&gt;You're a Data Scientist trying to design a system that find related questions to the one that is currently being asked&lt;/figcaption&gt;\n&lt;/figure&gt;\n</code></pre> <p>Goal: Determine questions similar to the one being asked. </p> A simple schematic diagram illustrating the process of embedding the words across many sentences. <p>Steps:</p> <ol> <li>First take the question that is being asked and another question that had been asked in the past,    pass both of these questions into BERT</li> <li>BERT generates word vectors</li> <li>Pipe these word vectors into some feed forward layer such that the output would be a single    neuron corresponding to the similarity score</li> <li>Repeat the steps for every question on the platform to compute the pairwise similarity</li> <li>Select the highest similarity scores and the corresponding questions will be the most similar and    relevant to the question that is being asked</li> </ol> <p> !!! warning</p> <pre><code>However, there is a big issue here. If there are 100 million questions on the platform, we\u2019d have to run the forward pass of BERT 100 million times every single time a new question comes in. This is not viable!\n</code></pre> <p>So the next question so ask is: how do we make BERT work for the current goal?</p>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#sentence-transformers","title":"Sentence Transformers","text":""},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#pass-1-high-level-idea","title":"Pass 1: High Level Idea","text":"Embedding space: It contains vectors of the questions that represent meaning. <p>Steps:</p> <ol> <li>We would want to pass the new question into BERT to get a single vector that represents the    meaning of the question.</li> <li>Compare the vector of the new question to the vectors of all other questions using a similarity    metric (i.e. cosine similarity).</li> <li>Return the nearest neighbours as the most related questions to the new question.</li> </ol> <p>Therefore, for every new question asked, we only require a single forward pass of the BERT model not 100 million times as mentioned before. This is great because computing simple similarity metrics between vectors is much cheaper than passing in all questions on the platform through the complex model every time you need to make a decision.</p>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#pass-2-sentence-transformers","title":"Pass 2: Sentence Transformers","text":"<p>In the first pass, a new question is passed into BERT to get a single vector that represents the question. However, BERT only gives us word vectors. Therefore, in order to get a single vector, you\u2019ll need to somehow aggregate these word vectors by passing it through some unit.</p> <p>The most straightforward way of doing this is to take the average of these vectors. This is known as mean pooling. Another way is to take the maximum value across every dimension of the embedding. This is known as max pooling.</p> BERT outputs vectors for each word so in order to get a vector for the question/sentence, we need to aggregate these word vectors. This is the simplest form of a Sentence Transformer. <p>The diagram above shows the simplest form of a Sentence Transformer but the output vector generated is extremely poor quality. Its quality is so poor that you might be better off simply taking the average of GloVe embeddings (and not even using BERT).</p> Source: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks https://arxiv.org/pdf/1908.10084 <p>How to get sentence vectors with meaning?</p> <p>In order for BERT to create sentence vectors that actually have meaning, we need to further train it (fine-tune) on sentence level tasks (refer to next section for more information).</p> <p>Once we train (fine-tune) BERT on one or all of these tasks, the sentence vector generated becomes a good representation of the sentence \u2014 that is, it encodes the meaning of the sentence very well.</p> <p>This is important since it means that closer the vectors are in terms of distance, the more similar is the meaning.</p> <p>Info</p> <p>In our Quora questioning setting, we would pass every question through the sentence transformer once and store them somewhere for future use. Then when a new question comes in, we pass only that question through the sentence transformer to get the sentence vector representation and then determine the questions with the highest cosine similarity and surface them as related questions. We can find the nearest neighbours through some nearest neighbours techniques:</p> <ul> <li>ANNOY (Approximate Nearest Neighbours)</li> <li>KNN Elastic Search</li> </ul>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#pass-3-sentence-transformers-training","title":"Pass 3: Sentence Transformers Training","text":"<p>BERT is good at word representations but we want to make a Sentence Transformer that is good with sentence representations. To do this, we fine-tune BERT on any or all of the three sentence related tasks:</p> <ol> <li>Natural Language Inference (NLI)</li> <li>Sentence Text Similarity (STS)</li> <li>Triplet Dataset</li> </ol>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#natural-language-inference-nli","title":"Natural Language Inference (NLI)","text":"Natural Language Inference: Does sentence 1 entails or contradicts sentence 2? If neither, the \u201cneutral\u201d category will should be predicted. <p>NLI is a task that takes in two sentences and determines if sentence 1 entails or contradicts sentence 2 or simply neither. See some examples below:</p> <p>Examples</p> <p>Entailment</p> <ul> <li>Sentence 1: \u201cSay hello to me!\u201d</li> <li>Sentence 2: \u201cGreet me!\u201d</li> </ul> <p>Neutral</p> <ul> <li>Sentence 1: \u201cSay hello to me!\u201d</li> <li>Sentence 2: \u201cTwo people greeting and playing together.\u201d</li> </ul> <p>Contradiction</p> <ul> <li>Sentence 1: \u201cSay hello to me!\u201d</li> <li>Sentence 2: \u201cYou\u2019re ignoring me!\u201d</li> </ul> <p>This allows BERT to understand sentence meanings as a whole. For training NLI, a Siamese network is used. \u201cSiamese\u201d means twins so we have two of the exact same Sentence Transformer networks connected in this fashion.</p> A Siamese Network. <p>If we want to compare two sentences, we pass them through the different BERT networks to get word representations. These word vectors are then combined to create a sentence vector and then concatenate the two sentence vectors and their difference. The output is a softmax classification which can be one of these three classes \u2014 entailment, contradiction or neutral.</p> Concatenating the two sentence vectors and their difference. <p>Note</p> <p>Note that the mean pooling and concatenation look really arbitrary but they were chosen because they yielded the best results than any other strategy \u2014 like choosing max pooling or simply only considering the absolute difference between the vectors instead.</p> <p>During inference time, we only need the Sentence Transformer piece where we get a question and then we get the corresponding sentence vector. This vector is the sentence representation that encodes the meaning of the sentence (very well, hopefully).</p>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#sentence-text-similarity-sts","title":"Sentence Text Similarity (STS)","text":"<p>Another task we can use to fine-tune BERT to understand sentences is using STS. Given two sentences, output the score of how similar they are.</p> Sentence Text Similarity: How similar is sentence 1 to sentence 2? <p>Just like NLI, this is also trained with a Siamese network. During training, we pass the two sentences to compare through different Sentence Transformers to get these sentence vectors and then compute the cosine similarity between these sentence vectors to get the a value between \\(-1\\) and \\(1\\). These are then compared to an actual labelled similarity rating on a scale of \\(1\\) to \\(5\\) which is normalized to be comparable to the output score. We minimize the squared difference between the two so that the model can be trained.</p> Consine similarity between two sentences."},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#triplet-dataset","title":"Triplet Dataset","text":"<p>A third type of task that we can train Sentence Transformers is using a dataset that has triple of sentences. The main sentence is called the \u201canchor\u201d, the next sentence is a sentence that is \u201crelated\u201d and the last sentence being one that is \u201cunrelated\u201d to the \u201canchor\u201d.</p> Triplet Dataset: One sentence is the anchor, another is a related sentence to the anchor and the other is unrelated. <p>We can quickly make this type of dataset by picking a Wikipedia page, then choosing a sentence to be the \u201canchor\u201d and the next sentence in the same paragraph can be chosen as the \u201crelated\u201d sentence and then choose a sentence from another paragraph as the \u201cunrelated\u201d sentence. See screenshot below for an example.</p> Yellow sentence being the anchor. Blue sentence being the related sentence and pink sentence being the unrelated sentence. <p>The network is a triplet (not siamese, or twins) of the exact same Sentence Transformer architectures. During training, we pass each sentence through a Sentence Transformer to get three sentence vectors; \\(S_{a}\\), \\(S_{+}\\) and \\(S_{-}\\).</p> <p>We want to make sure the distance between the anchor and the related sentence is small and the distance between the anchor and unrelated sentence is large. This is so that the meanings are learned.</p> Loss to minimize in the Triplet dataset."},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#conclusion","title":"Conclusion","text":"<p>Regardless which of the tasks is chosen for training the Sentence Transformers, during inference time, we should be able to pass in some sentences and generate sentence representation vectors that encode the meaning of the sentences very well.</p>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#pass-4-sentence-transformers-inference","title":"Pass 4: Sentence Transformers Inference","text":"<p>Going back to our Data Science job at Quora, how do we recommend similar questions? Before additional questions are asked, we want to pass in every single question/sentence through the fine-tuned Sentence Transformer to get the corresponding sentence vectors. These vectors are good sentence representations (if fine tuning did not go wrong). These vectors all live in a space also known as the embedding space as previously seen above.</p> <p>Next, when a new question comes in, we pass it through our Sentence Transformer to get the sentence representation or sentence embedding. Next, we determine the cosine similarity between the new question and every other candidate question. Finally, we will return the closest questions list as the related questions.</p> <p>For small datasets, we can determine the cosine similarity for a new question with every other question but it becomes increasingly harder to do when there are hundreds and millions of questions (very common especially on a platform like Quora).</p> Quora Statistics 2024. <p>To solve this issue, there are a couple of algorithms we can use. Spotify uses an Approximate Nearest Neighbours algorithm called ANNOY to recommend music to you. In this case, songs are embedded into vectors.</p> <p>Another way to quickly compute the nearest neighbours is through AWS which has an extremely efficient implementation of the k-Nearest Neighbours algorithm.</p>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#summary","title":"Summary","text":""},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#recurrent-neural-networks","title":"Recurrent Neural Networks","text":"<p>Advantages:</p> <ul> <li>Able to deal with Sequence-to-Sequence problems</li> </ul> <p>Disadvantages:</p> <ul> <li>Slow to train and during inference</li> <li>Do not truly understand context</li> </ul>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#transformers","title":"Transformers","text":"<p>Advantages:</p> <ul> <li>Replace Recurrent units with Attention units, addressing past concerns</li> <li>Solves Sequence-to-Sequence problems</li> </ul> <p>Disadvantages:</p> <ul> <li>Not necessarily complex enough to understand language</li> </ul>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#bert","title":"BERT","text":"<p>Advantages:</p> <ul> <li>Stack of Transformer encoders</li> <li>Complex enough to solve a host of NLP problems</li> </ul> <p>Disadvantages:</p> <ul> <li>Not good with sentence similarity tasks</li> </ul>"},{"location":"blog/2024/06/10/sentence-transformers-for-sentence-similarity/#sentence-bert","title":"Sentence BERT","text":"<p>Advantages:</p> <ul> <li>Fine tunes BERT on Sentence Similarity Tasks, addressing past concerns</li> </ul>"},{"location":"home/contribution_guides/classes_types_and_all/","title":"Classes, Types, and All","text":"<p>This page is a overview on how objects should be documented.</p> <p>A special syntax should be adhered to when labeling objects, attributes, etc. within documentation to improve readability. These special labels are called <code>doculabels</code>.</p> <pre><code>@\u200blabel(&lt;label&gt;)\n</code></pre> <p>Zero width space character</p> <p>To prevent any of the strings in this document from being redered as a <code>doculabel</code>, a zero space character was placed into the string. Do not copy the code in any of the blocks.</p> <p>The following labels can be used, simply type any of the texts below into the rounded brackets (and remove the angled brackets).</p> <ul> <li>@label(class)</li> <li>@label(pipe)</li> <li>@label(service)</li> <li>@label(interface)</li> <li>@label(type)</li> <li>@label(attr)</li> <li>@label(meth)</li> <li>@label(func)</li> <li>@label(private)</li> <li>@label(read only)</li> <li>@label(deprecated)</li> </ul> <p>While they can be rendered anywhere on the page, they should only be used in header elements (H2 and below).</p>"},{"location":"home/contribution_guides/classes_types_and_all/#page-layout","title":"Page Layout","text":"<p>Objects/types/interfaces/etc. should always have the second highest hierarchy, and should never be the highest. Page titles (<code>#</code> H1 tags) should be reserved purely for the name of the page.</p> <p>All objects and attributes (including private, read only, deprecated) should be documented.</p> <p>Below is a very rough example of how a page should be written.</p> Markdown <pre><code>## @\u200blabel(class) MyExampleClass\n\nShort description of my class.\n\n### Attributes\n\n#### @\u200blabel(attr) codeAttributeName\n`attrTypr` and explain what this attribute is for\n\n### Methods\n\n#### @\u200blabel(meth) My Humanised Method Name\n\n    ```\n    myMethodName(arg0:type):type\n    ```\n\nDescription\n: Some verbose reason what this method is for.\n\nParameters\n: `arg0` (`type`): Description of `arg0` and its relation to the method.\n\nReturns\n: `type` and its significance.\n</code></pre> <p>Generally speaking, the following patterns can be followed.</p> <ul> <li>Descriptive sections (e.g. attributes, methods, specific method groups) should be <code>H3</code>.</li> <li>Actual code attributes, methods, and all should be <code>H4</code>.</li> </ul> <p>Note</p> <p>See the example below for a visual example of how a page should look like.</p>"},{"location":"home/contribution_guides/classes_types_and_all/#attributes","title":"Attributes\u200b","text":"<p>All attributes must be labeled, with their respective types. To mark additional <code>doculabels</code>, they must be done in this order.</p> <ol> <li>@label(deprecated)</li> <li>@label(private)</li> <li>@label(read only)</li> <li>@label(attr)</li> </ol> Markdown <pre><code>#### @\u200blabel(attr) myAttribute\n`type` example to show attribute\n\n#### @\u200blabel(private) @\u200blabel(attr) youShouldntUseThisOutside\n`type` an example private attribute\n</code></pre>"},{"location":"home/contribution_guides/classes_types_and_all/#methods-and-functions","title":"Methods and Functions","text":"<p>Methods can be grouped together under the same <code>H3</code> header if they have similar relations.</p> Markdown <pre><code>### Methods related to Apples\n\n#### @\u200blabel(meth) Create apple\n...\n\n#### @\u200blabel(meth) Delete apple\n...\n\n### Methods related to Oranges\n\n#### @\u200blabel(meth) Create orange\n...\n\n#### @\u200blabel(meth) Delete orange\n...\n</code></pre> <p>For each method or function, the following items must be documented for clarity.</p> <ol> <li>Call signature</li> <li>Description</li> <li>Parameters</li> <li>Return type</li> </ol>"},{"location":"home/contribution_guides/classes_types_and_all/#call-signature","title":"Call Signature","text":"<p>This should be documented in a code block in the language the piece of code was written in. If it was written in TypeScript, it should look like this.</p> <pre><code>async function createApple(apple:Apple):Promise&lt;string&gt;\n</code></pre>"},{"location":"home/contribution_guides/classes_types_and_all/#description","title":"Description","text":"<p>A short sentence should be added to give a very summarised brief on what the function or method should do.</p> Markdown <pre><code>Description\n: Creates an apple in the fruit basket.\n</code></pre>"},{"location":"home/contribution_guides/classes_types_and_all/#parameters","title":"Parameters","text":"<p>For each of the parameters, the name, type, and description of it should be given.</p> <p>The syntax should look like this.</p> <pre><code>Parameter\n: `nameOfParam1` (`type`): Description\n: `nameOfParam2` (`type`): Description\n</code></pre> Markdown <pre><code>Parameters\n: `apple` (`Apple`): Creates the `Apple` fruit that should be added to the basket.\n</code></pre>"},{"location":"home/contribution_guides/classes_types_and_all/#returns","title":"Returns","text":"<p>This is particularly important as it outlines what the return type is, and its significance.</p> Markdown <pre><code>Returns\n: `string` Id of the apple created\n</code></pre>"},{"location":"home/contribution_guides/classes_types_and_all/#labelclass-examplefruitbasket","title":"@label(class) ExampleFruitBasket","text":"<p>This is an example of how a rendered class would look like</p>"},{"location":"home/contribution_guides/classes_types_and_all/#attributes_1","title":"Attributes","text":""},{"location":"home/contribution_guides/classes_types_and_all/#labelattr-fruits","title":"@label(attr) fruits","text":"<p><code>Fruit[]</code> an array containing all the fruits in the basket.</p>"},{"location":"home/contribution_guides/classes_types_and_all/#methods-related-to-apples","title":"Methods related to apples","text":""},{"location":"home/contribution_guides/classes_types_and_all/#labelmeth-add-apple","title":"@label(meth) Add apple","text":"<pre><code>addApple(apple:Apple):void\n</code></pre> Description Adds an apple to the fruit basket. Parameters <code>apple</code> (<code>Apple</code>): Apple to be added Returns <code>void</code>"},{"location":"home/contribution_guides/classes_types_and_all/#methods-related-to-oranges","title":"Methods related to oranges","text":""},{"location":"home/contribution_guides/classes_types_and_all/#labelmeth-add-orange","title":"@label(meth) Add Orange","text":"<pre><code>addOrange(orange:Orange):void\n</code></pre> Description Adds an orange to the fruit basket. Parameters <code>orange</code> (<code>Orange</code>): Orange to be added Returns <code>void</code>"},{"location":"home/contribution_guides/classes_types_and_all/#labelmeth-eat-orange-by-id","title":"@label(meth) Eat Orange by Id","text":"<pre><code>async eatOrange(id:string, round:boolean):Promise&lt;number&gt;\n</code></pre> Description Eat and orange and count the number of bites. Parameters <code>id</code> (<code>string</code>): UUID of the <code>Orange</code> to be eaten. <code>round</code> (<code>boolean</code>): Specifies if the <code>Orange</code> must be round. Returns <code>number</code> of bites needed to finish eating the orange"},{"location":"home/contribution_guides/endpoints/","title":"Endpoints","text":"<p>Endpoints are documented with OpenAPI standards.</p> <p>Plugin reference</p> <p>Documentation for the plugin used to render the OpenAPI documentation can be found here.</p>"},{"location":"home/contribution_guides/formatting/","title":"Formatting","text":""},{"location":"home/contribution_guides/formatting/#frontmatter","title":"Frontmatter","text":"<p>Frontmatter is the \"metadata\" section of each markdown page. The following attributes must be present on all pages.</p> <ul> <li><code>updated</code> -- date of which the page was last updated, in the DD-mmm-YYYY format.</li> <li><code>authors</code> -- a string, or a list of strings matching the authors name(s) that contributed to the page.</li> </ul> <p>These are required as the information is used to render the <code>updated</code> and <code>author</code> information at the bottom of the pages (hint: see the bottom of this page).</p> <p>The following code block is an example of how to write the frontmatter at the very top of each markdown file.</p> <pre><code>---\nupdated: 23 July 2024\nauthors: Johnny Tan\n---\n</code></pre> <p>Author attribution</p> <p>The authors.py hook was used in the rendering process of authors.</p>"},{"location":"home/contribution_guides/formatting/#hierarchy-of-headers","title":"Hierarchy of Headers","text":"<p>Headers should reflect the logical hierarchy of the content. They must be used in sequential order, starting from H1 for the main title, then H2 for major subsections, followed by H3 for subtopics within those subsections, and so on. This structure is crucial as it helps in organizing the content clearly and logically, making it easier for readers to follow and understand the flow of information.</p>"},{"location":"home/contribution_guides/introduction/","title":"Introduction","text":"<p>Documentation is crucial as it offers a comprehensive guide for developers to comprehend and maintain software. This is equally vital for newly onboarded developers as well as for long-standing team members. Furthermore, as the codebase grows in size and complexity, the documentation serves as a quick reference for team members.</p>"},{"location":"home/contribution_guides/introduction/#guides","title":"Guides","text":"<ul> <li>Formatting -- Refer to this section for our standard markdown formatting guidelines applicable across all documentation.</li> <li>Endpoints -- Details on how to document endpoints.</li> <li>Classes, types, and all -- This section offers detailed guidelines on preparing technical documentation for various objects and types within our codebase. It serves as a critical resource for accurately and precisely describing the structure and functionalities of our software.</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/","title":"Azure Search Index","text":""},{"location":"projects/genai/conversational-assistant/services/search_index/#introduction","title":"Introduction","text":"<p>This documentation describes the process of ingesting HealthHub articles into the Azure Search Index using Azure Blob Storage, the <code>azure_rag</code> pipeline for chunking and embedding, and eventual data retrieval for your application. The articles are ingested in JSON format and go through several stages, including document upload, chunking, embedding, and retrieval.</p>"},{"location":"projects/genai/conversational-assistant/services/search_index/#overview","title":"Overview","text":"<p>This project involves the ingestion of articles from HealthHub into an Azure Search Index to enable efficient and scalable search capabilities. The system leverages various Azure services such as Blob Storage, Azure Cognitive Search, and Azure OpenAI for embedding.</p> <p>The high-level architecture includes:</p> <ul> <li>Uploading HealthHub articles (in JSON format) to Azure Blob Storage.</li> <li>Utilizing an Azure Cognitive Search pipeline to chunk the articles and generate embeddings using Azure OpenAI.</li> <li>Storing the chunks and embeddings in Azure Search Index for semantic and full-text search.</li> </ul> <p>For more details, refer to:</p> <ul> <li>JSON Data Preparation</li> <li>Data Ingestion</li> <li>Search Index</li> <li>Skillset</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/#architecture","title":"Architecture","text":"<p>The diagram below shows a high level overview on how the services and components interact with each other.</p> Step Description HealthHub JSON Files JSON files containing article data, with fields like <code>id</code>, <code>title</code>, <code>content_category</code>, and <code>content</code>. Azure Blob Storage Upload JSON files to Azure Blob Storage for persistent storage. Azure Cognitive Search Pipeline Azure Cognitive Search pipeline responsible for indexing the data into the Azure Search Index. Azure Search Index The chunks and their embeddings are stored in the Azure Search Index, allowing for various types of search queries. Data Retrieval The final step where data can be queried and retrieved through several types of search. <pre><code>flowchart TD\n    A[HealthHub JSON Files] --&gt; B[Azure Blob Storage]\n    B --&gt; C[Azure Cognitive Search Pipeline]\n    C --&gt; D[Azure Search Index]\n    D --&gt; E[Data Retrieval]</code></pre>"},{"location":"projects/genai/conversational-assistant/services/search_index/#version-history","title":"Version History","text":"<p>The following versions detail the evolution of the ingestion process, addressing various issues:</p> <ul> <li>V1: Ingestion in txt files.</li> <li>V2: Ingestion in json files but with 2048 max page length and 20 page overlap (Resolve metadata issue)</li> <li>V3: Ingestion of article content and table content (Resolve lack of table content)</li> <li>V4: Ingestion in json files but with 5000 max page length and 20 page overlap (Resolve content cut-off issue)</li> <li>V5: Ingestion in json files but with 5000 max page length and 200 page overlap (Resolve lack of understanding between chunks)</li> <li>V6: Additional article content extracted from programs and sub-program pages. (Resolve the lack of programs and sub-program pages content)</li> <li>V7: Added 2 javascript articles to supplement the article content. (Resolve the missing content from the javascript from the programs and sub-program pages articles)</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/data_ingestion/","title":"Data Ingestion","text":"<p>The ingestion process involves bringing HealthHub articles (in JSON format) into the system, processing them through Azure services, and storing them in an Azure Search Index for querying.</p> <p>The ingestion process begins by uploading the JSON files containing article data to Azure Blob Storage. Blob Storage acts as a scalable storage solution that can hold a large number of documents and media files. Each document represents a single article with fields like id, title, content_category, content, etc. The typical structure of these JSON files includes fields like:</p> <ul> <li>id: A unique identifier for the article.</li> <li>title: The title of the article.</li> <li>cover_image_url: A URL pointing to an image associated with the article.</li> <li>full_url: A URL to the article\u2019s full content on HealthHub.</li> <li>content_category: The category under which the article falls (e.g., 'programs').</li> <li>category_description: The description of the article at the top of the page.</li> <li>pr_name: The name of the article provider.</li> <li>date_modified: The last edited date of this article (if any).</li> <li>content: The body of the article itself.</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/data_ingestion/#json-example","title":"JSON Example","text":"<pre><code>[\n  {\n    \"id\": \"1434570_content\",\n    \"title\": \"National Steps Challenge\u2122 Community Challenge\",\n    \"cover_image_url\": \"https://ch-api.healthhub.sg/api/public/content/09a981f1a280460dbca961ea71f04cba?v=fc6b51b0\",\n    \"full_url\": \"https://www.healthhub.sg/programmes/community-challenge\",\n    \"content_category\": \"programs\",\n    \"category_description\": \"Feel good with every move as you bond with your neighbours! The National Steps Challenge\u2122 Season 5 is back with Community Challenge!\",\n    \"pr_name\": \"Health Promotion Board\",\n    \"date_modified\": \"2024-09-10\",\n    \"content\": \"your content here\"\n  }\n]\n</code></pre>"},{"location":"projects/genai/conversational-assistant/services/search_index/data_ingestion/#steps-for-data-ingestion","title":"Steps for Data Ingestion","text":"<ol> <li> <p>Uploading to Blob Storage: The JSON files are uploaded to Azure Blob Storage to persist and stage the data before indexing.</p> </li> <li> <p>Inserting Documents into the Azure Search Index: Once uploaded, the documents are inserted into the Azure Search Index using the <code>SearchClient</code>. The document fields are mapped to the corresponding index fields, enabling full-text search, filtering, sorting, and faceting functionalities. The primary client types used in the process are:</p> </li> <li> <p>SearchClient: Handles individual document operations such as adding or deleting documents from the search index.</p> </li> <li>SearchIndexClient: Used for managing the index itself, including creating, updating, or deleting indexes.</li> <li> <p>SearchIndexerClient: Manages automated indexing pipelines, integrating Blob Storage or databases as data sources.</p> </li> <li> <p>Chunking and Embedding: This pipeline handles the ingestion of articles into the search index. It consists of two major skills:</p> </li> <li> <p>SplitSkill (Chunking): Splits the article content into manageable chunks.</p> </li> <li> <p>Azure OpenAI EmbeddingSkill: Generates embeddings for each chunk, using the model <code>text-embedding-3-small</code>.</p> </li> <li> <p>Search Index Creation: After chunking and embedding, the data is stored in the Azure Search Index for retrieval. The search index is configured to allow full-text and vector search.</p> </li> </ol>"},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/","title":"Search Index","text":"<p>Azure Cognitive Search is a powerful search service for building fast, scalable, and full-text search solutions. In this project, we use Azure Cognitive Search to index and retrieve articles from HealthHub, enabling semantic search based on vector embeddings.</p>"},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/#azure-search-components","title":"Azure Search Components","text":""},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/#searchclient","title":"SearchClient","text":"<p>Purpose: The <code>SearchClient</code> is responsible for handling individual document operations within the search index.</p> <p>Functions:</p> <ul> <li>Add Documents: Upload documents one by one or in batches to the search index.</li> <li>Delete Documents: Remove documents from the search index by their unique identifier.</li> <li>Search Documents: Execute full-text searches and vector-based searches across the indexed data.</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/#searchindexclient","title":"SearchIndexClient","text":"<p>Purpose: The <code>SearchIndexClient</code> is used to manage the search index itself, handling tasks related to the creation, updating, or deletion of indexes.</p> <p>Functions:</p> <ul> <li>Create Index: Define the schema (fields, types, and attributes) of a new index.</li> <li>Update Index: Modify the schema or settings of an existing index.</li> <li>Delete Index: Remove the entire index from the service.</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/#searchindexerclient","title":"SearchIndexerClient","text":"<p>Purpose: The <code>SearchIndexerClient</code> is responsible for managing automated indexing pipelines that can ingest data from external sources like Blob Storage or databases.</p> <p>Functions:</p> <ul> <li>Data Source Integration: Configure data sources (e.g., Azure Blob Storage) for automatic indexing.</li> <li>Run Indexer: Schedule or trigger the indexing process that pulls data from the source and updates the search index.</li> <li>Monitor Indexing Jobs: Check the status of indexing jobs and review logs for potential errors.</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/#search-fields","title":"Search Fields","text":"<p>Azure Cognitive Search fields are defined with attributes that determine how the data is used in searches, filtering, sorting, and faceting. Below is an overview of the key fields used in our search index.</p>"},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/#key-fields-in-the-search-index","title":"Key Fields in the Search Index","text":"Field Searchable Filterable Sortable Facetable Retrievable Analyzer Name Vector Search Dimensions id true true true true true - - title true false false false true en.microsoft - cover_image_url true false false false true - - full_url false false false false true - - content_category true true false false true en.microsoft - category_description true false false false true en.microsoft - pr_name true false false false false - - date_modified true false false false false - - chunks true false false false true en.microsoft - embedding true false false false true - 1536"},{"location":"projects/genai/conversational-assistant/services/search_index/search_index/#search-field-attributes","title":"Search Field Attributes","text":"<p>Each field in the index can be configured with specific attributes that determine how it is used in searches, filters, sorting, or faceting:</p> <ul> <li>searchable: Allows full-text search on the field.</li> <li>filterable: Enables filtering on exact matches or ranges (e.g., by date or category).</li> <li>sortable: Allows sorting of results based on the values in this field.</li> <li>facetable: Supports faceted navigation by creating categories or filters from this field.</li> <li>retrievable: Specifies whether the field\u2019s content can be retrieved and returned in search results.</li> </ul>"},{"location":"projects/genai/conversational-assistant/services/search_index/skillset/","title":"Skillset","text":"<p>The skillset in Azure Cognitive Search handles the transformation of article content, including chunking and embedding. Below are the key skills used in the pipeline:</p>"},{"location":"projects/genai/conversational-assistant/services/search_index/skillset/#1-splitskill-chunking","title":"1. SplitSkill (Chunking)","text":"<ul> <li> <p>Purpose: Splits the content of each article into smaller chunks, making it easier to process for embedding and search.</p> </li> <li> <p>Mode: Set to <code>pages</code> for dividing the content into pages.</p> </li> <li> <p>Configuration:</p> </li> </ul> <pre><code>split_skill = SplitSkill(\n  text_split_mode=\"pages\",  # Can also split by sentences\n  context=\"/document/content\",\n  maximum_page_length=5000,  # Maximum characters per chunk\n  page_overlap_length=200,   # Overlap between chunks\n  inputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/content\")],\n  outputs=[OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")])\n</code></pre>"},{"location":"projects/genai/conversational-assistant/services/search_index/skillset/#2-azure-openai-embeddingskill","title":"2. Azure OpenAI EmbeddingSkill","text":"<ul> <li> <p>Purpose: Uses Azure OpenAI to generate vector embeddings for each chunk of content.</p> </li> <li> <p>Model: <code>text-embedding-3-small</code></p> </li> <li> <p>Configuration:</p> </li> </ul> <pre><code>embedding_skill = AzureOpenAIEmbeddingSkill(\ncontext=\"/document/content/pages/*\",\ninputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/content/pages/*\")],\noutputs=[OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")])\n</code></pre>"},{"location":"projects/genai/conversational-assistant/services/search_index/skillset/#3-final-document-structure-in-the-index","title":"3. Final Document Structure in the Index","text":"<ul> <li>After chunking and embedding, each article document in the index will look like this:</li> </ul> <pre><code>{\n  \"id\": \"1434570_content\",\n  \"title\": \"National Steps Challenge\u2122 Community Challenge\",\n  \"content\": {\n      \"pages_0\": {\n          \"vector\": [0.123, 0.456, 0.789, ...]\n      },\n      ...\n  }\n  }\n</code></pre>"},{"location":"projects/genai/conversational-assistant/services/search_index/skillset/#index-projections","title":"Index Projections","text":"<p>The chunks and embeddings are projected into the Azure Search Index with the following structure:</p> Field Description parent_id Identifier for the parent document or related article, if applicable. id Primary key of the document, uniquely identifies each article. title Title of the article. cover_image_url A URL pointing to an image associated with the article. full_url A URL to the article\u2019s full content on HealthHub. content_category The category under which the article falls (e.g., 'programs'). category_description A brief description of the article category, usually found at the top. pr_name The name of the article provider or publisher (e.g., Health Promotion Board). date_modified The date when the article was last modified (if any). chunks The individual chunks of the content split by the SplitSkill. embedding Vector representation of each chunk, used for vector-based semantic search."},{"location":"projects/genai/conversational-assistant/webapp/backend/architecture/","title":"Architecture","text":"Architecture flow"},{"location":"projects/genai/conversational-assistant/webapp/backend/API/endpoints/","title":"Endpoints","text":"<p>For testing</p> <p>Run the webapp locally first before testing the endpoint</p> Endpoint diagram with buttons <p></p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/","title":"Overview","text":"<p><code>Pydantic</code> models are used for validating HTTP requests received and responses sent by the backend.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#models","title":"Models","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#chat","title":"Chat","text":"<ul> <li>TextChatRequest</li> <li>TextChatResponse</li> <li>TextChatResponseWithChunk</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#voice","title":"Voice","text":"<ul> <li>VoiceChatRequest</li> <li>VoiceChatResponse</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#transcription","title":"Transcription","text":"<ul> <li>TranscriptionResponse</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#feedback","title":"Feedback","text":"<ul> <li>FeedbackRequest</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#speech","title":"Speech","text":"<ul> <li>SpeechRequest</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#source","title":"Source","text":"<ul> <li>Source</li> <li>SourceWithChunk</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#message","title":"Message","text":"<ul> <li>ChatMessage</li> <li>ChatMessageWithSource</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#history","title":"History","text":"<ul> <li>ChatHistory</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/overview/#profile","title":"Profile","text":"<ul> <li>Profile</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_request/","title":"@label(type) TextChatRequest","text":"<p>TextChatRequest pydantic model contains required parameters to be sent to the LLM for generating a response.</p> <p>Used for both <code>/chat/stream</code> and <code>/chat</code> endpoint.</p> Python <pre><code>class TextChatRequest(BaseModel):\n    chat_history: Optional[List[ChatMessage]] = []\n    profile: Profile\n    query: ChatMessage\n    language: str\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_request/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_request/#labelattr-chat_history","title":"@label(attr) chat_history","text":"<p><code>List[ChatMessage]</code> A list of chat messages that have been exchanged between the user and the chatbot.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_request/#labelattr-profile","title":"@label(attr) profile","text":"<p><code>Profile</code> The user profile.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_request/#labelattr-query","title":"@label(attr) query","text":"<p><code>ChatMessage</code> The user query.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_request/#labelattr-language","title":"@label(attr) language","text":"<p><code>string</code> The response language chosen by user</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response/","title":"@label(type) TextChatResponse","text":"<p>TextChatResponse pydantic model contains parameters that will be returned to the frontend. It does not contain any text chunk as the frontend will not be displaying it.</p> <p>Used for <code>/chat/stream</code> endpoint.</p> Python <pre><code>class TextChatResponse(BaseModel):\n    response_message: str\n    sources: List[Source]\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response/#labelattr-response_message","title":"@label(attr) response_message","text":"<p><code>string</code> The response message from the LLM.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response/#labelattr-sources","title":"@label(attr) sources","text":"<p><code>List[Source]</code> A list of sources without text chunk that the LLM has used to generate the response.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response_with_chunk/","title":"@label(type) TextChatResponseWithChunk","text":"<p>TextChatResponseWithChunk pydantic model contains parameters that will be returned to the frontend.</p> <p>Used for <code>/chat</code> endpoint.</p> Python <pre><code>class TextChatResponseWithChunk(BaseModel):\n    response_message: str\n    sources: List[SourceWithChunk]\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response_with_chunk/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response_with_chunk/#labelattr-response_message","title":"@label(attr) response_message","text":"<p><code>string</code> The response message from the LLM.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/chat/text_chat_response_with_chunk/#labelattr-sources","title":"@label(attr) sources","text":"<p><code>List[SourceWithChunk]</code> A list of sources with text chunk that the LLM has used to generate the response.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/","title":"@label(type) FeedbackRequest","text":"<p>FeedbackRequest pydantic model contains required parameters to be sent to CosmosDB for storing feedback.</p> <p>Used for <code>/feedback</code> endpoint.</p> Python <pre><code>class FeedbackRequest(BaseModel):\n    date_time: str\n    feedback_type: Literal[\"positive\", \"negative\"]\n    feedback_category: List[str]\n    feedback_remarks: Optional[str] = \"\"\n    user_profile: Profile\n    chat_history: List[ChatMessageWithSource]\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/#labelattr-date_time","title":"@label(attr) date_time","text":"<p><code>string</code> The date and time when the feedback was submitted.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/#labelattr-feedback_type","title":"@label(attr) feedback_type","text":"<p><code>Literal[\"positive\", \"negative\"]</code> The type of feedback submitted.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/#labelattr-feedback_category","title":"@label(attr) feedback_category","text":"<p><code>List[str]</code> A list of feedback categories. E.g [\"Outdated sources\", \"Not factually correct\"]</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/#labelattr-feedback_remarks","title":"@label(attr) feedback_remarks","text":"<p><code>Optional[str]</code> Optional remarks for the feedback.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/#labelattr-user_profile","title":"@label(attr) user_profile","text":"<p><code>Profile</code> The user profile.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/feedback/feedback_request/#labelattr-chat_history","title":"@label(attr) chat_history","text":"<p><code>List[ChatMessageWithSource]</code> A list of chat messages with sources that have been exchanged between the user and the chatbot.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/history/chat_history/","title":"@label(type) ChatHistory","text":"<p>ChatHistory pydantic model contains parameters of a chat history message that will be uploaded to CosmosDB</p> Python <pre><code>class ChatHistory(BaseModel):\n    id: str\n    session_id: str\n    created_at: str\n    last_modified: str\n    chat_messages: List[ChatMessageWithSource]\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/history/chat_history/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/history/chat_history/#labelattr-id","title":"@label(attr) id","text":"<p><code>string</code> The unique identifier of the chat history. (Uses the same id as the session id)</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/history/chat_history/#labelattr-session_id","title":"@label(attr) session_id","text":"<p><code>string</code> The session id of the chat history.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/history/chat_history/#labelattr-created_at","title":"@label(attr) created_at","text":"<p><code>string</code> The timestamp when the chat history was first created.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/history/chat_history/#labelattr-last_modified","title":"@label(attr) last_modified","text":"<p><code>string</code> The timestamp when the chat history was last modified.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/history/chat_history/#labelattr-chat_messages","title":"@label(attr) chat_messages","text":"<p><code>List[ChatMessageWithSource]</code> A list of chat messages that have been exchanged between the user and the chatbot. Each chat message contains the role, content, and sources of the message.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message/","title":"@label(type) ChatMessage","text":"<p>ChatMessage pydantic model contains parameters of a message that conforms to OpenAPI <code>ChatCompletionMessageParam</code> schema</p> Python <pre><code>class ChatMessage(BaseModel):\n    role: str\n    content: str\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message/#labelattr-role","title":"@label(attr) role","text":"<p><code>string</code> The role of the chat message. It can be either 'user' or 'assistant'.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message/#labelattr-content","title":"@label(attr) content","text":"<p><code>string</code> The content of the chat message.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message_with_source/","title":"@label(type) ChatMessageWithSource","text":"<p>ChatMessageWithSource pydantic model contains parameters of a message that conforms to OpenAPI <code>ChatCompletionMessageParam</code> schema. It contain sources.</p> Python <pre><code>class ChatMessageWithSource(BaseModel):\n    role: str\n    content: str\n    sources: List[SourceWithChunk] | List[Source]\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message_with_source/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message_with_source/#labelattr-role","title":"@label(attr) role","text":"<p><code>string</code> The role of the chat message. It can be either 'user' or 'assistant'.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message_with_source/#labelattr-content","title":"@label(attr) content","text":"<p><code>string</code> The content of the chat message.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/message/chat_message_with_source/#labelattr-sources","title":"@label(attr) sources","text":"<p><code>List[SourceWithChunk]</code> or <code>List[Source]</code> A list of sources with or without text chunk that the LLM has used to generate the response.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/profile/profile/","title":"@label(type) Profile","text":"<p>Profile pydantic model contains parameters of a user profile.</p> Python <pre><code>class Profile(BaseModel):\n    profile_type: str\n    user_age: Optional[int] = -1\n    user_gender: Optional[str] = \"male\"\n    user_condition: Optional[str] = \"\"\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/profile/profile/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/profile/profile/#labelattr-profile_type","title":"@label(attr) profile_type","text":"<p><code>string</code> The type of the profile. It can be either 'general' or 'myself' or \"others\".</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/profile/profile/#labelattr-user_age","title":"@label(attr) user_age","text":"<p><code>int</code> The age of the user.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/profile/profile/#labelattr-user_gender","title":"@label(attr) user_gender","text":"<p><code>string</code> Gender of the user. It can either be 'male' or 'female'</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/profile/profile/#labelattr-user_condition","title":"@label(attr) user_condition","text":"<p><code>string</code> The condition(s) of the user. The conditions are concatenated with a comma. For example, \"diabetes, hypertension\".</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/","title":"@label(type) Source","text":"<p>Source pydantic model contains parameters of an article retrieved from Azure AI Search It does not contain the article text chunk.</p> Python <pre><code>class Source(BaseModel):\n    ids: List[str]\n    title: str\n    cover_image_url: str\n    full_url: str\n    content_category: str\n    category_description: str\n    pr_name: str\n    date_modified: str\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-ids","title":"@label(attr) ids","text":"<p><code>List[string]</code> List of ids of the article. (Note: This is not the parent id, it is the 'sub' id after indexing)</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-title","title":"@label(attr) title","text":"<p><code>string</code> Title of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-cover_image_url","title":"@label(attr) cover_image_url","text":"<p><code>string</code> URL of the cover image of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-full_url","title":"@label(attr) full_url","text":"<p><code>string</code> URL of the full article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-content_category","title":"@label(attr) content_category","text":"<p><code>string</code> Content category of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-category_description","title":"@label(attr) category_description","text":"<p><code>string</code> Category description of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-pr_name","title":"@label(attr) pr_name","text":"<p><code>string</code> Publisher name of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source/#labelattr-date_modified","title":"@label(attr) date_modified","text":"<p><code>string</code> Date the article was last modified.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/","title":"@label(type) SourceWithChunk","text":"<p>SourceWithChunk pydantic model contains parameters of an article retrieved from Azure AI Search. It contains the article text chunk.</p> Python <pre><code>class SourceWithChunk(BaseModel):\n    id: str\n    title: str\n    cover_image_url: str\n    full_url: str\n    content_category: str\n    category_description: str\n    pr_name: str\n    date_modified: str\n    chunk: str\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-ids","title":"@label(attr) ids","text":"<p><code>List[string]</code> List of ids of the article. (Note: This is not the parent id, it is the 'sub' id after indexing)</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-title","title":"@label(attr) title","text":"<p><code>string</code> Title of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-cover_image_url","title":"@label(attr) cover_image_url","text":"<p><code>string</code> URL of the cover image of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-full_url","title":"@label(attr) full_url","text":"<p><code>string</code> URL of the full article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-content_category","title":"@label(attr) content_category","text":"<p><code>string</code> Content category of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-category_description","title":"@label(attr) category_description","text":"<p><code>string</code> Category description of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-pr_name","title":"@label(attr) pr_name","text":"<p><code>string</code> Publisher name of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-date_modified","title":"@label(attr) date_modified","text":"<p><code>string</code> Date the article was last modified.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/source/source_with_chunk/#labelattr-chunk","title":"@label(attr) chunk","text":"<p><code>string</code> Text chunk of the article.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/speech/speech_request/","title":"@label(type) SpeechRequest","text":"<p>SpeechRequest pydantic model contains required parameter to be sent to Azure Speech Service for text to speech conversion.</p> <p>Used for <code>/speech</code> endpoint</p> Python <pre><code>class SpeechRequest(BaseModel):\n    text: str\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/speech/speech_request/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/speech/speech_request/#labelattr-text","title":"@label(attr) text","text":"<p><code>string</code> The text to be converted to speech.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/transcription/transcription_response/","title":"@label(type) TranscriptionResponse","text":"<p>TranscriptionResponse pydantic model contains parameters that will be returned to the frontend.</p> <p>Used for <code>/ws/transcribe</code> endpoint</p> Python <pre><code>class TranscriptionResponse(BaseModel):\n    text: str\n    is_final: bool\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/transcription/transcription_response/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/transcription/transcription_response/#labelattr-text","title":"@label(attr) text","text":"<p><code>string</code> The transcribed text.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/transcription/transcription_response/#labelattr-is_final","title":"@label(attr) is_final","text":"<p><code>bool</code> The flag to indicate if the transcription is final or not.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_request/","title":"@label(type) VoiceChatRequest","text":"<p>VoiceChatRequest pydantic model contains required parameters to be sent to the LLM for generating a response.</p> <p>Used for <code>/voice/stream</code> endpoint.</p> Python <pre><code>class VoiceChatRequest(BaseModel):\n    chat_history: Optional[List[ChatMessage]] = []\n    profile: Profile\n    query: ChatMessage\n    language: str\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_request/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_request/#labelattr-chat_history","title":"@label(attr) chat_history","text":"<p><code>List[ChatMessage]</code> A list of chat messages that have been exchanged between the user and the chatbot.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_request/#labelattr-profile","title":"@label(attr) profile","text":"<p><code>Profile</code> The user profile.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_request/#labelattr-query","title":"@label(attr) query","text":"<p><code>ChatMessage</code> The user query.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_request/#labelattr-language","title":"@label(attr) language","text":"<p><code>string</code> The response language chosen by user</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_response/","title":"@label(type) VoiceChatResponse","text":"<p>VoiceChatResponse pydantic model contains parameters that will be returned to the frontend. It does not contain any text chunk as the frontend will not be displaying it.</p> <p>Used for <code>/voice/stream</code> endpoint.</p> Python <pre><code>class VoiceChatResponse(BaseModel):\n    response_message: str\n    audio_base64: str\n    sources: List[Source]\n</code></pre>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_response/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_response/#labelattr-response_message","title":"@label(attr) response_message","text":"<p><code>string</code> The response message from the LLM.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_response/#labelattr-audio_base64","title":"@label(attr) audio_base64","text":"<p><code>string</code> The audio response from the LLM in base64 format.</p>"},{"location":"projects/genai/conversational-assistant/webapp/backend/schema/voice/voice_chat_response/#labelattr-sources","title":"@label(attr) sources","text":"<p><code>List[Source]</code> A list of sources without text chunk that the LLM has used to generate the response.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/","title":"Introduction","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/#high-level-dependency","title":"High Level Dependency","text":"<p>The frontend for HealthierME 2.0 is build using Angular v18.</p> Domain Technology Remarks Framework Angular v18 Modularity between components and business logic. Component PrimeNG Large range of components out of the box. Styling TailwindCSS Fast tooling for styling of components. Icons Lucide One of the largest icon library with native support for Angular."},{"location":"projects/genai/conversational-assistant/webapp/frontend/#philosophy","title":"Philosophy","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/#data-persistence","title":"Data Persistence","text":"<p>To minimise the technical complexity of maintaining states, all stateful logic is handled on the frontend, allowing the backend to be purely stateless. As such, <code>LocalStorage</code> and <code>IndexedDb</code> stores are used to persist user information. This strategy allows us to make do without an authentication (or user based) system, drastically reducing technical complexity -- particularly important given the short turn around time given to produce a proof-of-concept.</p> <p><code>Message</code>s are persisted in the browser using <code>IndexedDb</code> and are queried by the ID of the profile that is currently being interacted with. This is managed by ChatMessageService.</p> <p>To manage user preferences, <code>LocalStorage</code> was used, and is managed by PreferenceService. Preferences include the chat mode, and Voice Activity Detection (VAD) settings.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/#software-architecture","title":"Software Architecture","text":"<p>The diagram below shows a very, very, high level overview on how the services and components interact with each other.</p> <p>Warning</p> <p>This diagram does not cover every relation and interaction that has been implemented. It does however give a broad idea of the intention behind the implemented structure and how its abstraction of business logic can be expanded.</p> <p>The implemented logic is more nuanced than depicted, with more components and a few more services.</p> <p>Services can be grouped into two general types, a service to abstract out business logic, Abstraction Service Layer (ASL), and services that are responsible for actionable items, Service Layer (SL).</p> <pre><code>flowchart RL\n    subgraph ui [UI]\n        direction RL\n        voice[[Voice Component]]\n        text[[Text Input Component]]\n    end\n\n    subgraph asl [Abstraction Service Layer]\n        direction RL\n        convoBroker{{Conversation Broker}}\n    end\n\n    subgraph sl [Service Layer]\n        direction RL\n        endpoint([Endpoint Service])\n        vad([Voice Activity Detection Service])\n        chat([Chat Message Service])\n        audio([Audio Service])\n        audioPlayer([Audio Player Service])\n    end\n\n    ui --&gt; asl\n    asl --&gt; sl</code></pre> <p>The ultimate goal of this layered structure was to abstract away business logic from components.</p> <p>For example, to process a voice input:</p> <ol> <li>Voice recording must be started (with or without VAD)</li> <li>An API call must be made</li> <li>The transcribed user message must be persisted</li> <li>The streamed API response must be parsed</li> <li>LLM response must be persisted as a message</li> <li>Audio of the LLM response must be played</li> </ol> <p>By adopting the UI/ASL/SL layer structure, the logic is consolidated into ASL services that can be accessed from other components, encouraging reusability of the business logic and keeping UI components readable and simple to maintain.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/","title":"Audio Player Service","text":"<p>This service is responsible for playing all sounds on the frontend. This includes:</p> <ul> <li>LLM audio response (voice chat)</li> <li>Text to speech</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelservice-audioplayerservice","title":"@label(service) AudioPlayerService","text":"<p>To facilitate audio streaming from LLM voice responses, it implements an audio queue system. Audio blobs are played in the sequence they are added in. This implementation was due to how audio files of the LLM response was received on the frontend.</p> <p>Assumption</p> <p>The current implementation generally assumes that there will only be one source of audio, voice LLM and TTS included.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelprivate-labelattr-audioelement","title":"@label(private) @label(attr) audioElement","text":"<p><code>HTMLMediaElementWithCaptureStream</code> source of audio being played.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelprivate-labelattr-queue","title":"@label(private) @label(attr) queue","text":"<p><code>Blob[]</code> contains audio files to be played.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelattr-stream","title":"@label(attr) $stream","text":"<p><code>BehaviorSubject&lt;MediaStream|null&gt;</code> keeping track of the current audio stream. This will be consumed by the waveform visualiser.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelattr-playing","title":"@label(attr) $playing","text":"<p><code>BehaviorSubject&lt;boolean&gt;</code> to keep track of the current playing state.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#methods","title":"Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelprivate-labelmeth-play-next-in-queue","title":"@label(private) @label(meth) Play Next in Queue","text":"<pre><code>private playNextInQueue(): void\n</code></pre> Description This method will play the next audio in the queue."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelmeth-get-audio-stream","title":"@label(meth) Get Audio Stream","text":"<pre><code>getAudioStream(): BehaviorSubject&lt;MediaStream|null&gt;\n</code></pre> Description Public method to retrieve the <code>BehaviorSubject</code> to track the current audio stream source. Returns <code>BehaviorSubject&lt;MediaStream|null&gt;</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelmeth-play","title":"@label(meth) Play","text":"<pre><code>play(...blob: Blob[]): void\n</code></pre> Description Method to add an audio file to the queue to be played. Parameters <code>...blob</code> (<code>...Blob[]</code>): Destructed array of <code>Blob</code>s to be played. Will be added to a queue."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelmeth-force-play","title":"@label(meth) Force Play","text":"<pre><code>forcePlayAndReplace(blob: Blob): void\n</code></pre> Description This method is to clear the current queue of audio files, and play the provided <code>Blob</code> audio. Parameters <code>blob</code> (<code>Blob</code>): Audio file to be played"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelmeth-stop-and-clear","title":"@label(meth) Stop and Clear","text":"<pre><code>stopAndClear(): void\n</code></pre> Description This method clears the current queue, stops the audio from being played and updates local states."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelmeth-play-start-voice-audio","title":"@label(meth) Play Start Voice Audio","text":"<pre><code>playStartVoiceAudio(): void\n</code></pre> Description This method plays a pre-defined audio file (<code>startvoice.mp3</code>) from the app's assets, used to signal the start of voice interaction."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-player/#labelmeth-play-stop-voice-audio","title":"@label(meth) Play Stop Voice Audio","text":"<pre><code>playStopVoiceAudio(): void\n</code></pre> Description This method plays a pre-defined audio file (<code>stopvoice.mp3</code>) from the app's assets, used to signal the end of voice interaction."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-service/","title":"Audio Service","text":"<p>This service is responsible for managing the microphone resources on the frontend.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-service/#labelservice-audioservice","title":"@label(service) AudioService","text":"<p>This service requests for the microphone resource when necessary during voice input, and releases the microphone resource after voice recording has ended.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-service/#methods","title":"Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-service/#labelprivate-labelmeth-get-mic-input","title":"@label(private) @label(meth) Get Mic Input","text":"<pre><code>async getMicInput(): Promise&lt;MediaStream&gt;\n</code></pre> Description <p>This method will retrieve the microphone resource from the device.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-service/#labelasync-labelmeth-stop-audio-tracks","title":"@label(async) @label(meth) Stop audio tracks","text":"<pre><code>async stopTracks(stream: MediaStream)\n</code></pre> Description <p>This method will release all audio tracks and release the microphone resource.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/audio-service/#labelasync-labelmeth-merge-audio-streams","title":"@label(async) @label(meth) Merge Audio Streams","text":"<pre><code>async mergeAudioStreams(...streams: MediaStream[]): Promise&lt;MediaStream&gt;\n</code></pre> Description <p>This method merges the audio streams into 1 audio stream.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/","title":"Chat Message Service","text":"<p>This service is meant to handle persistence of conversation.</p> <p>Foot gun</p> <p>The current implementation is a \"foot gun\" implementation that was easy to put together and work for the limited use cases that were laid out. However, there are inheirent drawbacks that might induce silent failures in the expected behavior.</p> <p>Currently, only one chat history (defined by <code>Profile.id</code>) can be tracked at any one point of time. Calling <code>ChatMessageService.load()</code> will drop the reference to previously loaded chat histories. This means that previous <code>BehaviorSubject</code>s tracking the conversation will be orphaned and will not recieve any updates upon changes.</p> <p>How to fix</p> <p>This can be improved by memoizing the loaded chat history into a <code>Record&lt;string, BehaviorSubject&lt;Message[]&gt;</code>, so all <code>BehaviorSubject</code>s can be tracked and updated as necessary. Calling <code>ChatMessageService.load()</code> can then return a reference to the memoized <code>BehaviorSubject</code>. This will allow multiple conversations to be loaded and updated simultaniously.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#labelservice-chatmessageservice","title":"@label(service) ChatMessageService","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#labelprivate-labelattr-messages","title":"@label(private) @label(attr) $messages","text":"<p><code>BehaviorSubject&lt;Message[]&gt;</code> tracking the currently active chat history.</p> <p>Important</p> <p>See the note above.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#labelprivate-labelattr-currentprofileid","title":"@label(private) @label(attr) $currentProfileId","text":"<p><code>BehaviorSubject&lt;string&gt;</code> to keep track of the currently loaded conversation. Mainly used to print a warning in console.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#methods","title":"Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#labelmeth-load-messages","title":"@label(meth) Load Messages","text":"<pre><code>async load(profileId: string): Promise&lt;BehaviorSubject&lt;Message[]&gt;&gt;\n</code></pre> Description Method to load the conversation with a given profile into memory to be tracked for updates. Parameters <code>profileId</code> (<code>string</code>): Profile ID of the conversation to load. Returns <code>Promise&lt;BehaviorSubject&lt;Message[]&gt;&gt;</code> <p>Important</p> <p>See the note above.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#labelmeth-static-load-messages","title":"@label(meth) Static Load Messages","text":"<pre><code>async staticLoad(profileId: string): Promise&lt;Message[]&gt;\n</code></pre> Description Method to fetch the current existing messages with a given profile. This does not induce any side effects. Parameters <code>profileId</code> (<code>string</code>): ID of the profile to fetch for. Returns <code>Promise&lt;Message[]&gt;</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#labelmeth-insert-message","title":"@label(meth) Insert Message","text":"<pre><code>insert(message: Message): Promise&lt;void&gt;\n</code></pre> Description Method to persist a message in <code>IndexedDb</code>. Parameters <code>message</code> (<code>Message</code>): Message to be persisted Returns <code>Promise&lt;void&gt;</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/chat-message/#labelmeth-upsert-message","title":"@label(meth) Upsert Message","text":"<pre><code>upsert(message: Message): Promise&lt;void&gt;\n</code></pre> Description Method to update or create new message for persistence. Parameters <code>message</code> (<code>Message</code>): Message to be updated or created. Returns <code>Promise&lt;void&gt;</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/","title":"Conversation Broker Service","text":"<p>This service is responsible for managing interaction between UI components and other services related to chat (and voice) functionality.</p> <p>Isolation of business logic</p> <p>All interaction with voice and chat MUST come through this service. Logic related to all global interaction has been encapsulated into this service, so that UI components can focus on UI states and only UI related logic that responds to changes reflected in this service.</p> <p>This service should reflect the global state of events necessary for UI components.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelservice-convobrokerservice","title":"@label(service) ConvoBrokerService","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelattr-recorder","title":"@label(private) @label(attr) recorder","text":"<p><code>AudioRecorder</code> is the object responsible for recording user audio.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelattr-activeprofile","title":"@label(private) @label(attr) activeProfile","text":"<p><code>Profile | undefined</code> tracks the currently active profile. This is updated by a subscription instantiated by the constructor.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelattr-micstate","title":"@label(attr) $micState","text":"<p><code>BehaviorSubject&lt;MicState&gt;</code> is the global controller for the mic state, used to control the UI state of the main mic button on the voice page.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelattr-sendtimeout","title":"@label(attr) $sendTimeout","text":"<p><code>BehaviorSubject&lt;boolean&gt;</code> is a boolean flag used to signal if a timeout should be invoked.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelattr-iswaitingforvoiceapi","title":"@label(attr) $isWaitingForVoiceApi","text":"<p><code>BehaviorSubject&lt;boolean&gt;</code> to track if a response has been made from the backend API regarding voice chat.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#voice-chat-related-methods","title":"Voice Chat Related Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelmeth-initialise-voice-chat","title":"@label(private) @label(meth) Initialise Voice Chat","text":"<pre><code>private async initVoiceChat(): Promise&lt;void&gt;\n</code></pre> Description Method to initialise voice activity detection, and initialise <code>AudioRecorder</code>. It is called in the constructor of the service. This method instantiates the subscription for VAD detection, and contains side effects. <p>VAD is only active in voice mode</p> <p>To prevent undesired VAD, the initialised subscribtion to handle VAD will only trigger side effects when the user is in <code>ChatMode.Voice</code>.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelmeth-start-recording","title":"@label(private) @label(meth) Start Recording","text":"<pre><code>private handleStarteRecording(): void\n</code></pre> Description Method to trigger the start of audio recording."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelmeth-stop-recording","title":"@label(private) @label(meth) Stop Recording","text":"<pre><code>private handleStopRecording(): void\n</code></pre> Description Handle the stopping of recording, and post process the recorded audio. The recorded audio will be sent to the backend as a voice message."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelmeth-stop-audio-playback","title":"@label(private) @label(meth) Stop Audio Playback","text":"<pre><code>private handleStopPlaying(): void\n</code></pre> Description Method to stop the current audio playback and reset the mic state. Also unsubscribes from the voice stream to prevent further audio from playing."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelmeth-unsubscribe-from-voice-stream","title":"@label(private) @label(meth) Unsubscribe from Voice Stream","text":"<pre><code>private unsubscribeVoiceStream(): void\n</code></pre> Description Method to unsubscribe from the voice stream and reset any active voice subscriptions. This method ensures that any ongoing or pending voice stream is canceled properly to avoid memory leaks."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelmeth-play-base64-encoded-audio","title":"@label(private) @label(meth) Play Base64 Encoded Audio","text":"<pre><code>private async playAudioBase64(val:string): Promise&lt;void&gt;\n</code></pre> Description Method to play a base 64 encoded audio. This induces side effects in <code>AudioPlayerService</code>. Parameters <code>val</code> (<code>string</code>): Base 64 encoded audio file."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelprivate-labelmeth-send-voice","title":"@label(private) @label(meth) Send Voice","text":"<pre><code>private async sendVoice(audio: Blob, profile: Profile): Promise&lt;void&gt;\n</code></pre> Description Sends audio blob to the backend for LLM and voice chat functionality; it will handle the responses and updating of states related to voice chat. Side effects include audio player and chat message service. Parameters <code>audio</code> (<code>Blob</code>): Blob of audio recording file. <code>profile</code> (<code>Profile</code>): Profile used in the conversation"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelmeth-mic-button-click","title":"@label(meth) Mic Button Click","text":"<pre><code>handleMicButtonClick(): void\n</code></pre> Description Method used in callbacks when the mic button to trigger audio recording actions has been clicked."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#text-chat-related-methods","title":"Text Chat Related Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelmeth-send-chat","title":"@label(meth) Send Chat","text":"<pre><code>async sendChat(message: string, profile: Profile): Promise&lt;void&gt;\n</code></pre> Description Method to send a chat message. This will handle the persistence of messages into IndexedDB, and interacting with the backend via the <code>EndpointService</code>. Parameters <code>message</code> (<code>string</code>): User input message <code>profile</code> (<code>Profile</code>): Active profile used in the conversation."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#feedback-related-methods","title":"Feedback Related Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/conversation-broker/#labelmeth-send-feedback","title":"@label(meth) Send Feedback","text":"<pre><code>async sendFeedback(feedback: Feedback)\n</code></pre> Description Method to send a feedback object. This will handle the persistence of messages into IndexedDB, and interacting with the backend via the <code>EndpointService</code>. Parameters <code>feedback</code> (<code>feedback</code>): Feedback object"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/","title":"Endpoint Service","text":"<p>This service is used to interact with the backend. Understandably, this is the most crucial part in the context of backend frontend integration. Given that (at the point of writing) the endpoints were still evolving, this service served as a abstraction layer, so that the rest of the webapp will not break -- when API endpoints are updated, technically, this is the only service that needs to be updated, technically.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#labelservice-endpointservice","title":"@label(service) EndpointService","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#utility-methods","title":"Utility Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#labelmeth-text-to-speech","title":"@label(meth) Text to Speech","text":"<pre><code>async textToSpeech(text: string): Promise&lt;BehaviorSubject&lt;Blob | null&gt;&gt;\n</code></pre> Description Method to send text to the backend for conversion to speech. Parameters <code>text</code> (<code>string</code>): The text that needs to be converted to speech. Returns <code>Promise&lt;BehaviorSubject&lt;Blob | null&gt;&gt;</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#labelprivate-labelmeth-message-to-api-chat-history","title":"@label(private) @label(meth) Message to Api Chat History","text":"<pre><code>private messageToApiChatHistory(message: Message[]): ApiChatHistory[]\n</code></pre> Description Method to convert <code>Message</code> array into <code>ApiChatHistory</code> format for backend consumption. Parameters <code>message</code> (<code>Message[]</code>): Array of messages to convert. Returns <code>ApiChatHistory[]</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#labelprivate-labelmeth-message-to-api-chat-history-with-sources","title":"@label(private) @label(meth) Message to Api Chat History with Sources","text":"<pre><code>private messageToApiChatHistoryWithSources(message: Message[]): ApiChatHistorywithSources[]\n</code></pre> Description Method to convert <code>Message</code> array into <code>ApiChatHistorywithSources</code> format for backend consumption. Parameters <code>message</code> (<code>Message[]</code>): Array of messages to convert. Returns <code>ApiChatHistorywithSources[]</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#labelprivate-labelmeth-profile-to-api-profile","title":"@label(private) @label(meth) Profile to Api Profile","text":"<pre><code>private profileToApiProfile(profile: Profile): ApiProfile\n</code></pre> Description Method to convert <code>Profile</code> into <code>ApiProfile</code> format for backend consumption. Parameters <code>profile</code> (<code>Profile</code>) Returns <code>ApiProfile</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#methods","title":"Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#labelmeth-send-voice","title":"@label(meth) Send Voice","text":"<pre><code>async sendVoice(\n    recording: Blob,\n    profile: Profile,\n    history: Message[]\n): Promise&lt;BehaviorSubject&lt;VoiceResponse|null&gt;&gt;\n</code></pre> Description Method to send voice recording to the backend. Parameters <code>recording</code> (<code>Blob</code>): Binary of file recording. <code>profile</code> (<code>Profile</code>): Active profile used in the conversation. <code>history</code> (<code>Message[]</code>): Chat history in the conversation. Returns <code>Promise&lt;BehaviorSubject&lt;VoiceResponse|null&gt;&gt;</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/endpoint/#labelmeth-send-chat","title":"@label(meth) Send Chat","text":"<pre><code>async sendChat(\n    message: Message,\n    profile: Profile,\n    history: Message[]\n): Promise&lt;BehaviorSubject&lt;ChatReponse|null&gt;&gt;\n</code></pre> Description Method to send chat (text) message to the backend for processing Parameters <code>message</code> (<code>Message</code>): Chat message from user. <code>profile</code> (<code>Profile</code>): Active profile used in the conversation. <code>history</code> (<code>Message[]</code>): Chat history in the conversation. Returns <code>Promise&lt;BehaviorSubject&lt;ChatResponse|null&gt;&gt;</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/","title":"Preference Service","text":"<p>This service handles the user preference across the webapp. It is responsible for persisting these states into local storage and listening to changes to local storage.</p> <p>Currently, this service is used for managing:</p> <ul> <li>Language</li> <li>Chat mode</li> </ul>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelservice-preferenceservice","title":"@label(service) PreferenceService","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelattr-chatmode","title":"@label(attr) $chatMode","text":"<p><code>BehaviorSubject&lt;ChatMode&gt;</code> is the state controller for the chat mode, which manages whether the app operates in text or voice mode.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelattr-language","title":"@label(attr) $language","text":"<p><code>BehaviorSubject&lt;Language&gt;</code> controls the preferred language for the application.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#methods","title":"Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelprivate-labelmeth-initialise-preferences","title":"@label(private) @label(meth) Initialise Preferences","text":"<pre><code>private initialisePreferences(): void\n</code></pre> Description Initializes the preferences by subscribing to <code>BehaviorSubjects</code> and syncing them with local storage."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelprivate-labelmeth-listen-to-local-storage-events","title":"@label(private) @label(meth) Listen To Local Storage Events","text":"<pre><code>private listenToLocalStorageEvents(): void\n</code></pre> Description Listens for local storage changes and updates the corresponding preference states in real-time."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelprivate-labelmeth-load-from-local-storage","title":"@label(private) @label(meth) Load From Local Storage","text":"<pre><code>private loadFromLocalStorage&lt;T&gt;(key: PreferenceKey, defaultValue: T): T\n</code></pre> Description Loads a preference value from local storage, or uses the provided default value if no value is found in storage. Parameters <code>key</code> (<code>PreferenceKey</code>): The key under which the preference is stored. <code>defaultValue</code> (<code>T</code>): The default value to use if the preference is not found in storage. Returns <code>T</code>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelprivate-labelmeth-set-to-local-storage","title":"@label(private) @label(meth) Set To Local Storage","text":"<pre><code>private setToLocalStorage&lt;T&gt;(key: string, value: T): void\n</code></pre> Description Stores a preference value in local storage. Parameters <code>key</code> (<code>string</code>): The storage key for the preference. <code>value</code> (<code>T</code>): The value to store in local storage."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelmeth-set-chat-mode","title":"@label(meth) Set Chat Mode","text":"<pre><code>setChatMode(mode: ChatMode): void\n</code></pre> Description Sets the chat mode (either voice or text mode) for the application. Parameters <code>mode</code> (<code>ChatMode</code>): The chat mode to set, either <code>ChatMode.Voice</code> or <code>ChatMode.Text</code>."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#labelmeth-set-language","title":"@label(meth) Set Language","text":"<pre><code>setLanguage(language: Language): void\n</code></pre> Description Sets the preferred language for the application. Parameters <code>language</code> (<code>Language</code>): The selected language preference."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#older-implementations-labeldeprecated","title":"Older Implementations @label(deprecated)","text":"<p>Not Currently Used</p> <p>The following are older features previously handled by this service, but they are no longer in use. They remain documented here for reference but are not active in the current version of the app.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#show-live-transcription","title":"Show Live Transcription","text":"<p>Toggles live transcription of the user\u2019s voice input during interactions. This would show a live text transcription as the user speaks.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#voice-interrupt","title":"Voice Interrupt","text":"<p>Allows the user to enable or disable the ability to interrupt ongoing audio playback with a voice command.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#detect-voice-start","title":"Detect Voice Start","text":"<p>Controls whether the app would automatically detect when the user starts speaking to begin recording.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/preference/#detect-voice-end","title":"Detect Voice End","text":"<p>Controls the automatic detection of the end of the user\u2019s voice input, used to stop recording after a period of silence.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/","title":"Profile Service","text":"<p>This service is responsible for creating new profiles and managing existing profiles for users.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelservice-profileservice","title":"@label(service) ProfileService","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelprivate-labelattr-profiles","title":"@label(private) @label(attr) $profiles","text":"<p><code>BehaviorSubject&lt;Profile[]&gt;</code> stores all profiles retrieved from the database store.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelprivate-labelattr-currentprofileinurl","title":"@label(private) @label(attr) $currentProfileInUrl","text":"<p><code>BehaviorSubject&lt;string&gt;</code> tracks the current profile through the profile id in the url.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#methods","title":"Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelmeth-set-profile-in-url","title":"@label(meth) Set Profile in URL","text":"<pre><code>setProfileInUrl(id: string)\n</code></pre> Description Method to update the existing url to the new profile linked to the argument 'id' passed into the function."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelmeth-create-profile","title":"@label(meth) Create Profile","text":"<pre><code>createProfile(profile: Profile)\n</code></pre> Description Method to create a new profile."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelmeth-get-all-profiles","title":"@label(meth) Get All Profiles","text":"<pre><code>getProfiles(): BehaviorSubject&lt;Profile[]&gt;\n</code></pre> Description Method to get all existing profiles in the database store."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelmeth-get-specific-profiles","title":"@label(meth) Get Specific Profiles","text":"<pre><code>getProfile(profileId: string): BehaviorSubject&lt;Profile | undefined&gt;\n</code></pre> Description Method to get a specific profiles in the database store. If the profile does not exist, it does not return anything."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelmeth-update-profile","title":"@label(meth) Update Profile","text":"<pre><code>updateProfile(updatedProfile: Profile)\n</code></pre> Description Method to update the profile in updatedProfile."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/profile-service/#labelmeth-delete-profile","title":"@label(meth) Delete Profile","text":"<pre><code>deleteProfile(id: string)\n</code></pre> Description Method to delete a profile by id."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/","title":"Voice Activity Detection @label(deprecated)","text":"<p>This service is used to handle Voice Activity Detection (VAD).</p> <p>The current implementation uses the browser's <code>SpeechRecognition</code> API to detect speech. Transcription is still handled by the backend due to the following reasons.</p> <ol> <li>Multi language support. The browser requires the user to specify the language; leaving this capability to the backend allows us to automatically detect the user's language.</li> <li>Limited browser support. Not all browsers support this API (e.g. Arc, Firefox), leaving this to our own API allows us to have full control and simplify the process of Speech to Text (STT) transcription.</li> </ol> <p>Fallback required</p> <p>A fall back VAD detector needs to be implemented in the event of an unsupported browser. This method can be done using live transcription from our backend, or using alternative methods (e.g. volume levels).</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#labelservice-vadservice","title":"@label(service) VadService","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#attributes","title":"Attributes","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#labelprivate-endtimeout","title":"@label(private) endTimeout","text":"<p><code>number</code> to keep track of timeout calls that are used in <code>VadService.start()</code> to emit an event when speech has ended.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#labelprivate-speech","title":"@label(private) $speech","text":"<p><code>Subject&lt;void&gt;</code> emits an event whenever speech has been detected; fired through a subscription in <code>VadService.configSpeechRecognition()</code> as a side effect.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#labelprivate-recognition","title":"@label(private) recognition","text":"<p><code>SpeechRecognition</code> object from the browser.</p>"},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#methods","title":"Methods","text":""},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#labelprivate-labelmeth-configure","title":"@label(private) @label(meth) Configure","text":"<pre><code>private configSpeechRecofnition(): void\n</code></pre> Description Method to instantiate the speech recognition object. Called in the constructor."},{"location":"projects/genai/conversational-assistant/webapp/frontend/services/voice-activity-detection/#labelmeth-start","title":"@label(meth) Start","text":"<pre><code>start(): Observable&lt;VoiceActivity&gt;\n</code></pre> Description Method to get an observable to keep track of VAD activity. Returns <code>Observable&lt;VoiceActivity&gt;</code>"},{"location":"projects/genai/health-hub/content-opt-and-harm/","title":"Index","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/#introduction","title":"Introduction","text":"<p>Our primary objective is to reduce the workload in the manual review process. It aims to identify and optimise the articles across three different areas -</p> <ol> <li>Article Content</li> <li>Article Title</li> <li>Article Meta Description</li> </ol>"},{"location":"projects/genai/health-hub/content-opt-and-harm/#workflow","title":"Workflow","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/#optimisation-workflow","title":"Optimisation Workflow","text":"<p> For individual articles, the initial steps of the Article Rewriting Workflow is to evaluate the quality of the article based on its content, title and meta description. We utilise both Rules, Statistics and Large Language Models (LLMs) to perform these evaluations. Then, these evaluations are later shared to the users for approval/refinement. Finally, the selected articles (together with their evaluations) are passed down to the <code>Article Optimisation Flow</code> to refine and optimise the articles.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/#harmonisation-workflow","title":"Harmonisation Workflow","text":"<p> For grouped articles, the user will annotate articles to harmonise in the User Annotation Excel file. Following that, these artilces will undergo Article Harmonisation.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/#project-setup","title":"Project Setup","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/#setting-up-for-optimisation-checks","title":"Setting up for Optimisation Checks","text":"<ol> <li>Run the Data Processing Pipeline via Kedro. Refer to the <code>README.md</code> in <code>content-optimization</code> for more information.</li> <li>Fetch the <code>merged_data.parquet</code> file from the <code>content-optimization/data/03_primary</code> directory</li> <li>Generate the <code>ids_for_optimisaton.csv</code> files by referring to the <code>exclude_articles.ipynb</code> notebook.</li> <li>Add these 2 files into the <code>data</code> subdirectory in the <code>article-harmonisation</code> project.</li> <li>Run the <code>checks.py</code> Python file to execute the Optimisation Checks workflow.</li> </ol> <p>Refer to the <code>README.md</code> in <code>article-harmonisation</code> for more information.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/#setting-up-for-article-rewriting","title":"Setting up for Article Rewriting","text":"<ol> <li>Run the Data Processing Pipeline via Kedro. Refer to the <code>README.md</code> in <code>content-optimization</code> for more information.</li> <li>Fetch the <code>merged_data.parquet</code> file from the <code>content-optimization/data/03_primary</code> directory</li> <li>Add the <code>merged_data.parquet</code> file into the <code>data</code> subdirectory in the <code>article-harmonisation</code> project.</li> <li>Go to the Step 1 Harmonisation and Optimisation Checks subdirectory within User Annotation directory.</li> <li>Download Stage 1 user annotation for HPB_sample.xlsx and store it in <code>article-harmonisation/data/article_rewriting/</code> in the <code>article-harmonisation</code> project.</li> </ol> <p>Refer to the <code>README.md</code> in <code>article-harmonisation</code> for more information.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/","title":"LangChain","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/#introduction","title":"Introduction","text":"<p>LangChain is a framework for developing LLM-powered applications. It is a library for building complex chain-based language processing applications. It allows for easy chaining of components like parsers, retrievers and generators, making it ideal for natural language processing tasks.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/#langchain-expression-language-lcel","title":"LangChain Expression Language (LCEL)","text":"<p>We predominantly use LCEL to support quick and easy prototyping of LangChain components.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/#runnables","title":"Runnables","text":"<p>Runnables are standard interfaces that allows us to combine various LangChain components into a chain. We typically use the pipe <code>|</code> operator to chain them together. Refer to this documentation on how to chain these runnables.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/#working-with-multiple-chains","title":"Working with Multiple Chains","text":"<p>There are times when you need to utilise the outputs from a previous chain in the current one. Typically, this requires constructing a <code>meta-chain</code> that links all these chains together. Also, you would need to define a dictionary containing a <code>RunnablePassthrough()</code> as a value in the chain of interest. The value can then be fetched via an <code>itemgetter</code> in the <code>meta-chain</code>.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/#inspecting-your-runnables","title":"Inspecting Your Runnables","text":"<p>Sometimes, the constructed chain can get very complicated. Hence, it is important to inspect how the chains are arranged so that you can view the data flow along these components for better debugging. This is especially the case when there is parallel execution and/or branches in the LLM chain.</p> <p>Note</p> <p>Use <code>chain.get_graph().print_ascii()</code> to obtain the computation graph of the LLM Chain</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/#classes","title":"Classes","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/langchain/#azurechatopenai","title":"AzureChatOpenAI","text":"<p>During the Article Rewriting Process, we are utilising <code>gpt-4o-mini</code> from Azure OpenAI Service to evaluate and optimise the articles. We rely on the <code>AzureChatOpenAI</code> class to abstract the implementation of making HTTP requests to the service and use them within chains.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langgraph/","title":"LangGraph","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/langgraph/#introduction","title":"Introduction","text":"<p>LangGraph is a framework for developing LLM-powered Agentic Workflows. It is a library for building stateful, multi-actor applications with large language models (LLMs). It extends the LangChain framework to enable the creation of complex, stateful workflows involving multiple AI agents.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langgraph/#key-concepts","title":"Key Concepts","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/langgraph/#graphs","title":"Graphs","text":"<p>LangGraph agents compose of three key components -</p> <ol> <li>State: A shared data structure that represents the current snapshot of the Agentic Workflow. We are using a TypedDict to store data throughout the workflow.</li> <li>Nodes: Python functions that perform transformation on the current state and returns an updated state.</li> <li>Edges: Python functions that directs the execution of the Agentic Workflow along a sequence of nodes based on either conditional or fixed transitions.</li> </ol> <p>The Graph State must consist of Schema and Reducers. The Schema is typically stored in <code>states/definitions.py</code> within the <code>article-harmonisation</code> project. The reducers are stored in the <code>utils/formatters.py</code>.</p> <p>There are 3 key functions that we have created to run the LangGraph application. We have stored these functions in <code>utils/graphs.py</code>. They are -</p> <ol> <li><code>create_graph</code>: Python function that compiles a LangGraph Object based on the provided schema, nodes and edges.</li> <li><code>draw_graph</code>: Python function to generate a visual representation of the Compiled LangGraph object, displaying the possible paths of the workflow</li> <li><code>execute_graph</code>: Python function to execute the LangGraph Application with the provided input and CompiledGraph object.</li> </ol>"},{"location":"projects/genai/health-hub/content-opt-and-harm/langgraph/#notes","title":"Notes","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/langgraph/#branching","title":"Branching","text":"<p>In our project, we implemented a custom reducer that assist in updating dictionaries during parallel node execution. Refer to this link to understand how to implement branches for parallel execution.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/llm-observability/","title":"LLM Observability","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/llm-observability/#introduction","title":"Introduction","text":"<p>Phoenix by Arize AI is an open-source observability library designed for experimentation, evaluation, and troubleshooting. It allows us to visualise the execution of the Agentic Workflows and track down issues. We mainly use Phoneix to trace the execution of the LangGraph workflows. Refer to these notebooks to learn more about how to use Phoenix for LLM tracing.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/llm-observability/#tracing","title":"Tracing","text":"<p>LLM tracing records the paths taken by requests as they propagate through multiple steps or components of an LLM application. Tracing is a helpful tool for understanding how your LLM application works. Phoenix offers comprehensive tracing capabilities that are not tied to any specific LLM vendor or framework.</p> <p></p> <p>Phoenix captures the following traces from the LangGraph execution -</p> <ul> <li>Application Latency: Identify and address slow invocations of LLMs, Retrievers, and other components within your application, enabling you to optimize performance and responsiveness.</li> <li>Token Usage: Gain a detailed breakdown of token usage for your LLM calls, allowing you to identify and optimize the most expensive LLM invocations.</li> <li>Runtime Exceptions: Capture and inspect critical runtime exceptions, such as rate-limiting events, that can help you proactively address and mitigate potential issues.</li> <li>Prompt Templates: Understand the prompt templates used during the prompting step and the variables that were applied, allowing you to fine-tune and improve your prompting strategies.</li> <li>LLM Function Calls: For LLMs with function call capabilities (e.g., OpenAI), you can inspect the function selection and function messages in the input to the LLM, further improving your ability to debug and optimize your application.</li> </ul> <p>Refer to this link to learn more about implementing tracing for LangGraph applications.</p> <p>Warning</p> <p>Ensure that the Phoenix Server is active when running the LangGraph Agentic Workflows. <pre><code># Launches the web server at http://127.0.0.1:6006\npython3 -m phoenix.server.main serve\n</code></pre></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_content_preprocessing/","title":"Article Content Preprocessing","text":"<p><p>Article Content Preprocessing</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_content_preprocessing/#1-introduction","title":"1. Introduction","text":"<p>This section will be covering the preprocessing step for an article content before it is processed by the researcher node. The preprocessing is conducted by a rule-based function. All article content will need to undergo this step before being processed by the researcher node.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_content_preprocessing/#2-rationale-for-article-content-preprocessing","title":"2. Rationale for Article Content Preprocessing","text":"<p>Some articles contain a list-like structure, where there is a clear hierachy between headers. For example, a h2 header can be used to introduce the readers to the list, followed by h3 headers representing an item each. This example can be be seen below:</p> <pre><code>\"\"\"&lt;h2&gt; 2 bodyweight exercises to help you achieve your weight goal &lt;/h2&gt;\n\n&lt;h3&gt; 1. Pushups &lt;/h3&gt;\n&lt;p&gt; Details about pushups &lt;/p&gt;\n\n&lt;h3&gt; 2. Situps &lt;/h3&gt;\n&lt;p&gt; Details about situps &lt;/p&gt;\"\"\"\n</code></pre> <p>For this explanation and for the rest of this page, we will be referring to the h2 headers as a \"parent\" to the h3 headers and the h3 headers as a \"child\" to the h2 headers.</p> <p>This relationship between a parent and child header is not captured effectively in the <code>extracted_content_body</code> when extracting it from the <code>merged_data.parquet</code> file. Hence, a pre-processing step is added to better accentuate these relations between headers.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_content_preprocessing/#3-explanation-of-article-content-preprocessing-output","title":"3. Explanation of Article Content Preprocessing Output","text":"<p>This step starts by extracting the article headers and its content body from <code>merged_data.parquet</code>.</p> <p>It will extract the html tag of the header from <code>extracted_headers</code> and determine which header category the header to. The header categories are listed in the table below.</p> <p> html tag header category h1 Main Header h2 Sub Header h3 - h6 Sub Section <p></p> <p>The article preprocessing will concatenate the html header tag with the header category like so:</p> <p><code>&lt; html tag &gt; &lt; header category &gt;: &lt; article header &gt;</code></p> <p>The function will also check for any potential parent for each header. Any preceding header of a greater hierachy than the header currently processed will be considered it's \"parent\". In other words, a h2 header will be considered to be the parent of any subsequent h3 headers, until the next h2 header or h1 header. Likewise, if the article flows consist of a h2, h3, then a h4 header, the h3 header will be considered the parent of the h4 header.</p> <p>If any parent header is found, the details will be captured in a String like so:</p> <p><code>&lt;header category of current header&gt; to &lt;html tag of parent header&gt; &lt;header category of parent header&gt;: &lt;parent header&gt;</code></p> <p>If no parent header is found, there will be no additional String below.</p> <p>After processing the header type and checking for any parents, the rest of the content pertaining to the specific header will follow.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_content_preprocessing/#4-example-of-article-content-preprocessing-output","title":"4. Example of Article Content Preprocessing Output","text":"<p>Continuing from the example above, this is will be the output after the preprocessing step:</p> <pre><code>\"\"\"h2 Sub Header: 2 bodyweight exercises to help you achieve your weight goal\n\nh3 Sub Section: 1. Pushups\nSub Section to h2 Sub Header: 2 bodyweight exercises to help you achieve your weight goal\nContent: # All content under this header\n\nh3 Sub Section: 2. Situps\nSub Section to h2 Sub Header: 2 bodyweight exercises to help you achieve your weight goal\nContent: # All content under this header\"\"\"\n</code></pre> <p>The h2 header in the example is referred to as a h2 Sub Header, corresponding to it's header category from the table. The h2 header is not a sub header to any parent header, and neither does it have any content below the header, hence there is only a single line.</p> <p>The h3 headers also has their html tags and corresponding header category captured in the first line, followed by a second sentence stating their relation to the h2 Sub Header. Finally, the content for the h3 Sub Sections are concatenated below.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_content_preprocessing/#5-additional-resources-for-the-article-content-preprocessing-process","title":"5. Additional Resources for the article content preprocessing process","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li>@label(func) <code>concat_headers_to_content()</code> : This function runs the rule-based preprocessing step. This function can found be at <code>article-harmonisation/utils/formatters.py</code>.</li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_harmonisation_intro/","title":"Intro to Article Harmonisation","text":"<p>Article Harmonisation Workflow</p> <p></p> <p>Article Harmonisation Workflow diagram</p> <p>Article harmonisation refers to the process of harmonising (combining) a group of articles. Articles in the same cluster can be marked for harmonisation, which will lead them to undergo the article harmonisation process. Article harmonisation will optimise all 4 article categories: article content, writing, title and meta description.</p> <p>The article harmonisation process is largely similar to that of article optimisation, with several exceptions. As such, the description for the article harmonisation process will take reference to the article optimisation process.</p> <p>The article harmonisation process is as follows:</p> <p>Step 1 Researcher node: This node is used to process the article content. It checks for irrelevant sentences in the article content and categorises them under a separate section. </p> <p>Step 2 Compiler node: The compiler node compiles the keypoints from each article from the researcher node. It combines identical keypoints between the group of processed article keypoints from the Researcher node.</p> <p>Step 3 Content guidelines optimisation: Under article harmonisation, all articles will undergo content guidelines optimisation irregardless of their content category.  For <code>disease-and-conditions</code> articles, the process of content optimisation is identical to article optimisation. For <code>live-healthy</code> articles, the compiled article content will be structured based on the structure of a user annoted \"main\" article.</p> <p>Step 4 Writing optimisation: Writing optimisation is carried out when the user flags the article for writing optimisation. The writing optimisation process aims to rewrite the article content to fit HealthHub's personality guidelines as well as improving the article's Hemingway readability score until it is less than 10.</p> <p>Writing guidelines is a multi-node process, consisting of a feedback loop with the following nodes:</p> <p>Step 4.1 Writing guidelines optimisation: This node is used to rewrite the article content to meet the voice and personality guidelines of HealthHub's voice and personality guidelines.</p> <p>Step 4.2 Readability optimisaion node: This node is used to rewrite the article content to improve the article's readability score. The article's readability is scored using the Hemingway scoring system.</p> <p>Step 4.3 Personality evaluation node: This node is used to evaluate if a readability optimised article still adheres to the HealthHub voice and personality guidelines. This evaluation will be used to determine if the article content requires another round of rewriting or to move on to subsequent optimisation nodes.</p> <p>Step 5 Title optimisation: The title optimisation process involves producing three optimised article titles from the article content. The titles will be optimised based on the HealthHub content playbook guidelines.</p> <p>Step 6 Meta description optimisation: The meta description optimisation process involves producing three optimised meta description from the article content.</p> <p>After the article optimisation process has been completed, the optimised output will be stored in the User Annotation Excel file for users to review.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article_optimisation_intro/","title":"Intro to Article Optimisation","text":"<p>Article Optimisation Workflow</p> <p></p> <p>Article Optimisation Workflow diagram</p> <p>Article optimisation refers to the process of optimising individual articles.</p> <p>The first step of article optimisation would be to evaluate the quality of the article based on its content, title and meta description. The article will be evaluated using Rules, Statistics and Large Language Models (LLMs). The output will then be stored on the User Annotation Excel File.</p> <p>Users will then analyze the evaluation outputs on the User Annotation Excel File and flag out areas to be optimised. Users can choose to flag these areas for optimisation: title, meta description and content.</p> <p>After user annotation, the article will undergo article optimisation. The flow of article optimisation is as follows:</p> <p>Step 1 Researcher node: This node is used to process the article content. It checks for irrelevant sentences in the article content and categorises them under a separate section. </p> <p>Step 2 Content guidelines optimisation: Content guidelines optimisation is carried out when the user flags the article for content optimisation. Under article optimisation, only diseases-and-conditions articles will undergo content optimisation.</p> <p>This process will strucure the article content into a specified structure and rewrite the content to fit the guidelines from the HealthHub content playbook.</p> <p>Step 3 Writing optimisation: Writing optimisation is carried out when the user flags the article for writing optimisation. The writing optimisation process aims to rewrite the article content to fit HealthHub's personality guidelines as well as improving the article's Hemingway readability score until it is less than 10.</p> <p>Writing guidelines is a multi-node process, consisting of a feedback loop with the following nodes:</p> <p>Step 3.1 Writing guidelines optimisation: This node is used to rewrite the article content to meet the voice and personality guidelines of HealthHub's voice and personality guidelines.</p> <p>Step 3.2 Readability optimisaion node: This node is used to rewrite the article content to improve the article's readability score. The article's readability is scored using the Hemingway scoring system.</p> <p>Step 3.3 Personality evaluation node: This node is used to evaluate if a readability optimised article still adheres to the HealthHub voice and personality guidelines. This evaluation will be used to determine if the article content requires another round of rewriting or to move on to subsequent optimisation nodes.</p> <p>Step 4 Title optimisation: The title optimisation process involves producing three optimised article titles from the article content. The titles will be optimised based on the HealthHub content playbook guidelines.</p> <p>Step 5 Meta description optimisation: The meta description optimisation process involves producing three optimised meta description from the article content.</p> <p>After the article optimisation process has been completed, the optimised output will be stored in the User Annotation Excel file for users to review.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/compiler_node/","title":"Compiler Node","text":"<p><p>Compiler Node</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/compiler_node/#1-introduction","title":"1. Introduction","text":"<p>The main task of the compiler node is to combine the processed article keypoints from the researcher node. This node is part of the article harmonisation process and compiles the processed keypoints of multiple articles.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/compiler_node/#2-rationale-for-compiler-node","title":"2. Rationale for Compiler Node","text":"<p>Since article harmonisation involves combining several largely similar articles to form a single optimised article, there will be cases where content from different articles will overlap. As such, an additional step has to be included to remove duplicate information. Having an additional LLM agent also overcomes the short context lengths of open source models used earlier in the project. Hence, the compiler node was designed to serve as a subsequent step that processes these article keypoints and ensures that there is not duplicate information/keypoints when harmonising the article content.</p> <p>While the current ChatGPT 4.o mini has a sufficiently long context length, the compiler node still serves as an additional step to combine duplicate information. This helps to split up article content processing between multiple LLM agents, which reduces the number of key instructions in the prompts which directly improve their effectiveness.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/compiler_node/#3-flow-of-compiler-node","title":"3. Flow of Compiler Node","text":"<p>The compiler node is a single step progress, where it takes processed keypoints from multiple articles as an input. it starts by extracting all researcher keypoints from the graph state and concatenating them into a single String. Clear headers and endings are indicated at the start and end of an article's keypoints. This clearly indicates the start and end of each article's keypoints for the LLM agent.</p> <p>Once the keypoints of all articles have been concatenated into a single String, the LLM agent will take the String of compiled keypoints as it's input and starts the compilation process. If any 2 keypoints contained duplicate information, the LLM agent will ensure that no content will be duplicated. After processing through these keypoints, the compiler node will return a single String containing the processed output and update it in the graph state.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/compiler_node/#4-additional-resources-for-the-compiler-node","title":"4. Additional Resources for the Compiler Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_compiler_prompt()</code> : This function returns the appropriate prompt for the compiler node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>compile_points()</code> : This function defines the LangChain for processing the article keypoints and invokes it to obtain a processed compilation of article keypoints. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>compiler_node()</code> : This function runs <code>compile_points()</code> and updates the graph state with the final compiled output. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>decide_next_optimisation_node()</code> : This function checks for the user flags after content guidelines optimisation and determines which optimisation node to direct the state to next. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_harmonisation/","title":"Content Guidelines Optimisation","text":"<p><p>Content Guidelines Optimisation Node (Article Harmonisation)</p></p> <p>Warning</p> <p>This document is still under development and only consists of the documentation up to this point. It will require further updates in the future.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_harmonisation/#1-introduction","title":"1. Introduction","text":"<p>The content guidelines optimisation node is used to rewrite the article keypoints to meet HealthHub's content guidelines and improve on the structure of the new article. Under article harmonisation, the content guidelines optimisation process varies between <code>live-healthy</code> and <code>diseases-and-conditions</code> articles.</p> <p>The process of optimising the content of <code>diseases-and-conditions</code> articles is identical to that of content optimisation for article optimisation. On the other hand, <code>live-healthy</code> articles will be restructured based on the structure of the user annoted \"main\" article.</p> <p>Note</p> <p>The details here only apply to Article Harmonisation. Kindly refer to Content Guidelines Optimisation Node (Article Optimisation) for details on Content Guidelines Optimisation in Article Optimisation</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_harmonisation/#2-rationale-for-content-guidelines-optimisation-node","title":"2. Rationale for Content Guidelines Optimisation Node","text":"<p>This section will be adding on to the rationale for content guidelines optimisation node.</p> <p>While <code>live-healthy</code> articles under article optimisation does not require content optimisation, <code>live-healthy</code> articles under article harmonisation requires a structure template for the output article.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_harmonisation/#3-flow-of-content-guidelines-optimisation-node","title":"3. Flow of Content Guidelines Optimisation Node","text":"<p>Kindly refer to here for the flow of Content Guidelines Optimisation Node in article optimisation</p> <p>In the User Annotation Excel file, files in the same group can be marked for harmonisation. Users can further split these articles into different sub groups, wherein articles within the same subgroup will be merged to produce a single succinct article.</p> <p>Within each subgroup, there will be one article designated by the user as the \"main article\". The main article will be labelled by the user in the User Annotation Excel file with a \"Y\" under the column <code>Main Article? (Y)</code>. Only <code>live-healthy</code> articles should require a main article structure.</p> <p>Content guidelines optimisation starts by extracting the content of the main article. It will then begin a three step process:</p> <p>Warning</p> <p>This section is still under development and only consists of the documentation of completed parts up to this point. It will require further updates in the future.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_harmonisation/#4-additional-resources-for-the-content-guidelines-optimisation-node","title":"4. Additional Resources for the Content Guidelines Optimisation Node","text":"<ul> <li> <p>@label(func) <code>return_content_prompt()</code> : This function returns the appropriate prompt for the content guidelines optimisation node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>optimise_content()</code> : This function defines the LangChain for optimising the article content and invokes it to obtain the final article content. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>content_guidelines_optimisation_node()</code> : This function runs <code>optimise_content()</code> and updates the graph state with the optimised article content output. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>HealthHub Content Playbook: This link will direct you to the Google Drive folder containing the Health Hub Content Playbook. The content playbook contains the guidelines used in the content optimisation prompt and they can be found under Chapter 3, Step 1, (iii) writing guide.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_optimisation/","title":"Content Guidelines Optimisation","text":"<p><p>Content Guidelines Optimisation Node (Article Optimisation)</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_optimisation/#1-introduction","title":"1. Introduction","text":"<p>The content guidelines optimisation node is used to rewrite and restructure the given article keypoints to fit the criterias of the guidelines given in the Health Hub (HH) content playbook. These guidelines include a certain structure that the article should follow, as well as certain personality writing guides.</p> <p>Note</p> <p>The details here only apply to Article Optimisation. Kindly refer to Content Guidelines Optimisation Node (Article Harmonisation) for details on Content Guidelines Optimisation in Article Harmonisation</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_optimisation/#2-rationale-for-content-guidelines-optimisation-node","title":"2. Rationale for Content Guidelines Optimisation Node","text":"<p>From the Health Hub content playbook, articles are expected to carry a certain voice and personality that emulates the writing style of Health Hub. Some voice guidelines include carrying a positive tone and be offer reassurance to the readers. Apart from rewriting the content in HealthHub's style, the content guidelines also restructures the given keypoints such that it follows a stipulated article structure. This article structure can be found in the Figma board \"HealtHub Main UI prototype\".</p> <p>Do note that in the context of Article Optimisation, only articles under the <code>diseases-and-conditions</code> category can be flagged for content guidelines optimisation. <code>live-healthy</code> articles do not undergo content guidelines optimisation due to the following reasons:</p> <ol> <li> <p>There are many sub categories under <code>live-healthy</code> articles, hence each category will require a separate prompt which will require extensive testing. Apart from that, some categories do not have a sample structure on the HealthHub Figma board.</p> </li> <li> <p><code>live-healthy</code> articles are encouraged to carry a more individualistic structure to avoid identical structure between different articles. <code>live-healthy</code> articles are meant to pique interest the readers and should avoid a set structure.</p> </li> </ol>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_optimisation/#3-flow-of-content-guidelines-optimisation-node","title":"3. Flow of Content Guidelines Optimisation Node","text":"<p>The content guidelines optimisation node for Article Optimisation is a single step process.</p> <p>The LLM agent is tasked with two objectives: To use the given keypoints to fill in the sections and rewrite the content based on the given guidelines.</p> <p>The final output should consist of an article following this structure.</p> <ol> <li>Overview of the condition</li> <li>Causes and Risk Factors</li> <li>Symptoms and Signs</li> <li>Complications</li> <li>Treatment and Prevention</li> <li>When to see a doctor</li> </ol> <p>After the article content undergoes content optimisation, the graph state will be updated with the optimised content.</p> <p>Note</p> <p>This task will be broken up into multiple steps in future developments to better capture key information in the researcher keypoints.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/content_guidelines_optimisation/#4-additional-resources-for-the-content-guidelines-optimisation-node","title":"4. Additional Resources for the Content Guidelines Optimisation Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_content_prompt()</code> : This function returns the appropriate prompt for the content guidelines optimisation node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>optimise_content()</code> : This function defines the LangChain for optimising the article content and invokes it to obtain the final article content. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>content_guidelines_optimisation_node()</code> : This function runs <code>optimise_content()</code> and updates the graph state with the optimised article content output. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>HealthHub Content Playbook: This link will direct you to the Google Drive folder containing the Health Hub Content Playbook. The content playbook contains the guidelines used in the content optimisation prompt and they can be found under Chapter 3, Step 1, (iii) writing guide.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/","title":"Meta Desc Optimisation","text":"<p><p> Meta Description Optimisation Node</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#1-introduction","title":"1. Introduction","text":"<p>The meta description optimisation node is used to create optimised meta descriptions. Users can choose to flag an article for meta description optimisation, which will produce 3 optimised meta description. Based on HealthHub's meta description length requirements, each meta description must be more than 70 characters and less than 160 characters (including spaces between words). Since there are no specified guidelines for writing meta descriptions in HealthHub's content playbook, the instructions for writing optimised meta descriptions are mainly sourced online.</p> <p>Additionally, the User Annotation Excel sheet may contain some feedback for optimising the meta description that will be addressed by the meta description optimisation node.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#2-rationale-for-meta-description-optimisation-node","title":"2. Rationale for Meta Description Optimisation Node","text":"<p>Similar to title optimisation, meta description optimisation was required to improve the original article's meta description as it's written poorly. Some meta descriptions are not sufficiently descriptive about the article's content, which will not incentivize readers to click on the link. Some key areas that needed to be addressed includes adding a call to action to the article as well as writing in an active voice.</p> <p>A feedback loop was added later in the project to ensure that all optimised meta description meet the character length requirements. At the time of writing this documentation, the project uses ChatGPT 4.o mini as the primary LLM model. While this model is able to rewrite articles effectively, it yields poor accuracy when counting the number of characters in a given text.</p> <p>Hence, it is challenging to instruct the LLM model to keep the optimised meta descriptions character length within a certain character limit while following other instructions. As such, a second prompt was required to provide clear instructions for the LLM to ensure that each optimised meta description meets the length requirements.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#3-flow-of-meta-description-optimisation-node","title":"3. Flow of Meta Description Optimisation Node","text":"<p>Meta description optimisation is a two step process, involving two unique prompts. The node starts by optimising the meta description based on a set of custom guidelines and addressing any feedback exracted from the User Annotation Excel file. Following that, the node will ensure that each optimised meta description meets the character length requirements and rewrite meta descriptions exceeding the character length limit.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#step-1-optimising-meta-description","title":"Step 1: Optimising meta description","text":"<p>In the first step, the meta description optimisation node takes in two inputs: the article content and any feedback for improving the original article meta description. The meta description optimisation node will then rewrite the article meta descriptions while following the custom guidelines and addressing the feedback from the evaluation node. The LLM agent's answer will include 3 optimised meta descriptions. An example is shown below:</p> <pre><code>\"\"\"1. Discover how Singapore's Infectious Diseases Act safeguards public health by enforcing vaccinations and controlling outbreaks.\n2. Learn how the Infectious Diseases Act helps Singapore combat infectious diseases through proactive measures and mandatory vaccinations.\n3. Explore the role of the Infectious Diseases Act in Singapore, ensuring safety through strict reporting, vaccinations, and outbreak management.\"\"\"\n</code></pre> <p>Each line starts with it's corresponding number and an article meta description.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#step-2-shortening-optimised-meta-descriptions","title":"Step 2: Shortening optimised meta descriptions","text":"<p>The second step instructs the LLM agent to check that the optimised meta descriptions have a character length between 100 and 130 characters, instead of the actual 70 - 160 characters range. This adds an additional 60 characters as a buffer as ChatGPT models could still exceed the character limit even with clear instructions. Any optimised meta description exceeding the meta description length limit will be shortened at this step.</p> <p>Finally, the actual length of each meta description is calculated after meta description optimisation through a rule-based function. If any meta description exceeds the character limit, the state graph will be redirected back for another round of meta description optimisation to produce shorter meta descriptions. In subsequent rewrites, all meta descriptions will be rewritten. If all optimised meta descriptions meet the length requirements, the graph state will be directed to other optimisation nodes.</p> <p>Note</p> <p>Further development can be done to improve the effeciveness of this feedback loop by adding additional fields for feedback on shortening the meta descriptions, as well as reducing the meta description length limit in the prompts with each subsequent rewrite. The rule-based function could also be configured to only rewrite lengthy meta descriptions while retaining shorter ones.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#4-sample-of-the-meta-description-optimisation-node-output","title":"4. Sample of the Meta Description Optimisation Node output","text":"<p>An example of the output from each step of meta description optimisation is shown below:</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#optimised-meta-descriptions-after-step-1","title":"Optimised meta descriptions after step 1","text":"<pre><code>\"\"\"1. Boost your mental well-being by developing emotional intelligence. Discover actionable tips to enhance your emotional awareness today! # 134 characters\n2. Unlock the power of emotional intelligence! Learn effective strategies to manage your emotions and improve your daily life. #123 characters\n3. Enhance your emotional intelligence with five practical steps. Transform your relationships and boost your mental health now! # 125 characters\"\"\"\n</code></pre>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#optimised-meta-descriptions-after-step-2","title":"Optimised meta descriptions after step 2","text":"<pre><code>\"\"\"1. Boost your mental well-being by developing emotional intelligence. Discover tips to enhance your emotional awareness! # 117 characters\n2. Unlock the power of emotional intelligence! Learn strategies to manage your emotions and improve your daily life. # 113 characters\n3. Enhance your emotional intelligence with five practical steps. Transform relationships and boost your mental health! # 116 characters\"\"\"\n</code></pre> <p>In the optimised meta description output from step 1, the first meta description exceeded the character limit of 130 characters stated in the prompt. In the subsequent step of meta description optimisation, the first meta description was shortened to just 117 characters. The other 2 titles were shortened as well, even though they do not exceed the character limit.</p> <p>Note</p> <p>Further testing could be done with varying limits for number of characters to achieve a better balance between meta description quality and meta description lengths.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/meta_desc_optimisation/#5-additional-resources-for-the-meta-description-optimisation-node","title":"5. Additional Resources for the Meta Description Optimisation Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_meta_desc_prompt()</code> : This function returns the appropriate prompt for the meta description optimisation node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>optimise_meta_desc()</code> : This function defines the LangChain for both meta description optimisation steps and combines them into a single chain. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>meta_description_optimisation_node()</code> : This function runs <code>optimise_meta_desc()</code> and updates the graph state with the final optimised meta description output. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>check_optimised_meta_descs_length()</code> : This function checks the character length of each optimised meta description and determines which node to send the graph state to. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>split_into_list()</code> : This is a rule-based function that takes the String output from the meta description optimisation as it's input. It will then return a list where each item is a meta description. This function can be found at <code>article-harmonisation/utils/formatters.py</code>.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/personality_evaluation/","title":"Personality Evaluation","text":"<p><p> Personality Evaluation Node</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/personality_evaluation/#1-introduction","title":"1. Introduction","text":"<p>The personality evaluation node is used to determine if an article's content meets the HealthHub's writing guidelines. This node is used to evaluate if a readability optimised writing still carries HealthHub's voice and personality after a series of rewriting.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/personality_evaluation/#2-rationale-for-personality-evaluation-node","title":"2. Rationale for Personality Evaluation Node","text":"<p>To avoid overcomplicating the prompts, the HealthHub writing guidelines were excluded from the readability optimisation nodes. Hence, the readability optimisation prompts only includes instructions for improving the readability of the article writing.</p> <p>As a result, the article writing may no longer effectively capture HealthHub's voice after readability optimisation. An additional step was required to evaluate the writing and determine if the writing needs to undergo a subsequent round of writing guidelines optimisation to better capture HealthHub's writing guidelines.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/personality_evaluation/#3-flow-of-personality-evaluation-node","title":"3. Flow of Personality Evaluation Node","text":"<p>The personality evaluation node is a single step process where the LLM agent is instructed to determine if the article writing still adheres to HealthHub's guidelines and return a corresponding boolean value. If HealthHub's writing guidelines is still captured, the LLM agent will return True. Otherwise the LLM agent will return False.</p> <p>The answer from the LLM agent will be stored in the graph's state and will be subsequently used to determine if the article writing needs to undergo another round of writing guidelines optimisation.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/personality_evaluation/#4-additional-resources-for-the-personality-evaluation-node","title":"4. Additional Resources for the Personality Evaluation Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_personality_evaluation_prompt()</code> : This function returns the personality evaluation prompt for the personality evaluation node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>evaluate_personality()</code> : This function defines the LangChain for evaluating the article's personality and invokes it to obtain the outcome of the evaluation. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>personality_guidelines_evaluation_node()</code> : This function runs <code>evaluate_personality()</code> and updates the graph state with the evaluation outcome. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>check_personality_after_personality_evaluation()</code>: This function is used to check if the readability optimised article still meets the HealthHub's writing guidelines. It will then determine which node to direct the state to based on the evaluation outcome. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/","title":"Readability Optimisation","text":"<p><p>Readability Optimisation Node</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#1-introduction","title":"1. Introduction","text":"<p>The readability optimisation node utilizes multiple prompts to improve the readability of the writing guidelines optimised article. Each prompt instructs the LLM agent to identify and rectify specifc areas for improvement.</p> <p>The article's readability is measured using the Hemingway Readability scoring system and the purpose of the readability optimisation node is to produce a final article writing that has a Hemingway score of less than 10.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#2-rationale-for-readability-optimisation-node","title":"2. Rationale for Readability Optimisation Node","text":"<p>The quality of an article can be subjective between different readers. Hence, this project utilizes the Hemingway scoring system to provide an objective evaluation for the rewritten article.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#3-flow-of-readability-optimisation-node","title":"3. Flow of Readability Optimisation Node","text":"<p>There are 4 steps in the readability optimisation node, each targetting a specifc area of the article to improve. Each step is represented by a unique prompt.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#step-1-cutting-out-redundant-writing","title":"Step 1: Cutting out redundant writing","text":"<p>The first prompt instructs the LLM to identify and cut out any redundant writing in the article body. This step helps to reduce the word count of the article, which can improve the Hemingway readability score as it is dependent on the number of words and characters in the content.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#step-2-shortening-lengthy-sentences","title":"Step 2: Shortening lengthy sentences","text":"<p>The next prompt instructs the LLM to identify and shorten any run-on sentences. The LLM agent will aim to replace these long sentences with multiple, shorter sentences or to rephrase the sentence using similar synonyms.</p> <p>Since the Hemingway readability score penalizes long sentences, run-on sentences contribute negatively to the Hemingway readability score. Shortening these sentences directly improves the Hemingway readability score.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#step-3-breaking-list-like-sentences-into-bullet-points","title":"Step 3: Breaking list-like sentences into bullet points","text":"<p>This prompt instructs the LLM to identify lengthy, list-like sentences and break them up into bullet points. List-like sentences refer to sentences listing out multiple items. For example, \"The best ways to relax are to watch shows, play games, enjoy good food, go for a hike and hang out with friends\" is a list-like sentence.</p> <p>List-like sentences are usually very long, which leads to a poorer Hemingway Readability score. Breaking these sentences up into bullet points where each item is an individual bullet point overcomes this issue and greatly improves the Hemingway score.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#step-4-simplifying-complex-words","title":"Step 4: Simplifying complex words","text":"<p>Apart from penalizing long sentences, the Hemingway Scoring system also penalizes the use of complex words. Complex words includes medical jargon or any uncommon terms. This prompt instructs the LLM to identify such terms and replace them with simpler phrases or common words to convey the same meaning.</p> <p>After completing all the readability optimisation steps, a new readability score will be calculated for the new readability optimised article and updated in the state.</p> <p>Note</p> <p>Do note that the number of rewriting tries increases by 1 whenever the article content undergoes readability optimisation. The maximum number of tries for optimising the readability of the article is set to be 3. If the number of rewriting tries exceeds the limit, the graph state will not undergo readability optimisation and instead move on to the next optimisation node.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/readability_optimisation/#4-additional-resources-for-the-readability-optimisation-node","title":"4. Additional Resources for the Readability Optimisation Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_hemingway_readability_optimisation_prompt()</code> : This function returns the appropriate readability optimisation prompt for the readability optimisation node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>optimise_readability()</code> : This function defines the LangChain for optimising the article's readability and invokes it to obtain the final readability optimised article. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>readability_optimisation_node()</code> : This function runs <code>optimise_readability()</code> and updates the graph state with the readability optimised article. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>check_num_of_tries_after_readability_optimisation()</code>: This function is used to check if the number of rewriting tries made for article optimisation has surpassed the limit and if the new readability optimised article is of acceptable readability. If either conditions returns True, this function will direct the graph state to the personality evaluation node. Otherwise, if the article has a readability score more than or equals to 10 and the number of rewriting tries has not exceeds the limit, this function will direct the graph state back to the readability optimisation node for another round of readabilty optimisation. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>calculate_readability()</code>: This is a rule-based function calculates the Hemingway readability score of a given text and returns the score as an integer. This function can be be found at <code>article-harmonisation/utils/evaluations.py</code></p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/","title":"Researcher Node","text":"<p><p>Researcher Node</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/#1-introduction","title":"1. Introduction","text":"<p>The main task of the researcher node is to process article content and sieve out unnecessary content in the article. The researcher node also adds any additional content from the User Annotation Excel file to the article.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/#2-rationale-for-researcher-node","title":"2. Rationale for Researcher Node","text":"<p>The rationale for developing a researcher node was mainly to overcome the token limits. It also improves the effectiveness of the Large Language Model (LLM) by splitting up the two tasks at the \"research\" step: processing article content and adding additional content.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/#3-flow-of-researcher-node","title":"3. Flow of Researcher Node","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/#step-1-processing-the-article-content","title":"Step 1: Processing the article content","text":"<p>A series of preprocessing steps are carried out before processing the article content through the researcher node. An abbreviated sample of an article input is shown below: </p> <pre><code>\"\"\"h3 Sub Header: Tremor in hands, arms, legs, jaw, or head\nSub Section to h2 Sub Header: Symptoms of Parkinson's disease\nContent: Patients of PD may suffer from tremors in their limbs that may worsen over time. For example, people may feel mild tremors or have difficulty getting out of a chair. They may also notice that they speak too softly, or that their handwriting is slow and looks cramped or small. \"\"\"\n</code></pre> <p>Kindly refer to article content processing for further explanation on the preprocessing steps for the article content.</p> <p>Utilizing the details of the headers and their relations to other headers, the researcher node will categorise them as a <code>main keypoint</code> or <code>sub keypoint</code>. If a header has been indicated to be the sub section/sub header of another header, it will be referred to as a <code>sub keypoint</code>. Otherwise, it will be referred to as a <code>main keypoint</code>. This process helps to retain the flow of a list-like structure in an article.</p> <p>The researcher node will also sieve out any unnecessary sentences and add it in a separate section at the bottom of it's answer. Unnecessary sentences includes citations, references, links to other pages and irrelevant sentences to the current context. These sentences will be added under an additional section at the bottom of the answer titled <code>omitted sentences</code>.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/#step-2-adding-additional-content-if-any","title":"Step 2: Adding additional content, if any","text":"<p>Following the processing step above, the researcher node will add any additional content to the article content. The additional content refers to additional content added by the user in the User Annotation Excel file. The additional content can be found under the <code>User: additional content to add for harmonisation</code> column in the Excel file.</p> <p>The additional content will be added as an additional input, along with the processed article content. The additional content will be added as a <code>main keypoint</code> to the processed article content. The researcher node is also tasked with writing an appropriate header for the additional content.</p> <p>No additional content will be added if the corresponding cell in the <code>User: additional content to add for harmonisation</code> column is empty.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/#4-sample-of-the-researcher-node-output","title":"4. Sample of the Researcher Node output","text":"<p>A sample of the final output from the researcher node can be seen below. In this example, there is additional content to be added, that can be seen in the final output.</p> <p>Additional content to be added:</p> <pre><code>\"\"\"Joining a Parkinson's support group can provide emotional support and valuable insights from others who are experiencing similar challenges. These groups offer a sense of community and shared understanding.\"\"\"\n</code></pre> <p>Final output from researcher node:</p> <pre><code>\"\"\"Main keypoint: Introduction to Parkinson's disease\nContent: Parkinson's is a neurodegenerative disease. It is a progressive disorder that affects the nervous system and other parts of the body. There are approximately 90,000 new patients diagnosed with PD annually in the US.\n\nMain keypoint: Symptoms of Parkinson's disease\n\nSub keypoint: Tremor in hands, arms, legs, jaw, or head\nContent: Patient's of PD may suffer from tremors in their limbs that may worsen over time. For example, people may feel mild tremors or have difficulty getting out of a chair. They may also notice that they speak too softly, or that their handwriting is slow and looks cramped or small.\n\nSub keypoint: Muscle stiffness\nContent: Patient's of PD may also suffer from muscle stiffness and lose their mobility as their conditions worsen over time. During early stages of Parkinson's, family members and close friends will begin to notice that the person may lack facial expression and animation as well.\n\nMain keypoint: Joining a support group\nContent: Joining a Parkinson's support group can provide emotional support and valuable insights from others who are experiencing similar challenges. These groups offer a sense of community and shared understanding.\n\nOmitted Sentences:\nBuy these essential oils to recover from Parkinson's Disease!\nRead more: Western medicine vs Alternative healing\nRelated: Newest breakthroughs in the field of neuroscience\"\"\"\n</code></pre> <p>From the sample above, a clear hierachy can be seen between the parent header <code>Symptoms of Parkinson's disease</code> and its child headers <code>Tremor in hands, arms, legs, jaw, or head</code> and <code>Muscle stiffness</code>. The list-like structure is still retained after processing by the researcher node, which will improve the writing in subsequent optimisation steps.</p> <p>The main keypoint, <code>Joining a support group</code>, was a header crafted by the researcher node for the additional content. The additional content is then found under this header.</p> <p>The final section, <code>Omitted Sentences</code>, contains irrelevant sentences and external links to other pages. In future developments, this section can be extracted out and added to the User Annotation Excel file.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/researcher_node/#5-additional-resources-for-the-researcher-node","title":"5. Additional Resources for the Researcher Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_researcher_prompt()</code> : This function returns the appropriate prompt for the researcher node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>generate_keypoints()</code> : This function defines the LangChain for processing the article content and invokes it to obtain the processed article content. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>add_additional_content()</code> : This function defines the LangChain for adding additional content and invokes it to obtain the final output from the research node. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>researcher_node()</code> : This function runs both <code>generate_keypoints()</code> and <code>add_additional_content()</code> and updates the graph state with the final researcher node output. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>check_for_compiler()</code> : This function checks if the graph state should be sent to the compiler node or subsequent optimisation steps. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/","title":"Title Optimisation","text":"<p><p> Title Optimisation Node</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#1-introduction","title":"1. Introduction","text":"<p>The title optimisation node is used to create optimised article titles. Users can choose to flag an article for title optimisation, which will produce 3 optimised article titles. Based on HealthHub's title length requirements, each article title must be less than 71 characters (including spaces between words). The title will also be rewritten based on the HealthHub title guidelines.</p> <p>Additionally, the User Annotation Excel sheet may contain some feedback for optimising the article title that will be addressed by the title optimisation node.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#2-rationale-for-title-optimisation-node","title":"2. Rationale for Title Optimisation Node","text":"<p>Title optimisation was required to improve on original article titles as they do not meet HealthHub's title guidelines. Some article titles are not sufficiently descriptive about the article's content, which will not incentivize readers to click on the link. Some key areas that needed to be addressed includes adding a call to action to the titles and writing in an active voice.</p> <p>This task was identified as a key task in the early process of planning out the structure of the LangGraph and was decoupled from the article rewriting process as it is a largely isolated task.</p> <p>A feedback loop was added later in the project to ensure that all optimised titles meet the character length requirements. At the time of writing this documentation, the project uses ChatGPT 4.o mini as the primary LLM model. While this model is able to rewrite articles effectively, it yields poor accuracy when counting the number of characters in a given text.</p> <p>Hence, it is challenging to instruct the LLM model to keep the optimised article title character length within a certain character limit while following other instructions. As such, a second prompt was required to provide clear instructions for the LLM to ensure that each optimised title meets the length requirements.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#3-flow-of-title-optimisation-node","title":"3. Flow of Title Optimisation Node","text":"<p>Title optimisation is a two step process, involving two unique prompts. The node starts by optimising the title based on the HealthHub's title guidelines and addressing any feedback exracted from the User Annotation Excel file. Following that, the node will ensure that each optimised title meets the character length requirements and rewrite titles exceeding the character length limit.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#step-1-optimising-article-title","title":"Step 1: Optimising article title","text":"<p>In the first step, the title optimisation node takes in two inputs: the article content and any feedback for improving the original article title. The title optimisation node will then rewrite the article while following the HealthHub title guidelines and addressing the feedback from the evaluation node. The LLM agent's answer will include 3 optimised titles. An example is shown below:</p> <pre><code>\"\"\"1. Safeguarding Singapore: Laws Against Infectious Diseases\n2. How Singapore's Laws Combat Infectious Disease Threats\n3. Empowering Public Health: Singapore's Infectious Disease Laws\"\"\"\n</code></pre> <p>Each line starts with it's corresponding number and an article title.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#step-2-shortening-optimised-titles","title":"Step 2: Shortening optimised titles","text":"<p>The second step instructs the LLM agent to check that the optimised titles have a character length of less than 65 characters, instead of the actual 70 characters limit. This adds an additional 6 characters as a buffer as ChatGPT models could still exceed the character limit even with clear instructions. Any optimised title exceeding the title length limit will be shortened at this step.</p> <p>Finally, the actual length of each title is calculated after title optimisation through a rule-based function. If any title exceeds the character limit, the state graph will be redirected back for another round of title optimisation to produce shorter titles. In subsequent rewrites, all titles will be rewritten. If all optimised titles meet the length requirements, the graph state will be directed to other optimisation nodes.</p> <p>Note</p> <p>Further development can be done to improve the effeciveness of this feedback loop by adding additional fields for feedback on shortening the titles, as well as reducing the title length limit in the prompts with each subsequent rewrite. The rule-based function could also be configured to only rewrite lengthy titles while retaining shorter ones.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#4-sample-of-the-title-optimisation-node-output","title":"4. Sample of the Title Optimisation Node output","text":"<p>An example of the output from each step of title optimisation is shown below:</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#optimised-titles-after-step-1","title":"Optimised titles after step 1","text":"<pre><code>\"\"\"1. Understanding Pneumonia: Causes, Symptoms, and Treatment Options  # 64 characters\n2. Protect Yourself: Recognizing Pneumonia Symptoms and Prevention  # 63 characters\n3. Navigate Pneumonia: Essential Insights on Causes and Care # 57 characters\"\"\"\n</code></pre>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#optimised-titles-after-step-2","title":"Optimised titles after step 2","text":"<pre><code>\"\"\"1. Understanding Pneumonia: Causes, Symptoms, and Treatments # 57 characters\n2. Protect Yourself: Recognizing Pneumonia Symptoms and Prevention  # 63 characters\n3. Navigate Pneumonia: Key Insights on Causes and Care # 51 characters\"\"\"\n</code></pre> <p>While none of the article titles from the first step exceeded the limit of 65 characters stated in the prompt, the first and third titles were still shortened in the second step.</p> <p>In the first title, the word \"Options\" was removed in the revised title, bringing down the number of characters to 57. In the third title, the word \"Essential\" was replaced with \"Key\", hence shortening the title to just 51 characters.</p> <p>In this example, it can be seen that ChatGPT models are not very accurate with counting the number of characters in a given text. Nonetheless, the feedback loop works as intended.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/title_optimisation/#5-additional-resources-for-the-title-optimisation-node","title":"5. Additional Resources for the Title Optimisation Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_title_prompt()</code> : This function returns the appropriate prompt for the title optimisation node. This function can be found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>optimise_title()</code> : This function defines the LangChain for both title optimisation steps and combines them into a single chain. This function can be found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>title_optimisation_node()</code> : This function runs <code>optimise_title()</code> and updates the graph state with the final optimised title output. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>check_optimised_titles_length()</code> : This function checks the character length of each optimised article and determines which node to send the graph state to. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>split_into_list()</code> : This is a rule-based function that takes the String output from the title optimisation as it's input. It will then return a list where each item is a title. This function can be found at <code>article-harmonisation/utils/formatters.py</code>.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/writing_guidelines_optimisation/","title":"Writing Guidelines Optimisation","text":"<p><p>Writing Guidelines Optimisation Node</p></p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/writing_guidelines_optimisation/#1-introduction","title":"1. Introduction","text":"<p>The writing guidelines optimisation node is used to rewrite the given article content in Health Hub's voice and personality guidelines. The voice and personality guidelines can be found in Health Hub's content playbook.</p> <p>The quality of the optimised writing is measured using the Hemingway readability score, wherein the output article should have a readability score less than 10.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/writing_guidelines_optimisation/#2-rationale-for-writing-guidelines-optimisation-node","title":"2. Rationale for Writing Guidelines Optimisation Node","text":"<p>Initially, article rewriting was planned to be a process handled by a single LLM agent. However, this approach did not accomodate for use cases where users may wish to only improve on the writing of an article while maintaining it's structure. Hence, the article rewriting process was split into two individual parts: content guidelines optimisation and writing guidelines optimisation.</p> <p>While the content guidelines optimisation node is primarily tasked with restructuring of the article content, the writing guidelines optimisation node is tasked with doing a complete rewrite of the article content to match HealthHub's voice and personality guide.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/writing_guidelines_optimisation/#3-flow-of-writing-guidelines-optimisation-node","title":"3. Flow of Writing Guidelines Optimisation Node","text":"<p>The writing guidelines optimisation node is a single step process where it will rewrite the article content based on the HealthHub's voice and personality guidelines.</p> <p>Below is a abbreviated sample of the guidelines in the prompt:</p> <pre><code>\"\"\"1. Welcome your readers warmly, understand their needs, and accommodate them. You should also account for diverse needs and health conditions if applicable.\nExample: \u201cLiving with diabetes doesn't mean you can\u2019t travel. With proper planning, you can still make travel plans safely.\u201d\n\n2. Ensure your writing is relevant to the visitor's needs and expectations.\nExample: \u201cWorried about new COVID-19 variants? Hear from our experts on infectious diseases and learn how you can stay safe!\u201d\n\n3. Personalize the experience for visitors with relevant content.\nExample: \u201cAre you a new mum returning to work soon? Here are some tips to help you maintain your milk supply while you work from the office.\u201d\"\"\"\n</code></pre> <p>A clear instruction along with an example is given for each guideline for the LLM agent to emulate.</p> <p>After rewriting the article content in HealthHub's voice and personality guidelines, the Hemingway readability score of the new rewritten article will be calculated and added to the graph state. If the readability score is less than 10, the graph state will move on to subsequent optimisation steps or conclude the article optimisation flow if no other optimisation steps are required. Otherwise, the graph state will be directed to the readability optimisation node.</p> <p>Do note that the limit on the maximum number of article readability rewrites is set to 3.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-generation/article-rewriting-nodes/writing_guidelines_optimisation/#4-additional-resources-for-the-writing-guidelines-optimisation-node","title":"4. Additional Resources for the Writing Guidelines Optimisation Node","text":"<p>Kindly refer to these sections for further clarification and details on the code:</p> <ul> <li> <p>@label(func) <code>return_writing_prompt()</code> : This function returns the writing prompt for the writing guidelines optimisation node. This function can found at <code>article-harmonisation/agents/prompts.py</code>.</p> </li> <li> <p>@label(func) <code>optimise_writing()</code> : This function defines the LangChain for optimising the article writing and invokes it to obtain the final optimised article writing. This function can found at <code>article-harmonisation/agents/models.py</code>.</p> </li> <li> <p>@label(func) <code>writing_guidelines_optimisation_node()</code> : This function runs <code>optimise_writing()</code> and updates the graph state with the optimised article content output. This function can found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>@label(func) <code>calculate_readability()</code>: This is a rule-based function calculates the Hemingway readability score of a given text and returns the score as an integer. This function can be found at <code>article-harmonisation/utils/evaluations.py</code></p> </li> <li> <p>@label(func) <code>check_readability_after_writing_optimisation</code>: This function is used to check the Hemingway readability score of the rewritten text. It will then decide which node to send the graph state to through some rule-based processes. This function can be found at <code>article-harmonisation/harmonisation.py</code>.</p> </li> <li> <p>HealthHub Content Playbook: This link will direct you to the Google Drive folder containing the Health Hub Content Playbook. The content playbook contains the guidelines used in the writing optimisation prompt and the writing style guides can be found in Section A from pages 5 - 11.</p> </li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/","title":"Introduction","text":"<p>The <code>Article Optimisation Checks</code> workflow focuses on evaluating articles based on their content, title and meta description. We utilise a diverse set of Rule-based, Statistical-based and LLM-based evaluations.</p> <p> The workflow is executed concurrently where the rule-based and statistical-based evaluations are executed first. This is then followed by the LLM-based evaluations where blocking calls are made to Azure OpenAI Service.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#checks","title":"Checks","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#rule-based-checks","title":"Rule-based Checks","text":"<p>Rule-based Checks have clearly defined thresholds that they must be kept within (e.g. Title Length must be within 70 characters). These checks are typically stored in the <code>flag</code> parameter within the LangGraph Schema.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#statistical-based-checks","title":"Statistical-based Checks","text":"<p>Statistical-based Checks have thresholds that are defined either by an equation (e.g. Hemmingway Score) or by exploring the distribution of the article's properties (e.g. Word Count).</p> <p>When the thresholds are very explicit (e.g. Below the 25<sup>th</sup> percentile of the Word Count Distribution), these checks are only stored in the <code>flag</code> parameter within the LangGraph Schema. However, the thresholds are not explainable (e.g. Readability), the article is submitted to an explainer that explains the evaluation. This is stored in the <code>judge</code> parameter of the LangGraph Schema.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#llm-based-checks","title":"LLM-based Checks","text":"<p>LLM-based Checks are composed of 3 key components - Evaluation, Decision and Summarisation. This is to ensure that the LLM focuses on one key objective at a time, thus lowering the likelihood of hallucinations.</p> <pre><code>\n    flowchart TD\n    article_inputs[&lt;b&gt;Article Inputs&lt;b&gt;] --&gt; evaluation(Evaluation)\n    evaluation --&gt; decision(Decision)\n    decision --&gt; |False| _end[End]\n    decision --&gt; |True| summarisation[Summarisation]\n    summarisation --&gt; _end\n\n    style article_inputs fill:#db8e02, color:#02075D, rx:20,ry:20\n    style evaluation fill:#F16E80,color:#fff\n    style decision fill:#2D9BF0,color:#fff\n    style _end fill: color:#5A5A5A, rx:30, ry:30\n    style summarisation fill:#BE88C6, color:#fff, rx:10, ry:10\n</code></pre>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#evaluation","title":"Evaluation","text":"<p>The Evaluation component mainly focuses on critiquing the article based on the key criteria provided. All criteria must be stated here. In most cases, the generated critique is long and verbose. However, this is very useful as this evaluation is passed downstream for the LLM to decide whether the article needs to be optimised.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#decision","title":"Decision","text":"<p>The Decision component is solely focused on deciding whether the article needs to be optimised based on the generated evaluation. It should only output either True or False (boolean) as a <code>decision</code> unless the Azure Content Filter has been triggered (The output should be None in this case). If flagged as True, the article evaluation will be passed for summarisation. Otherwise, the outputs are returned from the chain.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#summarisation","title":"Summarisation","text":"<p>The Summarisation component is only triggered when the Decision component outputs a True flag. The summarisation component focuses on summarising the verbose evaluation into 3 to 5 sentences. It is meant to be the <code>explanation</code> of the decision made.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#notes","title":"Notes","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#implementing-new-agents","title":"Implementing new Agents","text":"<ol> <li>Add in the new agent roles at <code>agents/enums.py</code></li> <li>Implement your new prompt at <code>agents/prompts.py</code></li> <li>Implement the new evaluation chain at <code>agents/models.py</code></li> <li>Define your new state schema at <code>states/definitions.py</code></li> <li>Integrate the new evaluations and their corresponding states into the LangGraph workflow at <code>checks.py</code></li> </ol> <p>After making these changes, you can run the <code>checks.py</code>. Refer to this <code>section</code> to better understand how to setup the Optimisation Checks Workflow.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#azure-ai-content-safety","title":"Azure AI Content Safety","text":"<p>There are times when a selected article may be blocked from LLM generation as it is flagged by the Azure AI Content Filter. As a result, you would be unable to generate the evaluation. Refer to this link to explore the harm categories which triggers the content filter.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#rate-limits","title":"Rate Limits","text":"<p>There are times when the rate limits imposed on the Azure OpenAI Service Deployments impacts the article Optimisation Checks. This is usually either due to the quota limits (most likely) or the request limits placed on the Deployment.</p> <p>To resolve this, you will need to ask the Account Manager (i.e. the person who manages the Resource Groups in the team) to increase the request or quota limits on the deployment.</p> <p>Note</p> <p>The current Azure Account Manager is Wilsven. Reach out to him to increase your quota or rate limits on the Deployment. These changes take some time to be reflected on the endpoint.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#slow-generation","title":"Slow Generation","text":"<p>The LLM generation typically takes a long time during Office Hours. My hypothesis is that the Azure OpenAI Service is being heavily consumed, resulting in slower response times. However, I am unsure whether it is <code>model-specific</code> (i.e. multiple organisations using the same model instance) or <code>group-specific</code> (i.e. multiple members using the same model deployment).</p> <p>I would recommend running this script after Office Hours for faster generation. Otherwise, run this script in a separate terminal session and work on other tasks instead. Occasionally, check on the progress of the Optimisation Checks workflow. You may run into exceptions or deadlocks.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#handling-exceptions","title":"Handling Exceptions","text":"<p>Sometimes, when running <code>checks.py</code>, you may encounter various exceptions. So far, there are 2 main exceptions - Content Filters and Deadlocks.</p> <p>However, other exceptions will be handled by the process and enter a graceful shutdown procedure. The procedure includes saving the past optimisation checks in a new parquet file called <code>agentic_response_*.parquet</code> in the <code>data/optimization_checks</code> directory. The <code>*</code> in the parquet file will be the timestamp <code>YYYY-MM-DD HH-MM-SS</code> at which the file was generated. We utilise the Apache Parquet format as the files are immutable.</p> <p>To avoid running into exceptions deterministically, the order of the articles are shuffled. The idea is to push these problematic articles back so that the other articles can be evaluated.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#content-filters","title":"Content Filters","text":"<p>When the Azure OpenAI service triggers a content filter, a <code>ValueError</code> exception is raised. A keyphrase search is first performed (<code>\"content filter being triggered\"</code>) to verify whether the Azure AI Content Filter has been triggered. Once verified, the LLM checks will be turned off and the article is resubmitted for only rule-based checks.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/#deadlocks","title":"Deadlocks","text":"<p>Sometimes, the Optimisation Checks workflow can run into a deadlock. These are the possible reasons -</p> <ol> <li>The <code>EVALUATOR</code> and <code>EXPLAINER</code> Agents are shared across all types of checks (<code>content</code>, <code>title</code> and <code>meta description</code>).</li> <li>The <code>AzureChatOpenAI</code> class is making a blocking call (i.e. a synchronous HTTP request) to the Azure OpenAI Service. Hence, the resource must be freed before being used for the next task. Refer to this link and search <code>async</code> on this page to run the chains asynchronously.</li> <li>There is a bug in the LangGraph workflow when performing concurrent execution as the current implementation is synchronous. Refer to this link to run the graph asynchronously.</li> </ol> <p>Otherwise, you can simply monitor the execution of the <code>checks.py</code> script. If <code>stdout</code> (i.e. outputs printed in the terminal) has not changed for at least 4 minutes, you can perform a <code>Keyboard Interrupt</code> (i.e. <code>Ctrl + C</code> in the terminal session) to end the process.</p> <p>The <code>Keyboard Interrupt</code> will trigger a graceful shutdown. Once you have performed a successful interrupt, you can rerun the script again. The evaluations will continue for the remaining articles.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/content/","title":"Content Evaluation","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/content/#content-flags-rule-based","title":"Content Flags (Rule-based)","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/content/#readability","title":"Readability","text":"<p>To assess the readability score of the article, we utilised a similar scoring mechanism as the Hemmingway Editor. We reverse-engineered the scoring function using this article from medium.</p> Hemmingway Score (H) <p>H = Math.round(4.71 * average word length + 0.5 * average sentence length - 21.43)</p> <p>However, we had to amend the function slightly due to the presence of URL links and the breaking up of sentence during parsing. We used <code>Math.ceil()</code> instead to resolve these issues. If the Hemmingway score is at least 10, it is considered <code>hard</code> to read. These articles are then passed to an LLM to explain why the article is <code>hard</code> to read.</p> <p>For a better understanding of the scoring function, refer to <code>utils/evaluations.py</code>.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/content/#insufficient-content","title":"Insufficient Content","text":"<p>To assess whether the article has sufficient content, we used word as a proxy indicator. Our focus is on these five content categories (<code>\"cost-and-financing\"</code>,<code>\"live-healthy-articles\"</code>, <code>\"diseases-and-conditions\"</code>, <code>\"medical-care-and-facilities\"</code>, <code>\"support-group-and-others\"</code>).</p> <p>We first plotted a box plot to obtain the distribution of the article word counts across these content categories from all content providers. From there, we decided that the lower quartile (i.e. 25<sup>th</sup> percentile) can serve a good threshold to flag insufficient content.</p> Word Count Thresholds <ul> <li>\"cost-and-financing\": 267</li> <li>\"live-healthy-articles\": 413</li> <li>\"diseases-and-conditions\": 368</li> <li>\"medical-care-and-facilities\": 202</li> <li>\"support-group-and-others\": 213</li> </ul>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/content/#content-judge-llm-based","title":"Content Judge (LLM-based)","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/content/#writing-style","title":"Writing Style","text":"<p>Warning</p> <p>The Writing Style Evaluation has been deprecated as its current implementation results in all articles being flagged for optimisation. While removing it is a stopgap measure, the long-term goal is to refine the prompts (i.e. using Decomposed Prompting) so that the content evaluations are more targeted.</p> <p>The Writing Style (structure) evaluation assesses the content structure across 5 key dimensions - Opening, Content Structure, Writing Style, Closing and Overall Effectiveness.</p> <pre><code>1. Opening\n\n   - Evaluates the clarity and effectiveness of the introduction\n\n2. Content Structure\n\n   - Evaluates the organisation of the content\n   - Evaluates whether the paragraphs are succinct and easy to read\n\n3. Writing Style\n\n   - Evaluates whether the tone is conversational\n   - Evaluates whether complicated terms were used for its intended audience\n   - Evaluates whether the content is relatable\n\n4. Closing\n\n   - Evaluates whether the next steps are clearly outlined\n   - Evaluates whether the message is clearly reinforced\n\n5. Overall Effectiveness\n\n   - Evaluates whether the article insights are actionable\n   - Evaluates whether the main content fulfills the promise made in the introduction\n</code></pre> <p>As the Writing Style Evaluation is an LLM-based check, we follow the same structure (<code>Evaluation -&gt; Decision -&gt; Summarisation</code>) as mentioned here.</p> <p>Refer to the <code>structure_evaluation_prompt</code> function in <code>agents/prompts.py</code> to understand the exact criteria used to evaluate the article content.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/meta-description/","title":"Meta Description Evaluation","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/meta-description/#meta-description-flags-rule-based","title":"Meta Description Flags (Rule-based)","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/meta-description/#meta-description-length","title":"Meta Description Length","text":"<p>The length of the article meta description must be within 70 and 160 characters. This is a requirement for storing purposes.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/meta-description/#meta-description-judge-llm-based","title":"Meta Description Judge (LLM-based)","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/meta-description/#meta-description-relevance","title":"Meta Description Relevance","text":"<p>The meta description evaluation assesses the relevance of the meta description with respect to its content. It performs the following steps -</p> <pre><code>1. Identify the Meta Description\n\n    - What is the meta description of the article?\n\n2. Analyse the Meta Description\n\n    - What is the main topic conveyed?\n    - Is the meta description clear, concise and engaging?\n\n3. Review the Content\n\n    - Summarise and Review the article\n\n4. Compare the Meta Description to the Content\n\n    - Does the content directly address the main topic of the meta description?\n    - Is the message and theme consistent between the content and meta description?\n    - Any missing information not reflected in the meta description?\n\n5. Evaluate Relevance\n\n    - Explain the relevance of the meta description and content\n    - Any discrepancies\n</code></pre> <p>As the Meta Description Evaluation is an LLM-based check, we follow the same structure (<code>Evaluation -&gt; Decision -&gt; Summarisation</code>) as mentioned here.</p> <p>Refer to the <code>meta_desc_evaluation_prompt</code> function in <code>agents/prompts.py</code> to understand the exact criteria used to evaluate the article meta description.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/title/","title":"Title Evaluation","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/title/#title-flags-rule-based","title":"Title Flags (Rule-based)","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/title/#title-length","title":"Title Length","text":"<p>The length of the article title must not exceed 70 characters. This is a requirement for storing purposes.</p>"},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/title/#title-judge-llm-based","title":"Title Judge (LLM-based)","text":""},{"location":"projects/genai/health-hub/content-opt-and-harm/article-opt-check/nodes/title/#title-relevance","title":"Title Relevance","text":"<p>The title evaluation assesses the relevance of the title with respect to its content. It performs the following steps -</p> <pre><code>1. Identify the Title\n\n   - What is the title of the article?\n\n2. Analyse the Title\n\n   - What is the main topic conveyed?\n   - Is the title clear and specific?\n\n3. Review the Content\n\n   - Summarise and Review the article\n\n4. Compare the Title to the Content\n\n   - Does the content directly address the main topic of the title?\n   - Is the message and theme consistent between the content and title?\n   - Any missing information not reflected in the title?\n\n5. Evaluate Relevance\n\n   - Explain the relevance of the title and content\n   - Any discrepancies\n</code></pre> <p>As the Title Evaluation is an LLM-based check, we follow the same structure (<code>Evaluation -&gt; Decision -&gt; Summarisation</code>) as mentioned here.</p> <p>Refer to the <code>title_evaluation_prompt</code> function in <code>agents/prompts.py</code> to understand the exact criteria used to evaluate the article title.</p>"},{"location":"projects/genai/health-hub/data-pipeline/","title":"Data Pipeline","text":""},{"location":"projects/genai/health-hub/data-pipeline/#kedro","title":"Kedro","text":"<p>Kedro is an open-source framework to create maintainable and modular data science pipelines. We are using kedro version <code>0.19.6</code> in our data pipelines. These pipelines are stored in the <code>content-optimization</code> directory. You can refer to the Get Started guide for more information.</p> <p>Before running or editing the Kedro pipeline, it is recommended to install the project in the <code>content-optimization</code> directory -</p> <pre><code># Install the Kedro Project\npip install -e .\n</code></pre> <p>This is important so that your Integrated Development Environment (IDE) can properly index the imports in your scripts.</p>"},{"location":"projects/genai/health-hub/data-pipeline/#key-concepts","title":"Key Concepts","text":""},{"location":"projects/genai/health-hub/data-pipeline/#nodes","title":"Nodes","text":"<p>A node is a wrapper for a Python function to execute your data transformations. It is the building block of a pipeline. In your nodes, you should define your function used, name of inputs as well as outputs, and the name of your node. You can refer to this link for more information.</p>"},{"location":"projects/genai/health-hub/data-pipeline/#pipelines","title":"Pipelines","text":"<p>A pipeline organises the dependencies and execution order of a collection of nodes and connects inputs and outputs while keeping your code modular. The pipeline determines the node execution order by resolving dependencies and does not necessarily run the nodes in the order in which they are passed in. You can refer to this link for more information.</p>"},{"location":"projects/genai/health-hub/data-pipeline/#data-catalog","title":"Data Catalog","text":"<p>The Kedro Data Catalog is the registry of all data sources that the project can use to manage loading and saving data. It maps the names of node inputs and outputs as keys in a DataCatalog, a Kedro class that can be specialised for different types of data storage. Kedro provides different built-in datasets for numerous file types and file systems, so you don\u2019t have to write the logic for reading/writing data. You can refer to this link for more information.</p>"},{"location":"projects/genai/health-hub/data-pipeline/#parameters","title":"Parameters","text":"<p>Project parameters make your Kedro pipelines more flexible and easier to configure, since you can change the behaviour of your nodes. By default, in a new Kedro project, parameters are defined in the parameters.yml file, which is located in the project\u2019s conf/base directory. This file contains a dictionary of key-value pairs, where each key is a parameter name and each value is the corresponding parameter value. These parameters can serve as input to nodes and are used when running the pipeline. You can refer to this link for more information.</p>"},{"location":"projects/genai/health-hub/data-pipeline/#datasets","title":"Datasets","text":"<p><code>kedro-datasets</code> is a library that define all the available data connectors that can be integrated into the Kedro Pipeline. You would typically defined in the Data Catalog. You can refer to this link for the available data connectors.</p>"},{"location":"projects/genai/health-hub/data-pipeline/#visualisations","title":"Visualisations","text":"<p>Kedro-Viz is an interactive development tool for visualising data science pipelines built with Kedro. This is extremely useful for understanding how the data flows from node to node in your pipeline. You can refer to this link for more information.</p>"},{"location":"projects/genai/health-hub/data-pipeline/#tests","title":"Tests","text":"<p>Writing tests is extremely crucial to ensuring the robustness of your Kedro pipelines. You can setup automated testing using the <code>pytest</code> framework. You can refer to this link for more information.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/","title":"Azure RAG Data Processing","text":""},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/#introduction","title":"Introduction","text":"<p>Our primary goal is to prepare the data (in JSON format) for the article ingestion in Microsoft Azure Search Index. The pipeline is branched out from the merged node in <code>data_processing</code>, and it converts the post processed parquet file into individual JSON file for each article. This enables the article content to be ingested into the search index for context retrieval in the Retrieval Augmented Generation (RAG) process for the app.</p> <p>In this pipeline, we focus on the following:</p> <ol> <li>Filtering the articles according to their <code>remove_type</code>.</li> <li>Process the <code>content_body</code> column into the new <code>processed_table_content</code> for articles with tables.</li> <li>Extracting the content and their table content from the parquet file into individual JSON files.</li> </ol>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/#setting-up-the-project","title":"Setting up the Project","text":"<ol> <li>No additional files required for this pipeline.</li> <li>Refer to the <code>README.md</code> to setup and run the Kedro Pipeline.</li> </ol> <p>Note</p> <p>We are interested in running the <code>azure_rag</code> pipeline. To do so, run the following command after setting up the virtual environment and its dependencies - <pre><code>cd content-optimization\n# Run the data processing pipeline to get the merged data\nkedro run --pipeline=\"data_processing\"\n# Run the azure_rag pipeline to process the merged data\nkedro run --pipeline=\"azure_rag\"\n</code></pre></p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/#adding-new-kedro-nodes","title":"Adding new Kedro nodes","text":"<p>When adding new kedro nodes, it is important to understand the key processes that accompany it. You will usually add the filepath(s) to the Data Catalog, supplement the required parameters and write your functions.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/#data-catalog","title":"<code>Data Catalog</code>","text":"<p>The Data Catalog is one of the most important files in the Kedro Pipeline. It indicates where your files are located in the project. Kedro handles the loading and saving of data on your behalf. You do not need to specify it in your nodes.</p> <p>Here is an example of how to define it:</p> <pre><code># Variable Name/Dictionary Key\nfiltered_data_rag:\n  # File Type - Refer to kedro-datasets (https://docs.kedro.org/projects/kedro-datasets/en/kedro-datasets-4.1.0/api/kedro_datasets.html) for the appropriate data connector\n  type: pandas.ParquetDataset\n  # File Path - Indicate where to save/load the desired file\n  filepath: data/03_primary/filtered_data.parquet\n  # Data Versioning - Indicate whether you want to only obtain the latest file or track the changes (via timestamp)\n  versioned: true\n</code></pre> <p>Once you have defined your variables, you can use them in your Kedro pipeline.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/#parameters","title":"<code>Parameters</code>","text":"<p>The Parameters are used to store any static definition of variables in the Kedro Pipeline. Each Pipeline has its own set of parameters. We do not hardcode any values in the code. We retrieve it from this file.</p> <p>Here is an example of the defining the duplicated article ids to filter out:</p> <pre><code># Parameter for the function in nodes.py and pipeline.py\nduplicated_articles:\n  # List defining the article ids that we are interested in\n  - 1445629\n  - 1443608\n  - 1435183\n  - 1435335\n  - 1434652\n</code></pre> <p>After defining your data variables and the parameters required for your function, we can proceed to the writing our function.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/#nodes","title":"<code>Nodes</code>","text":"<p>Here is where we define our functions to transform our data. A node is merely a step within the Kedro Pipeline that performs a set of transformations. When writing your node functions, you should do the following -</p> <ol> <li>Name your node as an <code>action</code> (i.e. it should start with a verb).</li> <li>Keep your implementation succinct. If your function requires a multiple functions or has a long implementation, you should consider creating a new Python file and import the main function over to <code>nodes.py</code>.</li> <li>Ensure that your input and output variables can be found either in your Data Catalog <code>catalog.yml</code> or Parameters <code>parameters_data_processing.yml</code>. We prefer to use the same variable names as defined in these configuration files for better clarity.</li> </ol> <p>Once we have created the node(s), we can now integrate them into the Kedro Pipeline.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/#pipeline","title":"<code>Pipeline</code>","text":"<p>This is the easiest part of the Kedro pipeline. To integrate the new node, just add a new node function to the pipeline.</p> <p>Warning</p> <p>The nodes in the Kedro pipeline are ordered. Do not mess the order of these nodes as we are generating the files dynamically from the input files. Each node function has dependencies that are generated by preceding nodes.</p> <p>Here is an example:</p> <pre><code>def create_pipeline(**kwargs) -&gt; Pipeline:\n    return pipeline(\n        [\n            node(\n                func=filter_articles,\n                inputs=[\n                    \"merged_data\",\n                    \"params:duplicated_articles\",\n                    \"params:duplicated_content\",\n                    \"params:lengthy_articles\",\n                ],\n                outputs=\"filtered_data_rag\",\n                name=\"filter_articles_node\",\n            ),\n            node(\n                func=process_html_tables,\n                inputs=[\n                    \"filtered_data_rag\",\n                    \"params:temperature\",\n                    \"params:max_tokens\",\n                    \"params:n_completions\",\n                    \"params:seed\",\n                ],\n                outputs=\"processed_data_rag\",\n                name=\"process_html_tables_node\",\n            ),\n            node(\n                func=extract_content,\n                inputs=[\n                    \"processed_data_rag\",\n                    \"params:article_content_columns\",\n                    \"params:table_content_columns\",\n                ],\n                outputs=\"json_data_rag\",\n                name=\"extract_content_node\",\n            ),\n        ]\n    )\n</code></pre> <p>Note</p> <p>The data generated from this pipeline is not final, you will have to combine the JSON files generated from this pipeline and the <code>two Javascript articles</code> to ingest into the search index.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/","title":"Filtered Articles for Removal","text":""},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#overview","title":"Overview","text":"<p>Based on our Exploratory Data Analysis and requests from the HealthHub Team, we had to filter some articles to be removed from downstream applications.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#filter-before-extraction","title":"Filter Before Extraction","text":""},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#nan-content-in-content_body","title":"NaN Content in <code>content_body</code>","text":"<p>There is no HTML content present for extraction is the content is null.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#no-html-tags","title":"No HTML Tags","text":"<p>This typically occurs when test articles that are submitted into the VML system for testing purposes.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#no-extracted-content","title":"No Extracted Content","text":"<p>This typically occurs when there are only HTML tags present in the content body. As such, the extracted content is null. This is usually because the article is an infographic.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#duplicated-content","title":"Duplicated Content","text":"<p>We remove duplicated content based on the <code>extracted_content_body</code>. There is a high chance that it refers to the same article or that the article link has been updated.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#duplicated-urls","title":"Duplicated URLs","text":"<p>We remove duplicated content based on the <code>full_url</code>. There is a high chance that it refers to the same article or the article content has been updated.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/filtered_articles_for_removal/#multilingual-content","title":"Multilingual Content","text":"<p>We remove Chinese, Malay or Tamil articles as we do not want it to interfere with the clustering algorithm. Moreover, there are future plans to implement a translation process to convert all English articles into Chinese, Malay and Tamil.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/js_articles/","title":"Extract Article Content from the JavaScript Columns for Programs and Program-Sub-Pages","text":""},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/js_articles/#overview","title":"Overview","text":"<p>In response to the needs of the HealthHub Team, we have expanded our extraction process to include content from the JavaScript-based columns. These columns contain crucial article information found on the \u201cprograms\u201d and \u201cprogram-sub-pages\u201d articles that are not in the HTML file. By parsing and extracting content from these sources, we ensure comprehensive coverage of the article data for downstream applications.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/js_articles/#approach","title":"Approach","text":"<p>To extract content from the JavaScript columns, we implemented a two-step process:</p> <ol> <li> <p>JavaScript Parsing: We extract and clean the HTML structure dynamically generated by JavaScript. This ensures that hidden content is included in the data pipeline.</p> </li> <li> <p>Content Extraction: Once the JavaScript elements are parsed, we extract the relevant text, ensuring that the content retains its structure and meaning, much like the regular HTML extraction process.</p> </li> </ol> <p>For more details on the implementation and code, refer to the notebooks here: <code>IQuit.ipynb</code> and <code>vaccinate.ipynb</code></p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/extract_content/","title":"@label(func) <code>extract_content</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/extract_content/#overview","title":"Overview","text":"<p>The <code>Extract Content</code> node extracts and organizes content and table data from <code>processed_data_rag</code> dataframe into a dictionary format that will be partitioned into individual JSON files that represents each article.</p> <p>This function takes in the <code>processed_data_rag</code> dataframe, the <code>article_content_columns</code>, and <code>table_content_columns</code> parameters. It extracts and organized the article data by performing the following steps:</p> <ol> <li>Initializes an empty dictionary <code>json_data_rag</code> to store extracted data.</li> <li>Iterates over each row in the DataFrame using iterrows(), identifying the row by its \u201cid\u201d column.</li> <li>Extracts content columns specified in <code>article_content_columns</code>, checks for the presence of tables (has_table column), and processes the article\u2019s content by removing the <code>has_table</code> column and converting the <code>extracted_content_body</code> to a string format.</li> <li>Appends the processed content to the dictionary using a unique key generated from the row\u2019s <code>id</code> with the suffix <code>_content</code>.</li> <li>If a table is present (has_table is true), the function extracts and processes the table columns specified in <code>table_content_columns</code>, converting the <code>processed_table_content</code> to a string format.</li> <li>Appends the processed table data to the dictionary using a unique key generated from the row\u2019s <code>id</code> with the suffix <code>_table</code>.</li> <li>Returns the json_data_rag dictionary containing both content and table data for each row.</li> </ol> <p>The function returns a dictionary that will be split into individual JSON articles by Kedro PartitionDataset.</p> <pre><code>def extract_content(\n    processed_data_rag: pd.DataFrame,\n    article_content_columns: List[str],\n    table_content_columns: List[str],\n) -&gt; Dict[str, List[Dict[str, Any]]]:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/extract_content/#parameters","title":"Parameters","text":"<code>article_content_columns</code> (<code>List[str]</code>): A list of strings of the columns to be extracted to prepare the articles content JSON. Refer to the Data Catalog for more information. <code>table_content_columns</code> (<code>List[str]</code>): A list of strings of the columns to be extracted to prepare the articles table content JSON. Refer to the Data Catalog for more information."},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/extract_content/#returns","title":"Returns","text":"<code>json_data_rag</code>: Returns a dictionary that will be split into individual JSON articles by Kedro PartitionDataset. The JSON files are saved at <code>data/03_primary/processed_articles</code>. Refer to the <code>json_data_rag</code> key in the Data Catalog <p>Note</p> <p>The data generated from this pipeline is not final, you will have to combine the JSON files generated from this pipeline and the <code>two Javascript articles</code> to ingest into the search index.</p>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/filter_articles/","title":"@label(func) <code>filter_articles</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/filter_articles/#overview","title":"Overview","text":"<p>The <code>Filter Articles</code> node filter out the articles that have <code>No HTML Tags</code>, <code>No Extracted Content</code>, <code>NaN</code>, <code>Multilingual</code>, <code>Duplicated Content</code> from <code>remove_type</code> column. It also removes duplicated articles with specific 'id' values and articles that are too lengthy to be processed by the LLM.</p> <p>The link to the article <code>id</code> that are filtered for removal are in this file: <code>To remove excel sheet</code>. The <code>id</code> values for the <code>duplicated_articles</code> refers to the <code>To_use_duplicated_URL_to_keep</code> tab and <code>duplicated_content</code> refers to the <code>duplicated_content_to_keep</code> tab in the excel.</p> <p>This function takes in the <code>merged_data</code> dataframe, the <code>duplicated_articles</code>, <code>duplicated_content</code>, and <code>lengthy_articles</code> parameters. It filters out the articles by performing the following steps:</p> <ol> <li>Remove articles with 'No HTML Tags' from the 'remove_type' column.</li> <li>Remove the rows with 'No Extracted Content' from 'remove_type' column.</li> <li>Remove the rows with 'NaN' from 'remove_type' column.</li> <li>Remove 'Multilingual' from 'remove_type' column.</li> <li>Remove the duplicated articles with specific 'id' values.</li> <li>Remove 'Duplicated Content' from 'remove_type' column, except for specific 'id' values.</li> <li>Remove the articles that are too lengthy for the LLM to process.</li> </ol> <p>The function returns a dataframe for further processing.</p> <pre><code>def filter_articles(\n    merged_data: pd.DataFrame,\n    duplicated_articles: List[int],\n    duplicated_content: List[int],\n    lengthy_articles: List[int],\n) -&gt; pd.DataFrame:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/filter_articles/#parameters","title":"Parameters","text":"<code>duplicated_articles</code> (<code>List[int]</code>): A list of integers where it contains the <code>id</code> of the articles that have duplicated URLs. Refer to the Data Catalog for more information. <code>duplicated_content</code> (<code>List[int]</code>): A list of integers where it contains the <code>id</code> of the articles that have duplicated content. Refer to the Data Catalog for more information. <code>lengthy_articles</code> (<code>List[int]</code>): A list of integers where it contains the <code>id</code> of the articles that are too lengthy to be processed by the LLM. Refer to the Data Catalog for more information."},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/filter_articles/#returns","title":"Returns","text":"<code>filtered_data_rag</code>: Returns a parquet files that have filtered out the articles. The file is saved at <code>data/03_primary/filtered_data.parquet</code>. Refer to the <code>filtered_data_rag</code> key in the Data Catalog"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/process_html_tables/","title":"@label(func) <code>process_html_tables</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/process_html_tables/#overview","title":"Overview","text":"<p>The <code>Process HTML Tables</code> node uses LLM to process the <code>content_body</code> column into a new <code>processed_table_content</code> column. The <code>processed_table_content</code> column is the content of the tables from the articles to be processed as separate documents to be ingested into the search index.</p> <p>This function takes in the <code>filtered_data_rag</code> dataframe, the <code>temperature</code>, <code>max_tokens</code>, <code>seed</code>, and <code>n_completions</code> parameters. It process the table content in HTML format by performing the following steps:</p> <ol> <li>Extracts the raw HTML from the 'content_body' column</li> <li>Take in the raw HTML and pass it to the LLM to extract the table content in markdown format in a readable string.</li> <li>Creates a new column <code>processed_table_content</code> to insert the response generated by the LLM.</li> </ol> <p>The function returns a dataframe for further processing.</p> <pre><code>def process_html_tables(\n    filtered_data_rag: pd.DataFrame,\n    temperature: int,\n    max_tokens: int,\n    n_completions: int,\n    seed: int,\n) -&gt; pd.DataFrame:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/process_html_tables/#parameters","title":"Parameters","text":"<code>temperature</code> (<code>int</code>): This variable controls the randomness of the model\u2019s output, with lower values making the output more deterministic and higher values adding more variability. Refer to the Data Catalog for more information. <code>max_tokens</code> (<code>int</code>): This specifies the maximum number of tokens (words or word-parts) that the model can generate in its response. Refer to the Data Catalog for more information. <code>n_completions</code> (<code>int</code>): This determines how many completions or outputs the model should generate in response to a given prompt. Refer to the Data Catalog for more information. <code>seed</code> (<code>int</code>): This variable is used to initialize the random number generator, ensuring that the model\u2019s behavior is reproducible when the same seed is used. Refer to the Data Catalog for more information."},{"location":"projects/genai/health-hub/data-pipeline/azure_rag/nodes/process_html_tables/#returns","title":"Returns","text":"<code>processed_data_rag</code>: Returns a parquet files that have processed the table content of the articles. The file is saved at <code>data/03_primary/processed_data.parquet</code>. Refer to the <code>processed_data_rag</code> key in the Data Catalog"},{"location":"projects/genai/health-hub/data-pipeline/clustering/","title":"Introduction","text":"<p>Our primary goal is to reduce the workload associated with the manual review process by presenting groups of similar articles. This enables easier annotation, helping to determine which articles should be removed, harmonized, or optimized. This work lays the foundation for future content optimization and harmonization.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/#workflow","title":"Workflow","text":"<p> The initial layer of our clustering approach employs graph-based methods to form preliminary groupings of related articles. This is achieved by leveraging the similarities in various article features, such as content body, article titles, and meta descriptions provided in the dataset.</p> <p> Following this, the second level of clustering utilises BERTopic to further refine the larger-sized clusters output from the first level of clustering. This additional step is necessary as the first level of clustering still produces clusters with number of articles ranging from 11 to 70, which are too large and not optimal for user review. By performing the second level of clustering, we aim to create more specific and smaller cluster. In this step, keywords are also generated to represent each cluster's content.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/#exploration","title":"Exploration","text":"<p>Various techniques were evaluated in the first level of clustering. The experimentation focused on different embedding techniques, multi-feature clustering methodologies, and feature selection to determine the most effective approach for clustering related articles.</p> <p>The image below summarizes the key findings and decisions made during this experimentation process:  Based on these findings, the selected approach for the first level of clustering is the <code>nomic-embed-text-v1.5 model</code>, utilizing weighted embeddings with a weighting scheme of 0.7 for content body and 0.3 for title. This method has been shown to generate more accurate and manageable clusters for user review.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/","title":"Embedding Techniques","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#introduction","title":"Introduction","text":"<p>Ablation studies were conducted to choose the best embedding method to generate document embeddings to best represent each article. First, we evaluate the effectiveness of different pooling strategies and embedding models for generating document representations. We focused on comparing mean pooling and max pooling, which are two prevalent methods for aggregating a sequence of embeddings into a fixed-length vector. Mean pooling averages the values across embeddings to capture a balanced representation, while max pooling selects the highest values to highlight prominent features. This analysis was performed using three Sentence-BERT models on a subset of data, and the results revealed that mean pooling generally produced superior document representations.</p> <p>Following this, we expanded our investigation to include various embedding methods, encompassing both neural network-based and statistical vector-based approaches. The performance of these methods was assessed through quantitative metrics such as V-measure and median difference, as well as qualitative evaluations of clustering outputs, to assess their effectiveness in capturing semantic meaning and the quality of the clustering results.</p> <p>The HH team and its agency had a prior content optimisation exercise to annotate articles for combine and rewrite. The exercise was conducted manually, and was documented in an excel file which is used as a point of reference for the study below.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#ablation-study-on-pooling-strategy","title":"Ablation Study on Pooling Strategy","text":"<p>First, an ablation study on pooling strategy was conducted to identify the best method to convert a sequence of embeddings into a single fixed-length representation of each article. In the context of embeddings, mean pooling and max pooling are two common strategies used to aggregate a set of embeddings (typically vectors) into a single embedding that represents a larger text segment or document.</p> <p>Mean pooling computes the average value for each dimension of the embeddings across all the input vectors. Max pooling selects the maximum value for each dimension of the embeddings across all the input vectors. When applying these pooling strategies to embeddings, the choice between mean and max pooling depends on the specific use case and the nature of the text data:</p> <ul> <li>Mean Pooling: Suitable for obtaining a balanced and overall representation of the text, capturing the general meaning by averaging out variations. It\u2019s useful when the goal is to represent the entire text uniformly without emphasizing any particular part.</li> <li>Max Pooling: Suitable for scenarios where capturing the most salient or important features is crucial. It\u2019s useful when key information is expected to be reflected in the highest values of the embeddings, making it effective for tasks where the most significant aspects need to be highlighted.</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#pooling-strategy-evaluation-methodology","title":"Pooling Strategy: Evaluation Methodology","text":"<p>In the ablation study, mean and max pooling strategies were evaluated using 3 Sentence Bert models (<code>all-MiniLM-L6-v2</code>, <code>all-mpnet-base-v2</code>, <code>msmarco-bert-base-dot-v5</code>) on a subset of the reference excel file provided by HH team (20 articles). 20 x 20 confusion matrices (heatmaps) were generated and evaluated. The figure below shows an example output using <code>msmarco-bert-base-dot-v5</code> embeddings with mean pooling. The colour-coded text on each axis signifies that article titles of the same colour belong to a single group of similar articles. Ideally, confusion matrixes should form along the diagonal axis in lighter colours (signifying high correlation), while the areas away from the diagonal line should be as dark as possible (signifying low correlation).</p> <p></p> <p>Confusion Matrix / Heat Map generated from Dot Product Similarity between documents on <code>msmarco-bert-base-dot-v5</code> embeddings with mean pooling.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#pooling-strategy-results","title":"Pooling Strategy: Results","text":"<p>A summary of the results are documented as follows:</p> SBERT / Pooling Strategy Max Pooling Mean Pooling <code>all-MiniLM-L6-v2</code> \u2022 From the confusion matrix heatmap, the similarity distribution seems to be mostly even (a lot of values are in the 0.4 - 0.6 range).  \u2022This makes distinct clusters (along the diagonal) harder to discern (only clusters at the bottom right-hand corner of the confusion matrix can be spotted clearly). \u2022 Similarity distribution seems bimodal with the higher similarities lying on the diagonal axis of the confusion matrix heat map and lower similarities in other areas.  \u2022 This would suggest a more effective clustering of similar documents together. <code>all-mpnet-base-v2</code> \u2022Same as <code>all-MiniLM-L6-v2</code> using max pooling however, clusters along the diagonal are slightly more obvious.  \u2022 This would suggest that the <code>all-mpnet-base-v2</code> is a better sentence embedding model should max pooling be the aggregation strategy used. \u2022 Results are very similar to <code>all-MiniLM-L6-v2</code> using mean pooling. In that case, it would be wise to select the model with the smaller memory footprint (i.e. <code>all-MiniLM-L6-v2</code> which is 5 times smaller) <code>msmarco-bert-base-dot-v5</code> \u2022 Comparison results between max and mean pooling for this model seem to hold as well \u2014 mean pooling proved to be the better aggregation operation. \u2022 Comparison results between max and mean pooling for this model seem to hold as well \u2014 mean pooling proved to be the better aggregation operation. <p>In this ablation study, we have compared two pooling strategies and results have shown that mean pooling generates better document representations than max pooling.</p> <p>This means that after mean pooling aggregated across all the chunk embeddings into a single document embedding, this document embedding better encapsulates the meaning and semantic of the document/article than if we had used max pooling.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#ablation-study-on-embedding-models","title":"Ablation Study on Embedding Models","text":"<p>Neural network-based and statistical vector-based embedding methods are two different approaches for representing words or other textual data as vectors in a continuous vector space. These embeddings are used in various natural language processing (NLP) tasks to capture the semantic meaning of words and phrases.</p> <ul> <li>Neural network-based embedding methods use neural networks to learn dense, low-dimensional vector representations of words or phrases from large corpora. These methods typically involve training on large amounts of text data to capture contextual information and semantic relationships between words.</li> <li>Statistical vector-based embedding methods rely on statistical techniques to represent words as vectors based on their distributional properties in a corpus. These methods typically involve counting word occurrences and co-occurrences and using various mathematical techniques to derive the embeddings.</li> </ul> <p>The following embedding methods were explored:</p> Neural Network-based Statistical Vector-based Doc2Vec Latent Semantic Analysis (LSA) GloVe (Global Vectors for Word Representation) Latent Dirichlet Allocation (LDA) Contextual Embeddings  \u2022 all-MiniLM-L6-v2  \u2022 all-mpnet-base-v1  \u2022 all-mpnet-base-v2  \u2022 bge-large-en-v1.5  \u2022 bge-large-en-v1.5-quant  \u2022 bge-m3 \u2022 gte-base-en-v1.5  \u2022 jina-embeddings-v2-base-en  \u2022 multi-qa-mpnet-base-cos-v1  \u2022 multi-qa-mpnet-base-dot-v1  \u2022 mxbai-embed-large-v1  \u2022 nomic-embed-text-v1.5  \u2022 snowflake-arctic-embed-m-long  \u2022 stsb-mpnet-base-v2 Term Frequency-Inverse Document Frequency (TF-IDF) - Bag-of-words (BoW)"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#embedding-models-evaluation-methodology","title":"Embedding Models: Evaluation Methodology","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#embedding-models-quantitative-analysis","title":"Embedding Models: Quantitative Analysis","text":"<p>Quantitative analysis of clustering performance involves evaluating the results using specific metrics that provide insights into the effectiveness of the clustering solution. Each embedding method is evaluated using the reference excel file provided by HH team as guidance with the following metrics:</p> <ol> <li>V-measure: The harmonic mean of homogeneity and completeness. Higher score, the better.</li> <li>Homogeneity: Each cluster contains only members of a single class.</li> <li>Completeness: All members of a given class are assigned to the same cluster.</li> <li>Median difference: Difference in correlation scores between the median of same-group articles and that of different-group articles. This is a quantitative measure of intra-cluster versus inter-cluster similarity. Higher difference, the better.</li> </ol>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#embedding-models-qualitative-analysis","title":"Embedding Models: Qualitative Analysis","text":"<p>Qualitative analysis of clustering output involves visual inspection of the clusters, where data points within each cluster are reviewed to determine if they align with expected groupings and whether the clusters make logical sense and are meaningful in the context of the data. Key aspects of this analysis include:</p> <ol> <li>Similarity of articles within clusters: Examining whether the predicted clusters contain articles that are similar to each other. This involves checking if the articles within a cluster share common themes or characteristics, ensuring that the clustering results reflect meaningful groupings.</li> <li>Cluster topic specificity: Assessing whether the topics represented by the clusters are too broad or if they can be refined into more specific sub-topics. This step helps in determining if the clusters are sufficiently detailed or if they require further segmentation to enhance their relevance.</li> <li>Unclustered nodes: Evaluating if the unclustered nodes should be assigned to an existing cluster.</li> </ol>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#embedding-models-results","title":"Embedding Models: Results","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#results-of-quantitative-analysis","title":"Results of Quantitative Analysis","text":"<p>The top 5 models that had the highest V-measure score and median difference are as follow:</p> Ranking V-measure Median difference #1 nomic-embed-text-v1.5 TF-IDF #2 multi-qa-mpnet-base-cos-v1 all-mpnet-base-v2 #3 all-mpnet-base-v2 all-MiniLM-L6-v2 #4 bge-m3 multi-qa-mpnet-base-cos-v1 #5 TF-IDF all-mpnet-base-v1 <p>Results showed that these 6 identified models outperformed the rest. Next, we conducted a qualitative analysis on the clustering output of these 6 models to evaluate the quality of the clusters they produced.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#results-of-qualitative-analysis","title":"Results of Qualitative Analysis","text":"<p>The results of the qualitative analysis of the clustering output are summarized and ranked based on model performance as follows:</p> Ranking Model Remarks #1 nomic-embed-text-v1.5 \u2022 Able to breakdown more broad clusters compared to #2.  \u2022 Able to generate specific themed clusters not seen in other models.  \u2022 Time taken to embed 623 articles: 45min #2 all-MiniLM-L6-v2 \u2022 Able to breakdown broad clusters in other models into specific-themed clusters, compared to #3 &amp; #4.  \u2022 Unclustered nodes seen in #3 &amp; #4 managed to form clusters  \u2022 Time taken to embed 623 articles: 6min #3 multi-qa-mpnet-base-cos-v1 \u2022 Able to produce specific-themed clusters compared to #4. Example: healthy cooking, healthy eating at hawker #4 all-mpnet-base-v2 \u2022 Produces decent clusters with similar articles clustered together.\u00a0 \u2022 However, 2 of the clusters were noted to be too broad, and can be further broken down. #5 bge-m3 \u2022 A few clusters contained dissimilar topics grouped together. This is not ideal.\u00a0 #6 tfidf \u2022 A few clusters contained dissimilar topics grouped together. This is not ideal.\u00a0 \u2022 Model also produced the highest number of unclustered nodes with most single nodes being similar to existing predicted topics. <p><code>nomic-embed-text-v1.5</code> and <code>all-MiniLM-L6-v2</code> embedding models were able to generate specific-themed clusters not seen in other models.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/embedding-techniques/embedding-techniques/#conclusion","title":"Conclusion","text":"<p>In conclusion, this study evaluated pooling strategies and various embedding methods to determine the most effective approach for generating document embeddings. Key findings:</p> <ol> <li>Mean pooling outperforms max pooling in producing more coherent document representations, capturing the general meaning of the text better.</li> <li>Embedding models <code>nomic-embed-text-v1.5</code> and <code>all-MiniLM-L6-v2</code> generated more meaningful, specific-themed clusters, outperforming others in both quantitative and qualitative aspects.</li> </ol> <p>In the downstream studies, experiments were conducted using mean pooling strategy and embedding models <code>nomic-embed-text-v1.5</code> and <code>all-MiniLM-L6-v2</code> .</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/feature-selection/feature-selection/","title":"Feature selection","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/feature-selection/feature-selection/#introduction","title":"Introduction","text":"<p>Combining multiple features for clustering provides a richer and more comprehensive representation of the data, allowing the model to capture a broader range of information, leading to more accurate and representative embeddings. Clustering results can be more meaningful when based on a multi-faceted understanding of the data.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/feature-selection/feature-selection/#importance-of-each-feature","title":"Importance of each Feature","text":"<p>To assess the impact of individual features on clustering performance, clustering was conducted separately on each feature.</p> <p></p> <p>The results indicate that article body content and title are the most effective features for clustering similar articles. Both features generated more distinct and meaningful clusters, highlighting their importance in capturing the essence of the articles. In contrast, meta description and keywords produced fewer clusters, suggesting that embeddings derived from these features were less effective in distinguishing between articles.</p> <p>This finding was consistent across both embedding models used in the study, reinforcing the importance of content body and title in achieving accurate and well-separated clusters.</p> <p>Titles and body content serve complementary roles. Titles often summarise or highlight the main topic, whereas the body provides depth and context. By incorporating both features, the clustering algorithm can leverage the enhanced contextual understanding and embedding representations, leading to clusters that are more contextually relevant and useful.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/feature-selection/feature-selection/#evaluation","title":"Evaluation","text":"<p>First, we looked at the cluster size breakdown for each model. For both models, combination of content body with title produces higher number of smaller clusters of size \u2264 5.</p> <p></p> <p>Next, we evaluated each smaller-sized cluster (those that contains \u2264 5 articles) qualitatively. For both models, combination of content body with title gives:</p> <ul> <li>Higher absolute number of good groups</li> <li>Higher percentage of good groups</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/feature-selection/feature-selection/#conclusion","title":"Conclusion","text":"<p>The trend observed across both embedding models reinforces the importance of combining article body content and title in achieving good clustering output. Meta descriptions and keywords were less effective in generating well-separated clusters.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/","title":"Multi-feature Clustering Methodology","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#introduction","title":"Introduction","text":"<p>The following are features from the dataset which may be used for clustering:</p> <ol> <li>Article title</li> <li>Article meta description</li> <li>Article body content</li> <li>Keywords (generated using KeyBERT on body content)</li> </ol> <p>Combining multiple features for clustering provides a richer and more comprehensive representation of the data, allowing the model to capture a broader range of information, leading to more accurate and representative embeddings. Clustering results can be more meaningful when based on a multi-faceted understanding of the data.</p> <p>Two approaches were identified on the use of multiple features for clustering \u2014 weighted embeddings approach and weighted similarity approach. This study is conducted using 0.7*body content + 0.3*title for evaluation across the two approaches.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#methodology","title":"Methodology","text":"<p>Both methods leverage the benefits of using multiple features while controlling their influence through weightage, which can enhance the ability to capture diverse aspects of article content and improve clustering quality.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#weighted-embeddings-approach","title":"Weighted Embeddings Approach","text":"<p>In the weighted embeddings approach, each feature of the articles, such as article body content and article title, is first embedded into vectors using an embedding model. These feature-specific embeddings are then combined by applying predefined weights to each feature\u2019s embedding, reflecting their relative importance or relevance to the clustering task. This weighted combination results in a single, unified embedding for each article. Subsequently, the similarity scores between these unified embeddings are computed, and clustering is performed using community detection techniques.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#weighted-similarity-approach","title":"Weighted Similarity Approach","text":"<p>In the weighted similarity approach, cosine similarity scores are first calculated within each feature embeddings. Each article\u2019s similarity score is then adjusted by applying predefined weights that reflect the importance of the corresponding feature. Community detection is then applied to this weighted similarity matrix to identify clusters.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#evaluation-of-the-two-approaches","title":"Evaluation of the Two Approaches","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#quantitative-analysis","title":"Quantitative analysis","text":"<p>Quantitative analysis reviewed that</p> <ul> <li> <p>For <code>nomic-embed-text-v1.5</code> model, the weighted embeddings method produced</p> <ul> <li>more clusters</li> <li>clusters with less inter-connected edges (i.e. have more distinctly separated clusters)</li> <li>high proportion of small-sized clusters (88.9% of clusters are of group size 2-10)</li> </ul> </li> <li> <p>For <code>all-MiniLM-L6-v2</code> model, the weighted similarity method produced</p> <ul> <li>more clusters</li> <li>clusters with less inter-connected edges (i.e. have more distinctly separated clusters)</li> <li>high proportion of small-sized clusters (85.7% of clusters are of group size 2-10)</li> </ul> </li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#qualitative-analysis","title":"Qualitative analysis","text":"<p>During qualitative analysis, we looked at the top 5 biggest clusters to evaluate their differences. Generally, output from weighted embedding method is preferred for <code>nomic-embed-text-v1.5</code> model as it produces more specific-themed clusters. On the other hand, output from weighted similarity method is preferred for <code>all-MiniLM-L6-v2</code> model as it produces more specific-themed clusters.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/multi-feature/multi-feature-clustering-methodology/#conclusion","title":"Conclusion","text":"<p>The use of multiple features proves to enhance the clustering output, leading to more meaningful and contextually relevant clusters being produced. For subsequent experiments, <code>nomic-embed-text-v1.5</code> model with weighted embedding and <code>all-MiniLM-L6-v2</code> model with weighted similarity are used.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/subclustering/subclustering/","title":"Subclustering","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/subclustering/subclustering/#introduction","title":"Introduction","text":"<p>The initial clustering process identified over 60 groups, with 10 to 11 of these groups containing between 11 to 70 articles each. As larger clusters may hinder effective content review, we explored a second level of subclustering to determine if these larger-sized groups can be further subdivided into smaller clusters. This additional layer of refinement aims to improve the manageability and clarity of each cluster.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/subclustering/subclustering/#methodology","title":"Methodology","text":"<p>The second level of clustering involves the following steps:</p> <ol> <li>Identifying clusters that exceed size threshold of 10</li> <li>Applying BERTopic to perform subclustering: This process includes hyperparameter tuning to optimize HDBSCAN, followed by the use of c-TF-IDF to generate the top 5 keywords for each subcluster.</li> </ol>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/subclustering/subclustering/#evaluation","title":"Evaluation","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/subclustering/subclustering/#quantitative-review","title":"Quantitative Review","text":"Cluster Size nomic-embed-text-v1.5 (Before) nomic-embed-text-v1.5 (After) all-MiniLM-L6-v2 (Before) all-MiniLM-L6-v2 (After) 2-10 49 84 52 81 11-20 5 9 3 4 21-30 1 0 2 1 31-40 2 1 2 1 41-50 1 0 1 0 51-60 1 0 1 0 61-70 1 0 1 0 Total 60 94 62 87 <p>The second layer of topic modeling successfully broke down larger clusters into smaller clusters. As a result, clusters with sizes 41 and above were eliminated, showing that the large clusters were effectively split into smaller ones.</p> <p>For cluster sizes between 11 and 40, these groups still exist, but they are now smaller segments that came from the original larger clusters. This outcome is consistent for both the nomic-embed-text-v1.5 and all-MiniLM-L6-v2 models.</p> <p>For <code>nomic-embed-text-v1.5</code>, the largest cluster that remained after subclustering was a smoking-related group with size of 33.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/subclustering/subclustering/#qualitative-review","title":"Qualitative Review","text":"<ul> <li> <p>nomic-embed-text-v1.5: Out of 45 subgroups, 9 were noted to have issues such as:</p> <ul> <li>Articles with a different focus compared to the rest within the subgroup</li> <li>Differing article contexts within the subgroup</li> <li>No clear thematic distinction between the different subgroups</li> </ul> </li> <li> <p>all-MiniLM-L6-v2: Out of 36 subgroups, 13 were noted to have issues such as:</p> <ul> <li>No clear thematic distribution between different subgroups</li> <li>Subgroups were too broad, targeting different audiences</li> </ul> </li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/experiments/subclustering/subclustering/#conclusion","title":"Conclusion","text":"<p>Before the implementation of the second layer of topic modeling, when examining clusters with a size of 5 or less, the <code>nomic-embed-text-v1.5</code> model produced a higher absolute number of quality groups compared to the <code>all-MiniLM-L6-v2</code> model. Additionally, the <code>nomic-embed-text-v1.5</code> model also produced a higher percentage of good groups in comparison to the <code>all-MiniLM-L6-v2</code> model.</p> <p>After the second layer of topic modeling, both models produced approximately 80% quality subgroups:</p> <ul> <li>nomic-embed-text-v1.5: 36 out of 45 subgroups (~80%).</li> <li>all-MiniLM-L6-v2 Model: 23 out of 36 subgroups (~79%).</li> </ul> <p>The <code>nomic-embed-text-v1.5</code> model tends to produce more clusters and slightly smaller cluster sizes compared to the <code>all-MiniLM-L6-v2</code> model. Importantly, the <code>nomic-embed-text-v1.5</code> model consistently produces at least one valid subgroup per group.</p> <p>Based on these findings, it is recommended to proceed with the <code>nomic-embed-text-v1.5</code> model due to its consistent performance in producing more valid subgroups and better managing cluster sizes.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/","title":"Overview","text":"<p>The clustering pipeline contains 5 nodes:</p> <ol> <li>@label(func) <code>merge_ground_truth_to_data</code>: To merge reference excel from HH team into the processed dataset</li> <li>@label(func) <code>generate_clusters</code>: To generate first-level clusters using Louvain algorithm</li> <li>@label(func) <code>generate_subclusters</code>: To generate subclusters for those with cluster size &gt; 10 using BERTopic</li> <li>@label(func) <code>update_edges_dataframe</code>: To update first-level edge dataframe output from <code>generate_clusters</code> node</li> <li>@label(func) <code>cluster_viz</code>: To visualise the clusters using pyvis</li> </ol>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/cluster-visualization/","title":"@label(func) <code>cluster_viz</code>","text":"<p>The <code>cluster_viz</code> node generates an interactive visualization of clustered and unclustered nodes in a network graph using the Pyvis library. The function creates a visual representation where nodes represent articles, and edges represent similarity score between the nodes. Details such as predicted cluster label and cluster keywords are included in the graph.</p> <pre><code>def cluster_viz(\n    final_clustered_nodes: pd.DataFrame,\n    final_unclustered_nodes: pd.DataFrame\n):\n</code></pre> Parameters <p><code>final_unclustered_node</code> (<code>pd.DataFrame</code>): A DataFrame containing the nodes that remained unclustered, with columns:</p> <ul> <li><code>node_id</code> (<code>int</code>): Article ID of the unclustered node</li> <li><code>node_title</code> (<code>str</code>): Article title of the unclustered node</li> <li><code>node_community</code> (<code>int</code>): Topic number assigned to the unclustered node</li> </ul> <p><code>final_clustered_node</code> (<code>pd.DataFrame</code>): A DataFrame containing the updated clustered nodes with new cluster assignments and keywords, filtered to remove rows with missing keywords. Columns include:</p> <ul> <li><code>node_1_id</code> (<code>int</code>): ID of the first node</li> <li><code>node_2_id</code> (<code>int</code>): ID of the second node</li> <li><code>node_1_title</code> (<code>str</code>): Title of the first node</li> <li><code>node_2_title</code> (<code>str</code>): Title of the second node</li> <li><code>edge_weight</code> (<code>float</code>): Similarity between the two nodes</li> <li><code>node_1_pred_cluster_new</code> (<code>int</code>): New predicted cluster for the first node</li> <li><code>node_1_cluster_kws</code> (<code>List</code>): The top 5 keywords representing <code>node_1_pred_cluster_new</code> cluster</li> <li><code>node_2_pred_cluster_new</code> (<code>int</code>): New predicted cluster for the second node</li> <li><code>node_2_cluster_kws</code> (<code>List</code>): The top 5 keywords representing <code>node_2_pred_cluster_new</code> cluster</li> </ul> Returns <p>The function saves the interactive network graph as an HTML file at <code>data/07_model_output/neo4j_cluster_viz.html</code> and does not return any value. This file visualizes:</p> <ul> <li>Nodes and edges from the clustered nodes with attributes like predicted clusters, keywords, and edge weights.</li> <li>Single nodes from the unclustered node.</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/generate-cluster/","title":"@label(func) <code>generate_clusters</code>","text":"<p>The <code>generate_cluster</code> node orchestrates the process of clustering articles using multiple features by weightage and community detection in a Neo4j graph database. It takes in a DataFrame with article data, configuration for Neo4j, and various weights for different features. The function performs the following tasks:</p> <ol> <li>Similarity Calculation: Computes similarity scores between articles based on weighted embeddings of their features.</li> <li>Threshold Setting: Determines a threshold value for edge creation based on similarity scores. A pre-defined threshold value may also be used.</li> <li>Graph Projection and Community Detection: Projects the graph and detects communities within the graph via Louvain community detection.</li> <li>Cluster Results: Compiles clustering results and count articles in each cluster.</li> </ol> <pre><code>def generate_clusters(\n    merged_df_with_groundtruth: pd.DataFrame,\n    neo4j_config: Dict[str, str],\n    weight_title: float,\n    weight_cat: float,\n    weight_desc: float,\n    weight_body: float,\n    weight_combined: float,\n    weight_kws: float,\n    set_threshold: Union[Literal[False], float],\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n</code></pre> Parameters <p><code>neo4j_config</code> (<code>Dict[str, str]</code>): Configuration to connect to Neo4j database. Derived from values specified in <code>parameters_clustering.yml</code>.</p> <p><code>merged_df_with_groundtruth</code> (<code>pd.DataFrame</code>): The DataFrame output from <code>merge_ground_truth_data</code> node.</p> <p><code>weight_title</code> (<code>float</code>): Weightage of title similarity score to use to compute weighted similarity. Derived from values specified in <code>parameters_clustering.yml</code>.</p> <p><code>weight_cat</code> (<code>float</code>): Weightage of article category similarity score to use to compute weighted similarity. Derived from values specified in <code>parameters_clustering.yml</code>.</p> <p><code>weight_desc</code> (<code>float</code>): Weightage of meta description similarity score to use to compute weighted similarity. Derived from values specified in <code>parameters_clustering.yml</code>.</p> <p><code>weight_body</code> (<code>float</code>): Weightage of body content similarity score to use to compute weighted similarity. Derived from values specified in <code>parameters_clustering.yml</code>.</p> <p><code>weight_kws</code> (<code>float</code>): Weightage of body content similarity score to use to compute weighted similarity. Derived from values specified in <code>parameters_clustering.yml</code>.</p> <p><code>weight_combined</code> (<code>Literal[0,1]</code>): A flag indicating whether weighted embeddings will be used. Set to <code>1</code> to use weighted embedding, and <code>0</code> to disable their use. When set to <code>1</code>, ensure all other related weights are set to <code>0</code>. Derived from values specified in <code>parameters_clustering.yml</code>.</p> <p><code>set_threshold</code> (<code>Union[None, float]</code>): Threshold for clustering. Derived from values specified in <code>parameters_clustering.yml</code>. Set as <code>\"\"</code> if not pre-defining threshold.</p> Returns <p><code>first_level_pred_cluster</code> (<code>pd.DataFrame</code>): A DataFrame with the predicted cluster assignments for each article.</p> <p><code>first_level_metrics</code> (<code>pd.DataFrame</code>):A DataFrame containing the threshold, weightage parameters and cluster output metrics which include number of clusters, minimum cluster size, maximum cluster size, number of single unclustered articles.</p> <p><code>first_level_cluster_size</code> (<code>pd.DataFrame</code>): A DataFrame summarising the number of clusters within each size range, including a count of single unclustered articles.</p> <p><code>first_level_clustered_nodes</code> (<code>pd.DataFrame</code>): A DataFrame with information about each pair of nodes and their edge weight.</p> <p><code>first_level_unclustered_nodes</code> (<code>pd.DataFrame</code>): A DataFrame with information about each single node.</p> Raises <p><code>Neo4jError</code>: If an error occurs with Neo4j database operations.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/generate-subcluster/","title":"@label(func) <code>generate_subclusters</code>","text":"<p>This function processes the first level clusters (<code>first_level_pred_cluster</code>) and embeddings (<code>weighted_embeddings</code>) to perform a second level of clustering on clusters that have more than the specified <code>size_threshold</code>.The function performs the following tasks:</p> <ol> <li>Cluster Filtering: Identifies clusters that exceed the size threshold for subclustering.</li> <li>Subclustering: Applies BERTopic to perform subclustering on identified clusters.</li> <li>Topic Assignment: Assign unique topic number to the newly generated subclusters.</li> <li>Keyword Generation: Generates keywords for clusters that did not undergo subclustering but contain more than one article.</li> <li>Metrics Calculation: Calculates and returns metrics including the number of clusters, the minimum and maximum cluster sizes, and the number of unclustered articles.</li> </ol> <pre><code>def generate_subclusters(\n    weighted_embeddings: pd.DataFrame,\n    first_level_pred_cluster: pd.DataFrame,\n    umap_parameters: Dict,\n    size_threshold: float,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n</code></pre> Parameters <code>weighted_embeddings</code><code>(pd.DataFrame)</code>: DataFrame output from the feature_engineering pipeline, containing the weighted embeddings (loaded from a .pkl file) of each article and other features such as <code>id</code> and <code>extracted_content_body_embeddings</code> columns. <code>first_level_pred_cluster</code> <code>(pd.DataFrame)</code>: A DataFrame output from <code>generate_clusters</code> node, with the predicted cluster assignments for each article. <code>umap_parameters</code> <code>(Dict)</code>: A dictionary of UMAP parameters (n_neighbors, n_components) to be used for the clustering process. Derived from values specified in <code>parameters_clustering.yml</code>. <code>size_threshold</code> <code>(float)</code>: The minimum number of articles a cluster must have to proceed with subclustering. Returns <code>final_predicted_cluster</code> <code>(pd.DataFrame)</code>: A DataFrame with the updated clusters, including the new subclusters and cluster keywords. <code>final_cluster_size</code> <code>(pd.DataFrame)</code>: DataFrame containing the size of each cluster in bins of size 5. <code>final_metrics</code> <code>(pd.DataFrame)</code>: DataFrame containing clustering metrics which include the number of clusters, the minimum and maximum cluster sizes, and the number of unclustered articles."},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/merge-ground-truth-to-data/","title":"@label(func) <code>merge_ground_truth_to_data</code>","text":"<p>This function filters the ground truth data to include only entries that match the specified content contributor. It then merges this filtered ground truth data with the weighted embeddings dataframe based on the URL.</p> <p>Ground Truth Data</p> <p>The ground truth cluster information is derived from the reference Excel file provided by the HH team. Please note that this data serves as a reference from past manual audits and should not be considered as the definitive ground truth.</p> <pre><code>def merge_ground_truth_to_data(\n    ground_truth_data: pd.DataFrame,\n    content_contributor: str,\n    weighted_embeddings: pd.DataFrame,\n) -&gt; pd.DataFrame:\n</code></pre> Parameters <p><code>ground_truth_data</code> <code>(pd.DataFrame)</code>: DataFrame containing reference ground truth data, with columns including \"Owner\", \"Page Title\", \"Combine Group ID\", and \"URL\".</p> <p><code>content_contributor</code> <code>(str)</code>: The name of the content contributor to filter the ground truth data. To be specified in <code>parameters_clustering.yml</code>.</p> <p><code>weighted_embeddings</code> <code>(pd.DataFrame)</code>: DataFrame output from the <code>feature_engineering</code> pipeline, containing the weighted embeddings (loaded from a .pkl file) of each article and other features such as ID and URL</p> Returns <p><code>articles_df</code> <code>(pd.DataFrame)</code>: A merged DataFrame containing the weighted embeddings and ground truth data.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/parameters-clustering/","title":"Parameters","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/parameters-clustering/#parameters_clusteringyml","title":"<code>parameters_clustering.yml</code>","text":"<p>This document describes the configuration parameters used in the <code>parameters_clustering.yml</code> file for <code>clustering</code> Kedro pipeline.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/parameters-clustering/#neo4j-configuration","title":"Neo4j Configuration","text":"<pre><code>neo4j_config:\n  uri: neo4j://localhost:7687\n  database: hh-articles\n</code></pre> <p><code>uri</code>: The URI for the Neo4j Instance. In this case, it points to a locally hosted instance on port 7686</p> <p><code>database</code>: The name of databse to connect to. Here, it is set to <code>hh-articles</code>.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/parameters-clustering/#content-contributor","title":"Content Contributor","text":"<p>This parameter specifies the organization or entity contributing to the content.</p> <pre><code>content_contributor: Health Promotion Board\n</code></pre> <p><code>content_contributor</code>: The name of the content contributor, set to \"Health Promotion Board\". This filters the data to only include rows where the <code>pr_name</code> column matches this value.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/parameters-clustering/#similarity-weightage","title":"Similarity Weightage","text":"<p>This section defines the weightage for different aspects of similarity. To ensure proper weighted similarity, the total sum of all weights must equal <code>1</code>.</p> <p>NOTE</p> <p>The current clustering pipeline uses weighted embeddings instead of weighted similarity with <code>weight_combined</code> can be set to <code>1</code>, and all others set to <code>0</code>.</p> <pre><code>sim_weightage:\n  weight_title: 0\n  weight_cat: 0\n  weight_desc: 0\n  weight_body: 0\n  weight_combined: 1\n  weight_kws: 0\n</code></pre> <p><code>weight_title</code>: The weight assigned to title similarity. Here it is set to <code>0</code>, indicating no weight.</p> <p><code>weight_cat</code>: The weight assigned to category similarity, set to <code>0</code>.</p> <p><code>weight_desc</code>: The weight assigned to meta description similarity, set to <code>0</code>.</p> <p><code>weight_body</code>: The weight assigned to body content similarity, set to <code>0</code>.</p> <p><code>weight_combined</code>: A flag indicating whether weighted embeddings will be used. Set to <code>1</code> to use weighted embedding, and <code>0</code> to disable their use. When set to <code>1</code> ensure all other related weights are set to <code>0</code>.</p> <p><code>weight_kws</code>: The weight assigned to the keyword similarity, set to <code>0</code>.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/parameters-clustering/#similarity-threshold","title":"Similarity Threshold","text":"<p>This parameter controls whether a predefined similarity threshold is set.</p> <pre><code>set_threshold:\n</code></pre> <p><code>set_threshold</code>: Threshold value used to determine if edges should be formed between nodes based on similarity threshold. This should be a <code>float</code>. If set to <code>\"\"</code>, the threshold will default to the median similarity threshold derived from ground truth data.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/parameters-clustering/#umap-parameters","title":"UMAP Parameters","text":"<p>This section defines the UMAP (Uniform Manifold Approximation and Projection) parameters for dimensionality reduction. To be used for BERTopic.</p> <pre><code>umap_parameters:\n  n_neighbors: 15\n  n_components: 8\n</code></pre> <p><code>n_neighbors</code>: The number of neighbours to consider for each point in UMAP. Balances local versus global structure in the data. Low values will force UMAP to concentrate on very local strucuture, while large values will push to look at larger neighborhoods of each point.</p> <p><code>n_components</code>: The number of dimensions to reduce the data to.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/update-edges-dataframe/","title":"@label(func) <code>update_edges_dataframe</code>","text":"<p>This function updates the edges DataFrame (<code>first_level_clustered_nodes</code>) with new cluster assignments (<code>final_predicted_cluster</code>) and keywords from the updated prediction clusters after subclustering. It also identifies nodes that remain unclustered (single article clusters) and prepares a DataFrame for these unclustered nodes with relevant columns.</p> <pre><code>def update_edges_dataframe(\n    first_level_clustered_nodes: pd.DataFrame,\n    final_predicted_cluster: pd.DataFrame\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n</code></pre> Parameters <code>first_level_clustered_nodes</code> (<code>pd.DataFrame</code>): A DataFrame with information about each pair of nodes and their edge connections. Output from <code>generate_cluster</code> function. <code>final_predicted_cluster</code> <code>(pd.DataFrame)</code>: A DataFrame with the updated clusters, including the new subclusters and cluster keywords. Output from <code>generate_subcluster</code> function. Returns <p><code>final_unclustered_node</code> (<code>pd.DataFrame</code>): A DataFrame containing the nodes that remained unclustered, with columns:</p> <ul> <li><code>node_id</code> (<code>int</code>): Article ID of the unclustered node</li> <li><code>node_title</code> (<code>str</code>): Article title of the unclustered node</li> <li><code>node_community</code> (<code>int</code>): Topic number assigned to the unclustered node</li> </ul> <p><code>final_clustered_node</code> (<code>pd.DataFrame</code>): A DataFrame containing the updated clustered nodes with new cluster assignments and keywords, filtered to remove rows with missing keywords. Columns include:</p> <ul> <li><code>node_1_id</code> (<code>int</code>): ID of the first node</li> <li><code>node_2_id</code> (<code>int</code>): ID of the second node</li> <li><code>node_1_title</code> (<code>str</code>): Title of the first node</li> <li><code>node_2_title</code> (<code>str</code>): Title of the second node</li> <li><code>edge_weight</code> (<code>float</code>): Similarity between the two nodes</li> <li><code>node_1_pred_cluster_new</code> (<code>int</code>): New predicted cluster for the first node</li> <li><code>node_1_cluster_kws</code> (<code>List</code>): The top 5 keywords representing <code>node_1_pred_cluster_new</code> cluster</li> <li><code>node_2_pred_cluster_new</code> (<code>int</code>): New predicted cluster for the second node</li> <li><code>node_2_cluster_kws</code> (<code>List</code>): The top 5 keywords representing <code>node_2_pred_cluster_new</code> cluster</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/","title":"Clusters","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#create-graph-nodes","title":"Create Graph Nodes","text":"<p>The <code>create_graph_nodes</code> function is designed to create nodes in a Neo4j graph database. Specifically, it inserts nodes representing articles with various attributes such as title, URL, content, meta description, and multiple vector representations. Each node represents one article.</p> <pre><code>def create_graph_nodes(tx, doc):\n</code></pre> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query.</p> <p><code>doc</code> (<code>Dict[str, Any]</code>): A dictionary containing the article's data and vector representations. The dictionary must include the following keys:</p> <ul> <li><code>id</code>: The unique identifier for the article.</li> <li><code>title</code>: The title of the article.</li> <li><code>full_url</code>: The URL of the article.</li> <li><code>content</code>: The body content of the article.</li> <li><code>meta_description</code>: The meta description of the article.</li> <li><code>title_embeddings</code>: The vector representation of the article title.</li> <li><code>article_category_names_embeddings</code>: The vector representation of the article category names.</li> <li><code>category_description_embeddings</code>: The vector representation of the article category description.</li> <li><code>extracted_content_body_embeddings</code>: The vector representation of the article body content.</li> <li><code>combined_embeddings</code>: The combined vector representation of the article.</li> <li><code>keywords_all-MiniLM-L6-v2_embeddings</code>: The vector representation of the article keywords.</li> <li><code>ground_truth_cluster</code>: The ground truth cluster label of the article.</li> </ul> Returns <p>The function does not return any values. It performs an operation on the Neo4j database, creating a node with the provided attributes for each article.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#calculate-similarities","title":"Calculate Similarities","text":"<p>The <code>calculate_similarity</code> function uses Neo4j Graph Data Science (GDS) to compute cosine similarity between two articles.</p> <pre><code>def calculate_similarity(tx, vector_name):\n</code></pre> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query.</p> <p><code>vector_name</code> (<code>str</code>): Column name of vector to calculate cosine similarity.</p> Returns <p>The function returns a dictionary in the following structure:</p> <pre><code>{(node_1_id, node_2_id): similarity_score}\n</code></pre> <ul> <li>Keys: A tuple containing article ID for the first node (<code>node_1_id (int)</code>) and article ID for the second node (<code>node_2_id (int)</code>).</li> <li>Values: Cosine similarity score between the <code>vector_name</code> of <code>node_1_id</code> and <code>node_2_id</code>.</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#fetch-ground-truth","title":"Fetch Ground Truth","text":"<p>The <code>fetch_ground_truth</code> function fetches the ground truth for each article and return a dictionary of article ids and the ground truth labels. This function is used within <code>combine_similarities</code> function.</p> Parameters <p><code>session</code> (<code>neo4j.Session</code>): A Neo4j session object used to execute queries within a transaction.</p> Returns <p><code>ground_truth</code> (<code>Dict[int, int]</code>): A dictionary containing the article's id as the key and ground truth as the value.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#combine-similarities","title":"Combine Similarities","text":"<p>The <code>combine_similarities</code> function combines similarity scores from various feature vectors (such as title, category name, description, body content, combined vectors, and keywords) into a single weighted similarity score for each pair of nodes (articles) in a Neo4j database. This combined similarity score is then used for further analysis or clustering.</p> <pre><code>def combine_similarities(\n    session,\n    weight_title,\n    weight_cat,\n    weight_desc,\n    weight_body,\n    weight_combined,\n    weight_kws,\n):\n</code></pre> Parameters <p><code>session</code> (<code>neo4j.Session</code>): A Neo4j session object used to execute queries within a transaction.</p> <p><code>weight_title</code> (<code>int</code>): The weight assigned to title similarity for weighted similarity. To be retrieved from <code>parameters_clustering.yml</code></p> <p><code>weight_cat</code> (<code>int</code>): The weight assigned to the category similarity score for weighted similarity. To be retrieved from <code>parameters_clustering.yml</code></p> <p><code>weight_desc</code> (<code>int</code>): The weight assigned to the description similarity score for weighted similarity. To be retrieved from <code>parameters_clustering.yml</code></p> <p><code>weight_body</code> (<code>int</code>): The weight assigned to the body content similarity score for weighted similarity. To be retrieved from <code>parameters_clustering.yml</code></p> <p><code>weight_combined</code> (<code>Literal[0,1]</code>): A flag indicating whether weighted embeddings will be used. Set to <code>1</code> to use weighted embedding, and <code>0</code> to disable their use. When set to <code>1</code> ensure all other related weights are set to <code>0</code>. To be retrieved from <code>parameters_clustering.yml</code></p> <p><code>weight_kws</code> (<code>int</code>): The weight assigned to the keywords similarity score. To be retrieved from <code>parameters_clustering.yml</code>.</p> Returns <p><code>combined_similarities_df</code> (<code>pd.DataFrame</code>): A DataFrame containing combined similarity scores for each pair of articles. Each row represents a pair of articles with the following columns:</p> <ul> <li><code>node_1_id</code> (<code>int</code>): The ID of the first article in the pair.</li> <li><code>node_2_id</code>  (<code>int</code>): The ID of the second article in the pair.</li> <li><code>similarities_title</code> (<code>float</code>): The similarity score based on the title vectors.</li> <li><code>similarities_cat</code> (<code>float</code>): The similarity score based on the category vectors.</li> <li><code>similarities_desc</code> (<code>float</code>): The similarity score based on the description vectors.</li> <li><code>similarities_body</code> (<code>float</code>): The similarity score based on the body content vectors.</li> <li><code>similarities_combined</code> (<code>float</code>): The similarity score based on the combined embedding vectors.</li> <li><code>similarities_kws</code> (<code>float</code>): The similarity score based on the keywords vectors.</li> <li><code>weighted_similarity</code> (<code>float</code>): The weighted similarity score calculated from the individual feature similarities using the provided weights.</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#get-median-threshold","title":"Get Median Threshold","text":"<p>The <code>median_threshold</code> function calculates the median of the weighted similarity scores for pairs of articles that share the same ground truth cluster. This median value may be used as a threshold for clustering.</p> <p>Note: ground truth cluster information is gathered from the reference excel file provided by HH team.</p> <pre><code>def median_threshold(combined_similarities_df):\n</code></pre> Parameters <p><code>combined_similarities_df</code> (<code>pd.DataFrame</code>): A DataFrame output from <code>combine_similarities</code> function, containing similarity scores between pairs of articles</p> Returns <p><code>threshold</code> (<code>float</code>): Median of the weighted similarity scores for pairs of articles that share the same ground truth cluster.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#create-similarity-edges","title":"Create Similarity Edges","text":"<p>The <code>create_sim_edges</code> function creates edges between nodes in a Neo4j graph database based on their similarity scores. It iterates through a DataFrame of similarity scores and creates an edge between nodes if their weighted similarity exceeds a given threshold. This helps in forming connections between articles that are considered similar according to the specified criteria.</p> <pre><code>def create_sim_edges(tx, similarities, threshold):\n</code></pre> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query.</p> <p><code>similarities</code> (<code>pd.DataFrame</code>): A dataframe output from <code>combine_similarities</code> function, containing similarity scores between pairs of articles.</p> <p><code>threshold</code> (<code>float</code>): A value used as a cut-off point. Only pairs of nodes with a weighted similarity above this threshold will have edges created between them. This value can be pre-defined in <code>parameters_clustering.yml</code> or using the output threshold value from <code>median_threshold</code> function.</p> Returns <p>The function does not return any values. It performs operations within the Neo4j database to create edges based on the provided similarity scores and threshold.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#drop-graph-projection","title":"Drop Graph Projection","text":"<p>The <code>drop_graph_projection</code> function checks if a graph projection named <code>articleGraph</code> exists within the Neo4j database. If the projection exists, the function proceeds to drop (delete) it.</p> <pre><code>def drop_graph_projection(tx):\n</code></pre> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query.</p> Returns <p>The function does not return any values. It performs operations within the Neo4j database to drop the <code>articleGraph</code> graph projection if exists.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#create-graph-projection","title":"Create Graph Projection","text":"<p>The <code>create_graph_proj</code> function creates a graph projection named <code>articleGraph</code> in Neo4j using the Graph Data Science (GDS) library. This projection is used to facilitate graph algorithms and analysis by defining the nodes and relationships that should be included in the projected graph. In this case, it projects all nodes of type <code>Article</code> and thee <code>SIMILAR</code> relationship is defined as <code>similarity</code>.</p> <pre><code>def create_graph_proj(tx):\n</code></pre> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query.</p> Returns <p>The function does not return any values. It performs an operation within the Neo4j database to create a graph project for subsequent GDS operations.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#detect-community","title":"Detect Community","text":"<p>The <code>detect_community</code> function performs community detection on a projected graph in Neo4j using the Louvain algorithm from the Graph Data Science (GDS) library. This algorithm is used to identify clusters or communities within the graph. The results of the community detection are written back to the nodes with a property called community.</p> <pre><code>def detect_community(tx):\n</code></pre> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query.</p> Returns <p>The function does not return any values. It performs an operation within the Neo4j database to execute the Louvain community detection algorithm and write the detected community information back to the nodes in the graph.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#retrieve-predicted-cluster","title":"Retrieve Predicted Cluster","text":"<p>The <code>return_pred_cluster</code> function retrieves the predicted cluster assignments for articles from a Neo4j graph database. It queries the graph to retrieve details of each article, including its ID, title, URL, body content, and the detected community (i.e. cluster label) to which it belongs. The results are ordered by community and returned as a Pandas DataFrame.</p> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query</p> Returns <p><code>df</code> (<code>pd.DataFrame</code>): A DataFrame consisting of the following columns:</p> <ul> <li><code>id</code> (<code>int</code>): The unique identifier for the article</li> <li><code>title</code> (<code>str</code>): The title of the article</li> <li><code>url</code> (<code>str</code>): The URL of the article</li> <li><code>body_content</code> (<code>str</code>):  The body content of the article.</li> <li><code>cluster</code> (<code>int</code>): the community/cluster label to which the article has been assigned to</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#get-cluster-size","title":"Get Cluster Size","text":"<p>The <code>get_cluster_size</code> function analyzes the sizes of clusters predicted by the clustering algorithm. It groups the articles by their cluster assignment, calculates the size of each cluster, and then categorises these sizes into bins of size 5. The function returns a DataFrame summarizing the number of clusters within each size range, including a count of single unclustered articles.</p> <pre><code>def get_cluster_size(pred_cluster, column_name=\"cluster\"):\n</code></pre> Parameters <p><code>pred_cluster</code> (<code>pd.DataFrame</code>): A DataFrame of predicted cluster with a cluster column with column name defined in <code>column_name</code> parameter.</p> <p><code>column_name</code> (<code>str</code>): Column name of the cluster label.</p> Returns <p><code>cluster_size</code> (<code>pd.DataFrame</code>): DataFrame containing the size of each cluster in bins of size 5.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#get-clustered-nodes","title":"Get Clustered Nodes","text":"<p>This <code>get_clustered_nodes</code> function retrieves information about each pair of nodes and their connections within a Neo4j graph database. It executes a Cypher query to match nodes and their relationships, returning details about the nodes, their similarities and cluster information.</p> <pre><code>def get_clustered_nodes(tx):\n</code></pre> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query</p> Returns <p><code>df</code> (<code>pd.DataFrame</code>): A DataFrame consisting of the following columns:</p> <ul> <li><code>node_1_id</code>: Identifier of the first node</li> <li><code>node_2_id</code>: Identifier of the second node</li> <li><code>node_1_title</code>: Title of the first node</li> <li><code>node_2_title</code>: Title of the second node</li> <li><code>edge_weight</code>: Similarity score between the two nodes</li> <li><code>node_1_pred_cluster</code>: Community (cluster label) of the first node</li> <li><code>node_2_pred_cluster</code>: Community (cluster label) of the second node</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#get-unclustered-nodes","title":"Get Unclustered Nodes","text":"<p>The <code>get_unclustered_nodes</code> function retrieves details about nodes in a Neo4j graph database that do not have any relationships with other nodes. It executes a Cypher query to obtain nodes that are isolated.</p> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query</p> Returns <p><code>df</code> (<code>pd.DataFrame</code>): A DataFrame consisting of the following columns:</p> <ul> <li><code>node_title</code>: Title of the first node</li> <li><code>node_community</code>: Predicted community cluster of the node</li> <li><code>node_meta_desc</code>: Meta Description of the node</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_clusters/#count-articles","title":"Count Articles","text":"<p>The <code>count_articles</code> function retrieves the count of articles grouped by their community assignment from a Neo4j graph database. It executes a Cypher query to match nodes with the article label, aggregate them by their cluster, and count the number of articles in each cluster. The results are ordered by community.</p> Parameters <p><code>tx</code> (<code>neo4j.Transaction</code>): A Neo4j transaction object used to execute the Cypher query</p> Returns <p><code>df</code> (<code>pd.DataFrame</code>): A DataFrame consisting of the following columns:</p> <ul> <li><code>cluster</code>: Community (cluster label)</li> <li><code>article_count</code>: The number of articles in each community</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/","title":"Sub-clusters","text":""},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/#get-embeddings","title":"Get Embeddings","text":"<p>The <code>get_embeddings</code> processes a DataFrame containing clustered data to extract content embeddings and associated metadata. It then applies UMAP to reduce the dimensionality of the extracted embeddings for further analysis.</p> <pre><code>def get_embeddings(cluster_df, umap_parameters):\n</code></pre> Parameters <p><code>cluster_df</code> <code>(pd.DataFrame)</code>: A DataFrame containing the clustered data with the following relevant columns:</p> <ul> <li><code>id</code> (<code>int</code>): Unique identifier for the article.</li> <li><code>title</code> (<code>str</code>): Title of the article.</li> <li><code>body_content</code> (<code>str</code>): The body content of the article.</li> <li><code>extracted_content_body_embeddings</code> (<code>List[np.ndarray]</code>): Precomputed embeddings of the body content.</li> </ul> <p><code>umap_parameters</code> (<code>Dict[str, int]</code>): A dictionary of parameters for configuring the UMAP model. Expected keys:</p> <ul> <li><code>n_neighbors</code>: The size of the local neighborhood used for manifold approximation.</li> <li><code>n_components</code>: The dimension of the space to which the embeddings will be reduced.</li> </ul> Returns <code>embeddings</code> (<code>np.ndarray</code>): The original embeddings extracted from <code>extracted_content_body_embeddings</code>. <code>doc_titles</code> (<code>List[str]</code>): A list of titles. Extracted from <code>title</code> column of <code>cluster_df</code>. <code>docs</code> (<code>List[str]</code>): A list of article body content. Extracted from <code>body_content</code> column of <code>cluster_df</code>. <code>ids</code> (<code>List[int]</code>): A list of article IDs. Extracted from <code>id</code> column of <code>cluster_df</code>. <code>umap_embeddings</code> (<code>np.ndarray</code>): The embeddings after dimensionality reduction using UMAP."},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/#generate-cluster-keywords","title":"Generate Cluster Keywords","text":"<p>The <code>generate_cluster_keywords</code> function extracts key terms for each cluster from a set of documents using Class-based Term Frequency-Inverse Document Frequency (Class-based TF-IDF). It processes the body content of articles assigned to each cluster, performs lemmatization, and applies Class-based TF-IDF to identify the most significant words for each cluster. The function returns a dictionary where each key is a cluster identifier and the associated value is a list of the top five keywords for that cluster.</p> <pre><code>def (pred_cluster):\n</code></pre> Parameters <p><code>pred_cluster</code> (<code>pd.DataFrame</code>): A DataFrame with the following columns:</p> <ul> <li><code>body_content</code> (<code>str</code>): The article body content from which keywords will be extracted</li> <li><code>new_cluster</code> (<code>int</code>): The cluster assignment for each <code>body_content</code></li> </ul> Returns <code>cluster_keywords_dict</code> (<code>Dict[int,list]</code>): <p>Keys: Cluster ID as indicated in <code>new_cluster</code> column</p> <p>Values: List of top 5 keywords that represents the cluster</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<p>The <code>hyperparameter_tuning</code> function iterates over various combination of HDBSCAN hyperparameters to identify the optimal set that yields the highest clustering quality, as measured by DBCV scores. The parameters being tuned include minimum cluster size (<code>min_cluster_size</code>), minimum samples (<code>min_samples</code>) and the distance metric (<code>metric</code>).</p> <pre><code>def hyperparameter_tuning(embeddings):\n</code></pre> Parameters <p><code>embeddings</code> (<code>np.ndarray</code>): A numpy array of embeddings representing the data points to be used. This can be original <code>embeddings</code> or <code>umap_embeddings</code> obtained from <code>get_embeddings</code> function.</p> Returns <p><code>best_parameters</code> (<code>Dict[str, Union[int,str]]</code>): A dictionary containing the optimal set of HDBSCAN hyperparameters. Expected keys:</p> <ul> <li><code>min_cluster_size</code> (<code>int</code>): The optimal minimum cluster size, selected from the range <code>[2,3,4,5,6]</code></li> <li><code>min_samples</code> (<code>int</code>): The optimal minimum number of samples, selected from the range <code>[1,2,3,4,5,6,7]</code></li> <li><code>cluster_selection_method</code> (<code>str</code>): The optimal method for selecting clusters, with <code>\"leaf\"</code> being used in this tuning process (though <code>\"eom\"</code> can also be included as an option).</li> <li><code>metric</code> (<code>str</code>): The optimal distance metric, selected from <code>[\"euclidean\", \"manhattan\"]</code>.</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/#topic-modelling","title":"Topic Modelling","text":"<p>The <code>topic_modelling</code> function constructs and configures a BERTopic model to perform topic modeling on textual data. It utilises HDBSCAN for clustering reduced embeddings and allows for optional fine-tuning of topic representations. The function performs the following steps:</p> <ol> <li>Cluster Reduced Embeddings: Uses HDBSCAN to cluster the reduced embeddings based on the specified hyperparameters.</li> <li>Tokenize Topics: Uses <code>CountVectorizer</code> to tokenise the text data, excluding common English stop words.</li> <li>Create Topic Representation: Applies the <code>ClassTfidfTransformer</code> to extract topic words from the tokenized data.</li> <li>Optional Fine-Tuning: Optionally fine-tunes the topic representations using <code>MaximalMarginalRelevance</code> to enhance diversity.</li> <li>Return BERTopic Model: Returns the fully configured BERTopic model ready for use in topic modeling.</li> </ol> <pre><code>def topic_modelling(hyperparameters)\n</code></pre> Parameters <code>hyperparameters</code> (<code>Dict[str, Union[int, str]</code>): A dictionary containing the hyperparameters for HDBSCAN clustering, including: <ul> <li><code>min_cluster_size</code> (<code>int</code>): The minimum size of clusters.</li> <li><code>min_samples</code> (<code>int</code>): The minimum number of samples in a neighborhood for a point to be considered a core point.</li> <li><code>cluster_selection_method</code> (<code>str</code>): The method for selecting clusters.</li> <li><code>metric</code> (<code>str</code>): The distance metric to be used for clustering.</li> </ul> Returns <p><code>topic_model</code> (<code>BERTopic</code>): A BERTopic model object configured with the specified HDBSCAN parameters, a vectorizer for tokenizing topics, a c-TFIDF transformer for creating topic representations, and an optional representation model for fine-tuning topics.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/#create-topic-assigner","title":"Create Topic Assigner","text":"<p>The <code>create_topic_assigner</code> function generates a closure that assigns new topic numbers to elements based on a specified starting counter. This is particularly useful for assigning unique topic numbers to unclustered data points (labelled as <code>-1</code> in HBDSCAN) so that each unclustered point will be assigned a unique value.</p> <pre><code>def create_topic_assigner(start_counter)\n</code></pre> Parameters <p><code>start_counter</code> (<code>int</code>): The initial value for the topic counter, typically set as the max value +1 of the clustered data points. This counter will be incremented each time a new topic is assigned.</p> Returns <p><code>assign_new_topic</code> (<code>function</code>): A function that takes an input value <code>x</code> and assigns a new topic number if <code>x</code> equals <code>-1</code>. If <code>x</code> is not <code>-1</code>, the original value is returned unchanged.</p>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/#process-cluster","title":"Process Cluster","text":"<p>The <code>process_cluster</code> function processes a DataFrame of clustered data to extract embeddings (<code>get_embeddings</code> function), perform hyperparameter tuning (<code>hyperparameter_tuning</code> function), configure BERTopic model (<code>topic_modelling</code> function) and apply topic modeling. It assigns topics to each document, extracts relevant keywords, and ensures that unclustered data points are assigned unique topic numbers. The function involves the following steps:</p> <ol> <li>Extract embeddings: Extracts both the original and UMAP-reduced embeddings from the input DataFrame, using <code>get_embeddings</code> function.</li> <li>Hyperparameters Tuning: Tunes HDBSCAN hyperparameters using the UMAP-reduced embeddings, using <code>hyperparameter_tuning</code> function.</li> <li>Fit topic model: Creates and fits a BERTopic model to the document data, using <code>topic_modelling</code> function.</li> <li>Construct DataFrame: Constructs a DataFrame with the assigned topics, document titles, and IDs.</li> <li>Merge keywords: Extracts and merges the top 5 keywords for each topic into the DataFrame.</li> <li>Assign new topics: Assigns new topic numbers to unclustered data points (those with a topic value of -1), using <code>create_topic_assigner</code> function.</li> <li>Update topic information: Updates the Assigned Topic column to include cluster information, ensuring there are no repeated topic numbers across clusters.</li> </ol> <pre><code>def process_cluster(cluster_df, umap_parameters):\n</code></pre> Parameters <p><code>cluster_df</code> <code>(pd.DataFrame)</code>: A DataFrame containing the clustered data with the following relevant columns:</p> <ul> <li><code>id</code> (<code>int</code>): Unique identifier for the article.</li> <li><code>title</code> (<code>str</code>): Title of the article.</li> <li><code>body_content</code> (<code>str</code>): The body content of the article.</li> <li><code>extracted_content_body_embeddings</code> (<code>List[np.ndarray]</code>): Precomputed embeddings of the body content.</li> </ul> <p><code>umap_parameters</code> <code>(Dict[str, int])</code>: A dictionary of parameters for configuring the UMAP model. Expected keys:</p> <ul> <li><code>n_neighbors</code>: The size of the local neighborhood used for manifold approximation.</li> <li><code>n_components</code>: The dimension of the space to which the embeddings will be reduced.</li> </ul> Returns <p><code>result_df_kws</code> (<code>pd.DataFrame</code>): A DataFrame containing the following columns:</p> <ul> <li><code>id</code> (<code>int</code>): Unique identifier for each document.</li> <li><code>Title</code> (<code>str</code>): Titles of the documents.</li> <li><code>Assigned Topic</code> (<code>str</code>): The final assigned topic.</li> <li><code>top_5_kws</code> (<code>List[str]</code>): The top 5 keywords representing each topic.</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/clustering/nodes/utilities/utils_subclusters/#process-all-clusters","title":"Process All Clusters","text":"<p>The <code>process_all_clusters</code> function processes multiple clusters of data that needs to go through subclustering and apply the <code>process_cluster</code> function to each cluster individually. It consolidates the results into a single DataFrame.</p> <pre><code>def process_all_clusters(cluster_morethan_threshold, umap_parameters):\n</code></pre> Parameters <code>cluster_morethan_threshold</code> (<code>pd.DataFrame</code>): A DataFrame containing the data for clusters that exceed a specified threshold size. This DataFrame should include a cluster column that indicates the cluster assignment for each data point. <p><code>umap_parameters</code> (<code>Dict[str, int]</code>): A dictionary of parameters for configuring the UMAP model. Expected keys:</p> <ul> <li><code>n_neighbors</code>: The size of the local neighborhood used for manifold approximation.</li> <li><code>n_components</code>: The dimension of the space to which the embeddings will be reduced.</li> </ul> Returns <code>combined_df</code> (<code>pd.DataFrame</code>): A DataFrame that consolidates the results from processing each cluster. This DataFrame contains the combined <code>result_df_kws</code> output of the <code>process_cluster</code> function applied to each individual cluster."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/","title":"Data Processing","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/#introduction","title":"Introduction","text":"<p>Our primary goal is to merge the articles across different content categories. This is to facilitate the use of this dataset for downstream applications e.g. Clustering or Retrieval Augmented Generation (RAG).</p> <p>In this pipeline, we focus on the following:</p> <ol> <li>Standardising the column names</li> <li>Adding back the missing data</li> <li>Extracting the Content Body from its Raw HTML</li> <li>Performing its new category (IA) mappings</li> <li>Merging all of these data into 1 dataframe</li> </ol>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/#setting-up-the-project","title":"Setting up the Project","text":"<ol> <li>Download the <code>GenAI - Full Content Export.zip</code> file.</li> <li>Extract all the Excel files and place them in the <code>content-optimization/data/01_raw</code> directory of the Kedro pipeline.</li> <li>Download the <code>missing_contents.zip</code> file.</li> <li>Extract and move the [<code>missing_contents</code>] directory to the <code>content-optimization/data/01_raw</code> directory of the Kedro pipeline.</li> <li>Refer to the <code>README.md</code> to setup and run the Kedro Pipeline</li> </ol> <p>Note</p> <p>We are only interested in running the <code>data_processing</code> pipeline. To do so, run the following command after setting up the virtual environment and its dependecies - <pre><code>cd content-optimization\n# Run the Data processing pipeline\nkedro run --pipeline=data_processing\n</code></pre></p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/#adding-new-kedro-nodes","title":"Adding new Kedro nodes","text":"<p>When adding new kedro nodes, it is important to understand the key processes that accompany it. You will usually add the filepath(s) to the Data Catalog, supplement the required parameters and write your functions.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/#data-catalog","title":"<code>Data Catalog</code>","text":"<p>The Data Catalog is one of the most important files in the Kedro Pipeline. It indicates where your files are located in the project. Kedro handles the loading and saving of data on your behalf. You do not need to specify it in your nodes.</p> <p>Here is an example of how to define it:</p> <pre><code># Variable Name/Dictionary Key\nmerged_data:\n  # File Type - Refer to kedro-datasets (https://docs.kedro.org/projects/kedro-datasets/en/kedro-datasets-4.1.0/api/kedro_datasets.html) for the appropriate data connector\n  type: pandas.ParquetDataset\n  # File Path - Indicate where to save/load the desired file\n  filepath: data/03_primary/merged_data.parquet\n  # Data Versioning - Indicate whether you want to only obtain the latest file or track the changes (via timestamp)\n  versioned: true\n</code></pre> <p>Once you have defined your variables, you can use them in your Kedro pipeline.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/#parameters","title":"<code>Parameters</code>","text":"<p>The Parameters are used to store any static definition of variables in the Kedro Pipeline. Each Pipeline has its own set of parameters. We do not hardcode any values in the code. We retrieve it from this file.</p> <p>Here is an example of the defining the interested columns for the <code>cost-and-financing</code> Excel file -</p> <pre><code># Dictionary Key to reference our columns of interest\ncolumns_to_keep:\n  # Dictionary Key to reference the content category\n  cost-and-financing:\n    # List defining the columns that we are interested in\n    - id\n    - Content.Name\n    - CostAndFinancing_Title\n    - CostAndFinancing_ArticleCatNames\n    - CostAndFinancing_CoverImgUrl\n    - CostAndFinancing_FullUrl\n    - CostAndFinancing_FullUrl2\n    - CostAndFinancing_FriendlyUrl\n    - CostAndFinancing_CategoryDesc\n    - CostAndFinancing_ContentBody\n    - CostAndFinancing_ENKeywords\n    - CostAndFinancing_FeatureTitle\n    - CostAndFinancing_PRName\n    - CostAndFinancing_AlternateImageText\n    - CostAndFinancing_DateModified\n    - CostAndFinancing_NumberofViews\n    - CostAndFinancing_LastMonthViewCount\n    - CostAndFinancing_LastTwoMonthsView\n    - Page Views\n    - Engagement Rate\n    - Bounce Rate\n    - Exit Rate\n    - Scroll %\n    - \"% of Total Views\"\n    - Cumulative % of Total Views\n</code></pre> <p>Warning</p> <p>Do not mess the order of the columns in the <code>parameters_data_processing.yml</code> file. If you really need to amend it, ensure that the <code>columns_to_keep</code> have the same order as <code>default_columns</code> (i.e. <code>columns_to_keep -&gt; default_columns</code>). This is needed because we do not perform any validation in the code to check if the mapping is correctly. This mapping is implicitly defined via this configuration file.</p> <p>After defining your data variables and the parameters required for your function, we can proceed to the writing our function.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/#nodes","title":"<code>Nodes</code>","text":"<p>Here is where we define our functions to transform our data. A node is merely a step within the Kedro Pipeline that performs a set of transformations. When writing your node functions, you should do the following -</p> <ol> <li>Name your node as an <code>action</code> (i.e. it should start with a verb).</li> <li>Keep your implementation succinct. If your function requires a multiple functions or has a long implementation, you should consider creating a new Python file and import the main function over to <code>nodes.py</code>.</li> <li>Ensure that your input and output variables can be found either in your Data Catalog <code>catalog.yml</code> or Parameters <code>parameters_data_processing.yml</code>. We prefer to use the same variable names as defined in these configuration files for better clarity.</li> </ol> <p>Once we have created the node(s), we can now integrate them into the Kedro Pipeline.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/#pipeline","title":"<code>Pipeline</code>","text":"<p>This is the easiest part of the Kedro pipeline. To integrate the new node, just add a new node function to the pipeline.</p> <p>Warning</p> <p>The nodes in the Kedro pipeline are ordered. Do not mess the order of these nodes as we are generating the files dynamically from the input files. Each node function has dependencies that are generated by preceding nodes.</p> <p>Here is an example -</p> <pre><code>def create_pipeline(**kwargs) -&gt; Pipeline:\n    return pipeline(\n        [\n            node(\n                func=standardize_columns,\n                inputs=[\n                    \"all_contents\",\n                    \"params:columns_to_add\",\n                    \"params:columns_to_keep\",\n                    \"params:default_columns\",\n                ],\n                outputs=\"all_contents_standardized\",\n                name=\"standardize_columns_node\",\n            ),\n            node(\n                func=add_data,\n                inputs=[\n                    \"all_contents_standardized\",\n                    \"missing_contents\",\n                    \"params:updated_urls\",\n                ],\n                outputs=\"all_contents_added\",\n                name=\"add_data_node\",\n            ),\n            node(\n                func=extract_data,\n                inputs=[\n                    \"all_contents_added\",\n                    \"params:word_count_cutoff\",\n                    \"params:whitelist\",\n                    \"params:blacklist\",\n                ],\n                outputs=[\"all_contents_extracted\", \"all_extracted_text\"],\n                name=\"extract_data_node\",\n            ),\n            node(\n                func=map_data,\n                inputs=[\n                    \"all_contents_extracted\",\n                    \"params:l1_mappings\",\n                    \"params:l2_mappings\",\n                ],\n                outputs=\"all_contents_mapped\",\n                name=\"map_data_node\",\n            ),\n            node(\n                func=merge_data,\n                inputs=\"all_contents_mapped\",\n                outputs=\"merged_data\",\n                name=\"merge_data_node\",\n            ),\n            # Define a node function\n            node(\n                # The func variable must refer to the node function that you created in nodes.py\n                func=new_func_to_add_here,\n                # Define your inputs based on what was stated in either catalog.yml or parameters_data_processing.yml. Please note that parameters must have a `params:` prefix defined beforehand\n                inputs=[\n                    \"variable_from_data_catalog_file\",\n                    \"params:variable_from_parameters_config_file\"\n                ],\n                # Define your output(s) based on what was stated in catalog.yml\n                outputs=[\n                    \"variable_from_data_catalog_file\"\n                ],\n                # Name your node function. Please append `node` as a postfix. This name is used for visualising the Kedro pipeline\n                name=\"new_func_node\"\n            ),\n        ]\n    )\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/","title":"Flagging Articles for Removal","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#overview","title":"Overview","text":"<p>Based on our Exploratory Data Analysis and requests from either the Clustering or HealthHub Team, we had to flag some articles to be removed from downstream applications. We perform the flagging before and after extracted the processed text from the HTML content.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#flagging-before-extraction","title":"Flagging Before Extraction","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#nan-content-in-content_body","title":"NaN Content in <code>content_body</code>","text":"<p>There is no HTML content present for extraction is the content is null.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#excel-error","title":"Excel Error","text":"<p>This typically occurs when the number of characters exceeds the cell capacity in Excel. As such, we utilised the <code>parquet</code> file format to combat this limitation.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#no-html-tags","title":"No HTML Tags","text":"<p>This typically occurs when test articles that are submitted into the VML system for testing purposes.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#flagging-after-extraction","title":"Flagging After Extraction","text":"<p>Please note that the flagging of articles in this case is ordered due to overlapping flags. We will typically ignore the articles that are already flagged as <code>to_remove</code> before flagging the remaining articles.</p> <p>Additionally, some articles are whitelisted as HealthHub Team wishes to perform Content Optimisation and Harmonisation using these articles. Refer to the <code>whitelist</code> key in <code>parameters_data_processing.yml</code>. Refer to the <code>flag_articles_to_remove_after_extraction</code> function in <code>utils.py</code> for more information.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#no-extracted-content","title":"No Extracted Content","text":"<p>This typically occurs when there are only HTML tags present in the content body. As such, the extracted content is null. This is usually because the article is an infographic.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#recipe-articles","title":"Recipe Articles","text":"<p>HealthHub Team has informed us to exclude recipe articles from Content Optimisation and Harmonisation as these recipes are usually different from one another. Moreover, the current structure is deemed suitable for reading.</p> <p>We perform a keyword search to remove these articles. However, please note that it does not flag all recipe articles as we are using a heuristic.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#duplicated-content","title":"Duplicated Content","text":"<p>We remove duplicated content based on the <code>extracted_content_body</code>. There is a high chance that it refers to the same article or that the article link has been updated.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#duplicated-urls","title":"Duplicated URLs","text":"<p>We remove duplicated content based on the <code>full_url</code>. There is a high chance that it refers to the same article or the article content has been updated.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#multilingual-content","title":"Multilingual Content","text":"<p>We remove Chinese, Malay or Tamil articles as we do not want it to interfere with the clustering algorithm. Moreover, there are future plans to implement a translation process to convert all English articles into Chinese, Malay and Tamil.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#below-word-count","title":"Below Word Count","text":"<p>Some articles have extraordinarily low word counts. We believe that these articles are either short recipes or a brief summary of the infographic embedded in the article. By plotting the Word Count Distribution of all articles, we deemed <code>90 words</code> as the threshold to flag such articles.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/articles_flagged_removal/#blacklisted-articles","title":"Blacklisted Articles","text":"<p>These articles are either flagged during clustering or upon the HealthHub Team's request. Refer to this link for more information. The blacklisted articles are stated as parameters under the <code>blacklist</code> key in the <code>parameters_data_processing.yml</code> file.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/excluded-articles/","title":"Excluded Articles","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/excluded-articles/#overview","title":"Overview","text":"<p>Certain articles were excluded from clustering due to various data issues flagged by the <code>data_processing</code> pipeline, such as duplicated content or being categorized as recipes. Additionally, some were excluded based on user annotations (see section: User Annotation (HH Team))</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/excluded-articles/#remove-type-data-count","title":"Remove Type Data Count","text":"<p>The table below reflects the data count for each remove types for HPB articles:</p> to_remove categories HPB only to_remove articles Counts (final) Flagged/Annotated by Duplicated Content 1 Flagged by data_processing pipeline Duplicated URL 2 Flagged by data_processing pipeline Recipe 45 Flagged by data_processing pipeline + Annotated by HH and included in blacklist Table of Contents 4 Annotated by HH and included in blacklist No relevant content and mainly links 6 Annotated by HH and included in blacklist Service Directory 3 Annotated by HH and included in blacklist Infographic 14 Annotated by HH and included in blacklist LLM is unable to process content due to Azure's content filtering on hate, sexual, violence, and self-harm related categories 1 Annotated in blacklist TOTAL 76"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/excluded-articles/#excluded-content","title":"Excluded content","text":"<p>The <code>excluded_content_tab</code>(in Google Drive under <code>LLM Exploration/Health Hub/User Annotation/Step 1 Harmonisation and Optimisation Checks</code>) file contains articles that should be placed in the 'excluded articles' tab of user annotation Excel sheet. This file is generated using the <code>content-optimization/notebooks/exclude_articles.ipynb</code> notebook.</p> <p>Articles flagged for duplicated URLs or content will be excluded from this tab, as they are considered backend data issues. Specifically, this includes one article (Article ID: 1445972) marked for removal due to \"duplicated content,\" two articles (Article IDs: 1444417, 1445629) flagged for \"duplicated URLs,\" and one article (Article ID: 1445829) identified as a \"recipe.\" The last article was flagged as a recipe first due to the ordering of flags in the data processing pipeline, even though it also had duplicated content.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/excluded-articles/#user-annotation-hh-team","title":"User Annotation (HH Team)","text":"<p>The HH team conducted two rounds of annotation to assess the quality of the clusters generated during the content optimisation process. The annotations were performed using outputs from <code>content-optimization/notebooks/create_annotation_excel_final.ipynb</code> notebook, which generates <code>user_annotation</code> files to be sent to HH team for evaluation.</p> <p>Note</p> <p>The <code>final_pred_cluster</code> file is generated from the first iteration of clustering. Since clustering is dynamic, the clustering results changes with every iteration.</p>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/excluded-articles/#first-round-of-annotation","title":"First Round of Annotation","text":"<p>Annotation Process</p> <ul> <li>The HH Team annotated the \"User Annotation (To Combine)\" tab within the <code>user_annotation</code> file.</li> <li> <p>Articles labelled as \"Individual\" under the \"Action\" tab, and those with remarks in \"algorithm remarks\" column, were shifted to \"User Annotation (To Optimise)\" tab. This includes:</p> </li> <li> <p>66 articles labelled as \"Individual\" by HH team</p> </li> <li>212 articles under <code>final_pred_cluster</code>(in Google Drive under <code>LLM Exploration/Health Hub/Clustering/Final Clustering Result</code> folder) from the first iteration.</li> </ul> <p>Output</p> <ul> <li>The result of this annotation round was saved as <code>user_annotation_25jul.xlsx</code>(in Google Drive under <code>LLM Exploration/Health Hub/User Annotation</code> folder)</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/excluded-articles/#second-round-of-annotation","title":"Second Round of Annotation","text":"<p>Annotation Process</p> <ul> <li>The HH team annotated the \"User Annotation (To Optimise)\" tab based on the first round's output</li> <li>Articles marked with comments containing \"exclude\" under the \"user_annotation [HH's team's comments]\" were removed from optimisation</li> </ul> <p>Output</p> <ul> <li>The result of this annotation was saved as <code>Stage 1 user annotation for HPB_HHcomments_20Aug24.xlsx</code>(in Google Drive under <code>LLM Exploration/Health Hub/User Annotation/Step 1 Harmonisation and Optimisation Checks</code> folder)</li> </ul>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/","title":"Overview","text":"<p>The Data Processing Pipeline consists of 5 nodes:</p> <ol> <li>@label(func) <code>standardize_columns</code>: Standardise the column names of multiple dataframes loaded from the Excel Files</li> <li>@label(func) <code>add_data</code>: Add back the missing contents and updated URLs to the standardised dataframes</li> <li>@label(func) <code>extract_data</code>: Extract tables, links, headers and content from the Raw HTML text</li> <li>@label(func) <code>map_data</code>: Map the articles to its new L1 and L2 IA mappings based on its <code>content_category</code> and <code>article_category_names</code></li> <li>@label(func) <code>merge_data</code>: Merge all the partitioned dataframes (across all content categories) in to a single parquet file <code>merged_data.parquet</code>.</li> </ol>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/add_data/","title":"@label(func) <code>add_data</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/add_data/#overview","title":"Overview","text":"<p>The <code>add_data</code> node helps to add missing HTML text and updated URLs from <code>missing_contents.zip</code> into the standardised dataframe.</p> <p>This function takes in a dictionary of dataframes, where each dataframe is associated with a filename. It then adds back the missing and updated data by performing the following steps:</p> <ol> <li>Fetches missing content from text files to correct Excel errors.</li> <li>Adds content body to the dataframe for each content category.</li> <li>Updates URLs in the dataframe.</li> <li>Flags articles that should be removed before extraction.</li> </ol> <p>The function returns a dictionary mapping content categories to the updated dataframes.</p> <pre><code>def add_data(\n    all_contents_standardized: dict[str, Callable[[], Any]],\n    missing_contents: dict[str, Callable[[], Any]],\n    updated_urls: dict[str, dict[int, str]],\n) -&gt; dict[str, Callable[[], Any]]:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/add_data/#parameters","title":"Parameters","text":"<code>all_contents_standardized</code> (<code>dict[str, Callable[[], Any]]</code>): A dictionary where keys are content categories and values are functions that return dataframes of standardized content. Refer to the Data Catalog for more information. <code>missing_contents</code> (<code>dict[str, Callable[[], Any]]</code>): A dictionary where keys are file paths and values are functions that load the content of text files. Refer to the Data Catalog for more information. <code>updated_urls</code> (<code>dict[str, dict[int, str]]</code>): A dictionary where keys are content categories and values are dictionaries mapping the article IDs to updated URLs. This uses the <code>columns_to_keep</code> parameter from <code>parameters_data_processing.yml</code>."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/add_data/#returns","title":"Returns","text":"<code>all_contents_added</code>: Returns a set of parquet files corresponding to the content categories. These files are saved at <code>data/02_intermediate/all_contents_added</code>. Refer to the <code>all_contents_added</code> key in the Data Catalog"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/add_data/#note","title":"Note","text":"Some articles will be flagged for removal before extraction. Refer to the <code>flag_articles_to_remove_before_extraction</code> function in <code>utils.py</code> for more information."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/extract_data/","title":"@label(func) <code>extract_data</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/extract_data/#overview","title":"Overview","text":"<p>The <code>extract_data</code> node helps to extract data from the updated dataframes and stores it in parquet files and text files.</p> <p>This function takes in a dictionary of dataframes, where each dataframe is associated with a filename. It then extracted various data by performing the following steps:</p> <ol> <li>Check if the article is flagged for removal via the <code>to_remove</code> column</li> <li>Check if the HTML content contains a table and/or an image</li> <li>Extracts the related sections, tables, URLs, headers, image links and processed text via BeautifulSoup</li> <li>Flags articles that should be removed after extraction.</li> </ol> <p>The function returns a tuple containing a dictionary mapping content categories to the updated dataframes and a dictionary mapping the filenames to the extracted texts as a <code>.txt</code> file.</p> <pre><code>def extract_data(\n    all_contents_added: dict[str, Callable[[], Any]],\n    word_count_cutoff: int,\n    whitelist: list[int],\n    blacklist: dict[int, str],\n) -&gt; tuple[dict[str, pd.DataFrame], dict[str, str]]:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/extract_data/#parameters","title":"Parameters","text":"<code>all_contents_added</code> (<code>dict[str, Callable[[], Any]]</code>): A dictionary where keys are content categories and values are functions that return dataframes of the updated content. Refer to the Data Catalog for more information. <code>word_count_cutoff</code> (<code>int</code>): The minimum number of words in an article to be considered before flagging for removal. This uses the <code>word_count_cutoff</code> parameter from <code>parameters_data_processing.yml</code>. <code>whitelist</code> (<code>list[int]</code>): The list of article IDs to keep. This uses the <code>whitelist</code> parameter from <code>parameters_data_processing.yml</code>. <code>blacklist</code> (<code>dict[int, str]</code>): A dictionary containing the article IDs and the reason to remove it. This uses the <code>blacklist</code> parameter from <code>parameters_data_processing.yml</code>."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/extract_data/#returns","title":"Returns","text":"<code>all_contents_extracted</code>: Returns a set of parquet files corresponding to the content categories. These files are saved at <code>data/02_intermediate/all_contents_extracted</code>. Refer to the <code>all_contents_extracted</code> key in the Data Catalog <code>all_extracted_text</code>: Returns a set of <code>.txt</code> files corresponding to the content categories. These files are saved at <code>data/02_intermediate/all_extracted_text</code>. Refer to the <code>all_extracted_text</code> key in the Data Catalog"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/extract_data/#note","title":"Note","text":"Some articles will be flagged for removal after extraction. Refer to the <code>flag_articles_to_remove_after_extraction</code> function in <code>utils.py</code> for more information."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/map_data/","title":"@label(func) <code>map_data</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/map_data/#overview","title":"Overview","text":"<p>The <code>map_data</code> node helps to map the article to L1 and L2 Information Architecture (IA) categories. Refer to this IA Mappings document for more information.</p> <p>This function takes in a dictionary of dataframes, where each dataframe is associated with a filename. It then applies the mappings by performing the following steps:</p> <ol> <li>Invert the provided L1 and L2 mappings for each content category</li> <li>Applies the new mappings as new columns - <code>l1_mappings</code> and <code>l2_mappings</code> using the <code>article_category_names</code> column value</li> </ol> <p>The function returns a dictionary mapping content categories to the updated dataframes - new columns are inserted into the dataframe.</p> <pre><code>def map_data(\n    all_contents_extracted: dict[str, Callable[[], Any]],\n    l1_mappings: dict[str, dict[str, list[str]]],\n    l2_mappings: dict[str, dict[str, list[str]]],\n) -&gt; dict[str, Callable[[], Any]]:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/map_data/#parameters","title":"Parameters","text":"<code>all_contents_extracted</code> (<code>dict[str, Callable[[], Any]]</code>): A dictionary where keys are content categories and values are functions that return dataframes with the extracted content. Refer to the Data Catalog for more information. <code>l1_mappings</code> (<code>dict[str, dict[str, list[str]]]</code>): A dictionary of L1 category mappings. The outer key is the content category, inner key is the target (new) category, and the value is a list of source (old) categories. This uses the <code>l1_mappings</code> parameter from <code>parameters_data_processing.yml</code>. <code>l2_mappings</code> (<code>dict[str, dict[str, list[str]]]</code>): A dictionary of L2 category mappings, structured similarly to <code>l1_mappings</code>. This uses the <code>l2_mappings</code> parameter from <code>parameters_data_processing.yml</code>."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/map_data/#returns","title":"Returns","text":"<code>all_contents_mapped</code>: Returns a set of parquet files corresponding to the content categories. These files are saved at <code>data/02_intermediate/all_contents_mapped</code>. Refer to the <code>all_contents_mapped</code> key in the Data Catalog"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/merge_data/","title":"@label(func) <code>merge_data</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/merge_data/#overview","title":"Overview","text":"<p>The <code>merge_data</code> node helps to merge the data from multiple partitioned dataframes.</p> <p>This function takes in a dictionary of dataframes, where each dataframe is associated with a filename. It then concatenates all the dataframes into a single one, returning a single pandas dataframe where all articles (from various content categories) can be retrieved.</p> <pre><code>def merge_data(\n        all_contents_mapped: dict[str, Callable[[], Any]]\n) -&gt; pd.DataFrame:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/merge_data/#parameters","title":"Parameters","text":"<code>all_contents_mapped</code> (<code>dict[str, Callable[[], Any]]</code>): A dictionary where keys are content categories and values are functions that return dataframes with the mappings. Refer to the Data Catalog for more information."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/merge_data/#returns","title":"Returns","text":"<code>merged_data</code>: Returns a parquet file (versioned based on the time of execution). The file is saved at <code>data/03_primary/merged_data.parquet</code>. A new file is generated each time the <code>data_processing</code> pipeline is executed. Refer to the <code>merged_data</code> key in the Data Catalog"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/standardize_columns/","title":"@label(func) <code>standardize_columns</code>","text":""},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/standardize_columns/#overview","title":"Overview","text":"<p>The <code>standardize_columns</code> node helps to standardise the columns across multiple Excel files from <code>GenAI - Full Content Export.zip</code>.</p> <p>This function takes in a dictionary of dataframes, where each dataframe is associated with a filename. It then standardizes the columns of each dataframe by performing the following steps:</p> <ol> <li>Get the content category from the filename.</li> <li>Load the dataframe using the provided partition function.</li> <li>Standardize the column names by selecting and renaming the columns.</li> <li>Mark articles with no content or with dummy content in the <code>to_remove</code> column.</li> <li>Add the standardized dataframe to the <code>all_contents_standardized</code> dictionary.</li> </ol> <p>The function returns a dictionary mapping content categories to the standardized dataframes.</p> <pre><code>def standardize_columns(\n    all_contents: dict[str, Callable[[], Any]],\n    columns_to_add_cfg: dict[str, list[str]],\n    columns_to_keep_cfg: dict[str, list[str]],\n    default_columns: list[str],\n) -&gt; dict[str, pd.DataFrame]:\n</code></pre>"},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/standardize_columns/#parameters","title":"Parameters","text":"<code>all_contents</code> (<code>dict[str, Callable[[], Any]]</code>): A dictionary containing the raw <code>partitions.PartitionedDataset</code>where the keys are the filenames and the values loads the raw excel data as <code>pandas.DataFrame</code>. Refer to the Data Catalog for more information. <code>columns_to_add_cfg</code> (<code>dict[str, list[str]]</code>): A dictionary mapping content categories to lists of column names to add. These missing columns are added to facilitate an efficient way of standardising the columns across all dataframes. This uses the <code>columns_to_add</code> parameter from <code>parameters_data_processing.yml</code>. <code>columns_to_keep_cfg</code> (<code>dict[str, list[str]]</code>): A dictionary mapping content categories to lists of column names to keep. These columns are kept for downstream applications. This uses the <code>columns_to_keep</code> parameter from <code>parameters_data_processing.yml</code>. <code>default_columns</code> (<code>list[str]</code>): A list of default column names to rename the columns of the dataframes to. These are the column names of the standardized dataframes. All downstream applications will use these columns for further processing. This uses the <code>default_columns</code> parameter from <code>parameters_data_processing.yml</code>."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/standardize_columns/#returns","title":"Returns","text":"<code>all_contents_standardized</code>: Returns a set of parquet files corresponding to the content categories. These files are saved at <code>data/02_intermediate/all_contents_standardized</code>. Refer to the <code>all_contents_standardized</code> key in the Data Catalog."},{"location":"projects/genai/health-hub/data-pipeline/data_processing/nodes/standardize_columns/#note","title":"Note","text":"Ensure that the order of the <code>columns_to_keep</code> matches the <code>default_columns</code> as we do not validate the mappings."},{"location":"projects/genai/health-hub/webapp/","title":"Introduction (@label(deprecated))","text":""},{"location":"projects/genai/health-hub/webapp/#purpose-of-webapp","title":"Purpose of Webapp","text":"<p>This webapp was created with the intention to allow content creators and stakeholders to annotate similar articles for clustering (grouping) and optimisation. Article harmonisation and optimisation would then happen asynchronously after exporting the annotated articles.</p> <p>Latest branch on GitHub</p> <p>The branch containing the latest backend can be found on the webapp branch.</p> Disclaimer <p>At the time of writing, <code>webapp</code> is in a rough stage as development was halted half way due to a change in priority. The development stage of the <code>backend</code> is slightly better developed as compared to the <code>frontend</code>.</p>"},{"location":"projects/genai/health-hub/webapp/#project-structure","title":"Project Structure","text":"<p>The file structure for the webapp is split into the <code>frontend</code> and <code>backend</code> subfolders, each with its own subdirectory called <code>app</code>.</p> <pre><code>.\n\u251c\u2500\u2500 backend\n\u2502   \u2514\u2500\u2500 app\n\u2514\u2500\u2500 frontend\n    \u2514\u2500\u2500 app\n</code></pre> <p>Other project files pertaining to content optimisation and harmonisation are also located in the root directory.</p>"},{"location":"projects/genai/health-hub/webapp/system-architecture/","title":"System Architecture","text":"<p>This document outlines the general strategy of API interaction between the Frontend and Backend.</p> <p>The overall system of the web application comprises three main systems.</p> <ul> <li>Frontend (Angular)</li> <li>Backend (FastAPI)</li> <li>Database (MongoDB)</li> </ul>"},{"location":"projects/genai/health-hub/webapp/system-architecture/#local-development","title":"Local Development","text":"<pre><code>flowchart LR\n    Frontend\n    Backend\n    subgraph Docker\n        MongoDb[(\"MongoDb\")]\n    end\n\n    Frontend --&gt; Backend\n    Backend --&gt; MongoDb</code></pre> <p>Docker is utilised to containerise <code>MongoDb</code> for local development. While at the time of writing, <code>MongoDb</code> is the choice of database, it is important to note that the backend is designed to be as database-agnostic as possible.</p> <p><code>MongoDb</code> was chosen due to its 'schemaless' design, allowing for fast prototyping and adaptability.</p>"},{"location":"projects/genai/health-hub/webapp/backend/","title":"Introduction","text":"<p>The backend for this webapp has been built with FastAPI as the foundation. Flexibility of the backend was a key criteria for the software architecture. This is done by adhering to Object-Oriented Principles (OOP) for loose coupling.</p> <pre><code>sequenceDiagram\n    participant FE as Frontend\n    participant FA as FastAPI\n    participant DBC as Database Connector\n    participant DB as Database\n\n    FE -&gt;&gt; FA: Makes API request\n    activate FE\n    activate FA\n    FA -&gt;&gt; DBC: Method call\n    activate DBC\n    DBC -&gt;&gt; DB: Database query\n    DB --&gt;&gt; DBC: Records\n    DBC --&gt;&gt; FA: Pydantic or primitive types\n    deactivate DBC\n    FA --&gt;&gt; FE: Serialised Pydantic responses\n    deactivate FA\n    deactivate FE\n</code></pre> <p>The diagram above is a very high level overview of how database interactions should be made -- by using the DbConnector interface to build database connectors. This allows all database queries to be abstracted.</p>"},{"location":"projects/genai/health-hub/webapp/backend/api/endpoints/","title":"Endpoints","text":"<p>The endpoints below are the endpoints that have been implemented.</p> <p>Query Logic and DB Interactions</p> <p>While there are many more endpoints to be desired, it is important to note that the logic to interact with the database has already been implemented. What is left is to connect these endpoints with the <code>DbConnector</code> instance.</p> <p></p>"},{"location":"projects/genai/health-hub/webapp/backend/api/route-organisation/","title":"Route Organisation","text":"<p>Routes are organised by <code>subrouters</code> to organise routes related to their respective categories. The following <code>subrouters</code> have been set up, but not all have been fully configured with endpoints.</p> <ul> <li>Check (for system health checks)</li> <li>Groups</li> <li>Articles</li> <li>Harmonise</li> <li>Ignore</li> <li>Optimise</li> </ul> <p>Endpoints</p> <p>Available endpoints can be found here</p> Revisiting of Endpoints <p>Should this <code>webapp</code> be revisited, the logic to handle 'job' submission should be considered when designing the endpoints, taking into account the logic required to store 'job' transactions.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/","title":"Database Connector","text":"<p>Database Connector is an interface that has to be implemented by classes dedicated for database interactions.</p> <p>As the backend architecture is intended to be modular (closely following OOP concepts), all database interactions must be abstracted by <code>DbConnector</code> interface.</p> <p>The general direction for Database Connector is to be a query executor, whereby all necessary queries are handled by the implemented class. This means that classes that implement this interface must handle parsing of inputs and outputs to match the corresponding <code>Pydantic</code> models.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#overview","title":"Overview","text":"<p>The DbConnector interface provides an abstract class for a query engine abstraction, focusing on executing and parsing database queries tailored for specific data manipulation needs. It encapsulates methods for connecting to the database and managing various entities like articles, groups, edges, and jobs.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelinterface-dbconnector","title":"@label(interface) DbConnector","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#initialisation","title":"Initialisation","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-connect","title":"@label(meth) Connect","text":"<pre><code>async def connect() -&gt; None\n</code></pre> Description Initializes the database connection and completes the setup process."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#group-operations","title":"Group Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-group","title":"@label(meth) Create Group","text":"<pre><code>async def create_group_from_articles(group_name: str, article_ids: List[str]) -&gt; str\n</code></pre> Parameters group_name (str): The name of the group to create. article_ids (List[str]): List of article IDs to include in the group. Returns ID of the newly created group."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-all-groups","title":"@label(meth) Get All Groups","text":"<pre><code>async def get_all_groups() -&gt; List[Group]\n</code></pre> Returns A list of all groups, each populated with their respective ArticleMeta and Edges."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-by-id","title":"@label(meth) Get by ID","text":"<pre><code>async def get_group(group_id: str) -&gt; Group\n</code></pre> Parameters group_id (str): The ID of the group to retrieve. Returns The specified group."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#article-operations","title":"Article Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-articles","title":"@label(meth) Create Articles","text":"<pre><code>async def create_articles(articles: List[Article]) -&gt; List[str]\n</code></pre> Parameters articles (List[Article]): List of articles to be created in the database. Returns List of IDs for the newly created articles."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-all-articles","title":"@label(meth) Get All Articles","text":"<pre><code>async def get_all_articles() -&gt; List[ArticleMeta]\n</code></pre> Returns A list of all articles along with their metadata, excluding article contents to save on memory."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-articles","title":"@label(meth) Get Articles","text":"<pre><code>async def get_articles(article_ids: List[str]) -&gt; List[Article]\n</code></pre> Parameters article_ids (List[str]): List of article IDs to fetch. Returns List of articles with their content."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#edge-operations","title":"Edge Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-edges","title":"@label(meth) Create Edges","text":"<pre><code>async def create_edges(edges: List[Edge]) -&gt; List[str]\n</code></pre> Parameters edges (List[Edge]): List of edges to be created between articles. Returns List of IDs for the created edges."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-edges","title":"@label(meth) Get Edges","text":"<pre><code>async def get_edges(article_ids: List[str]) -&gt; List[Edge]\n</code></pre> Parameters article_ids (List[str]): List of article IDs to fetch edges for. Returns List of edges between the specified articles."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#generated-article-operations","title":"Generated Article Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-generated-articles","title":"@label(meth) Create Generated Articles","text":"<pre><code>async def create_generated_article(generated_articles: List[GeneratedArticle]) -&gt; List[str]\n</code></pre> Parameters generated_articles (List[GeneratedArticle]): List of generated articles to be inserted. Returns List of IDs for the inserted generated articles."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#job-operations","title":"Job Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-job","title":"@label(meth) Create Job","text":"<pre><code>async def create_job(group_id:str, remove_jobs: List[str], optimise_jobs: List[str], ignore_jobs: List[str], combine_jobs: List[str]) -&gt; str\n</code></pre> Parameters group_id (str): ID of the associated group remove_jobs (List[str]): List of <code>RemoveJob</code> IDs. Optimise_jobs (List[str]): List of <code>OptimiseJob</code> IDs. ignore_jobs (List[str]): List of <code>IgnoreJob</code> IDs. combine_jobs (List[str]): List of <code>CombineJob</code> IDs."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-job","title":"@label(meth) Get Job","text":"<pre><code>async def get_job(job_id: str) -&gt; Job\n</code></pre> Parameters job_id Returns Job"},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#combine-job-operations","title":"Combine Job Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-combine-job","title":"@label(meth) Create Combine Job","text":"<pre><code>async def create_combine_job(\n        group_id: str,\n        sub_group_name: str,\n        article_ids: List[str],\n        remarks: str = \"\",\n        context: str = \"\"\n) -&gt; str\n</code></pre> Parameters group_id (str): ID of the parent group. sub_group_name (str): Name of the subgroup to be combined. article_ids (List[str]): IDs of articles to be combined. remarks (str): Optional remarks for the subgroup. context (str): Additional context for the subgroup. Returns ID of the created combine job."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-combine-job","title":"@label(meth) Get Combine Job","text":"<pre><code>async def get_combine_job(job_combine_id: str) -&gt; JobCombine\n</code></pre> Parameters job_combine_id (str): ID of <code>JobCombine</code> Returns Specified combine job record."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-all-combine-jobs","title":"@label(meth) Get All Combine Jobs","text":"<pre><code>async def get_all_combine_jobs() -&gt; List[JobCombine]\n</code></pre> Returns List of all combine job records."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#optimisation-job-operations","title":"Optimisation Job Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-optimise-job","title":"@label(meth) Create Optimise Job","text":"<pre><code>async def create_optimise_job(\n    article_id: str,\n    optimise_title: bool,\n    optimise_meta: bool,\n    optimise_content: bool,\n    title_remarks: str = \"\",\n    meta_remarks: str = \"\",\n    content_remarks: str = \"\"\n) -&gt; str\n</code></pre> Parameters article_id (str): ID of the article to be optimised. optimise_title (bool): True if the title needs to be optimised. optimise_meta (bool): True if the meta description needs to be optimised. optimise_content (bool): True if the content needs to be optimised. title_remarks (str): Optional remarks for title optimisation. meta_remarks (str): Optional remarks for meta optimisation. content_remarks (str): Optional remarks for content optimisation. Returns ID of the created optimisation job."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-optimise-job","title":"@label(meth) Get Optimise Job","text":"<pre><code>async def get_optimise_job(job_optimise_id: str) -&gt; JobOptimise\n</code></pre> Parameters job_optimise_id (str): ID of the optimise job. Returns Specified optimise job record."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-all-optimise-jobs","title":"@label(meth) Get All Optimise Jobs","text":"<pre><code>async def get_all_optimise_jobs() -&gt; List[JobOptimise]\n</code></pre> Returns List of all optimisation job records."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#article-ignoring-operations","title":"Article Ignoring Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-ignore-job","title":"@label(meth) Create Ignore Job","text":"<pre><code>async def create_ignore_job(article_id: str) -&gt; str\n</code></pre> Parameters article_id (str): ID of the article to be ignored. Returns ID of the created ignore job."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-ignore-job","title":"@label(meth) Get Ignore Job","text":"<pre><code>async def get_ignore_job(job_ignore_id: str) -&gt; JobIgnore\n</code></pre> Parameters job_ignore_id (str): ID of the ignore job. Returns Specified ignore job record."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-all-ignore-jobs","title":"@label(meth) Get All Ignore Jobs","text":"<pre><code>async def get_all_ignore_jobs() -&gt; List[JobIgnore]\n</code></pre> Returns List of all ignore job records."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#article-removal-operations","title":"Article Removal Operations","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-create-remove-job","title":"@label(meth) Create Remove Job","text":"<pre><code>async def create_remove_job(article_id: str, remarks: str) -&gt; str\n</code></pre> Parameters article_id (str): ID of the article to be removed. remarks (str): Remarks about why the article is being removed. Returns ID of the created remove job."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-remove-job","title":"@label(meth) Get Remove Job","text":"<pre><code>async def get_remove_job(job_remove_id: str) -&gt; JobRemove\n</code></pre> Parameters job_remove_id (str): ID of the remove job. Returns Specified remove job record."},{"location":"projects/genai/health-hub/webapp/backend/db/db-connector/#labelmeth-get-all-remove-jobs","title":"@label(meth) Get All Remove Jobs","text":"<pre><code>async def get_all_remove_jobs() -&gt; List[JobRemove]\n</code></pre> Returns List of all remove job records."},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/beanie-documents/","title":"Beanie Documents","text":"<p>This file contains the Beanie document types used to interacting with the DB.</p> <p>NOTE: In Beanie, a Link is a special field type used to create a reference between two document types in a MongoDB database. It allows for the establishment of relationships between documents, similar to foreign keys in relational databases.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/beanie-documents/#group-document","title":"Group Document","text":"<pre><code>class GroupDocument(Document):\n    name: str\n    articles: List[Link[\"ArticleDocument\"]]\n    job: Link[\"JobDocument\"] = None\n</code></pre> <p>Description: A Group refers to a cluster of similar articles.</p> <p>Class variables:</p> <ul> <li><code>name</code>: The name of the group.</li> <li><code>articles</code>: A list of articles that belong to the group.</li> <li><code>job</code>: The latest job associated with the group.</li> </ul>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/er-diagram/","title":"ER Diagram","text":"<p>The ER diagram below is the implemented relation of database relations in MongoDb.</p> <pre><code>erDiagram\n  GROUP ||--o{ JOB : has\n  GROUP ||--|{ ARTICLE : has\n  GROUP ||--o| GENERATED_ARTICLE: has\n  GROUP ||--|{ EDGE : has\n  EDGE ||--|| ARTICLE : start\n  EDGE ||--|| ARTICLE : end\n  ARTICLE |{--o| JOB_COMBINE : \"part of\"\n  ARTICLE ||--o| JOB_IGNORE : \"part of\"\n  ARTICLE ||--o| JOB_REMOVE : \"part of\"\n  ARTICLE ||--o| JOB_OPTIMISE : \"part of\"\n  JOB ||--o{ JOB_COMBINE : contains\n  JOB ||--o{ JOB_OPTIMISE : contains\n  JOB ||--o{ JOB_REMOVE : contains\n  JOB ||--o{ JOB_IGNORE : contains</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/","title":"Mongo Connector","text":"<p>Mongo Connector is a concrete class that implements all the abstract method of the Database Connector that is dedicated for intereactions with MongoDB</p> <p>All necessary MongoDB queries are handled by this class. This class also handle parsing of inputs and outputs to match the corresponding <code>Pydantic</code> models.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#overview","title":"Overview","text":"<p>This Python file defines a MongoConnector class that extends a DbConnector base class, specifically tailored for interacting with a MongoDB database using asynchronous operations. It provides methods to connect to the database, initialize the Beanie ODM with specific document models, and perform CRUD operations on various entities such as articles, groups, jobs, and edges. The class includes functionality to create and retrieve articles, groups, and jobs (tasks related to articles), as well as to manage relationships between articles through edges. The connector also converts MongoDB documents into Python objects for easier manipulation within the application.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#methods","title":"Methods","text":""},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#connection","title":"Connection","text":"<ul> <li>connect</li> </ul> <pre><code>async def connect() -&gt; None\n</code></pre> <p>Description: Initializes the connection to MongoDB and completes the setup process.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#group-operations","title":"Group Operations","text":"<ul> <li>create_group_from_articles</li> </ul> <pre><code>async def create_group_from_articles(group_name: str, article_ids: List[str]) -&gt; str\n</code></pre> <p>Parameters:</p> <ul> <li>group_name (str): The name of the group to create.</li> <li>article_ids (List[str]): List of article IDs to include in the group.</li> </ul> <p>Description: Returns: ID of the newly created group.</p> <ul> <li>get_all_groups</li> </ul> <pre><code>async def get_all_groups() -&gt; List[Group]\n</code></pre> <p>Returns: A list of all <code>Group</code>, each populated with their respective <code>ArticleMeta</code> and <code>Edge</code>.</p> <ul> <li>get_group</li> </ul> <pre><code>async def get_group(group_id: str) -&gt; Group\n</code></pre> <p>Parameters:</p> <ul> <li>group_id (str): The ID of the group to retrieve.</li> </ul> <p>Returns: A <code>Group</code> representing the specified group.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#article-operations","title":"Article Operations","text":"<ul> <li>create_articles</li> </ul> <pre><code>async def create_articles(articles: List[Article]) -&gt; List[str]\n</code></pre> <p>Parameters:</p> <ul> <li>articles (List[Article]): List of <code>Article</code> to be created in the database.</li> </ul> <p>Returns: List of IDs for the newly created articles.</p> <ul> <li>get_all_articles</li> </ul> <pre><code>async def get_all_articles() -&gt; List[ArticleMeta]\n</code></pre> <p>Returns: A list of all <code>Article</code> along with their metadata, excluding article contents to save on memory.</p> <ul> <li>get_articles</li> </ul> <pre><code>async def get_articles(article_ids: List[str]) -&gt; List[Article]\n</code></pre> <p>Parameters:</p> <ul> <li>article_ids (List[str]): List of article IDs to fetch.</li> </ul> <p>Returns: List of <code>Article</code> with their content.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#edge-operations","title":"Edge Operations","text":"<ul> <li>create_edges</li> </ul> <pre><code>async def create_edges(edges: List[Edge]) -&gt; List[str]\n</code></pre> <p>Parameters:</p> <ul> <li>edges (List[Edge]): List of <code>Edge</code> to be created between articles.</li> </ul> <p>Returns: List of IDs for the created edges.</p> <ul> <li>get_edges</li> </ul> <pre><code>async def get_edges(article_ids: List[str]) -&gt; List[Edge]\n</code></pre> <p>Parameters:</p> <ul> <li>article_ids (List[str]): List of article IDs to fetch edges for.</li> </ul> <p>Returns: List of <code>Edge</code> between the specified articles.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#generated-article-operations","title":"Generated Article Operations","text":"<ul> <li>create_generated_article</li> </ul> <pre><code>async def create_generated_article(generated_articles: List[GeneratedArticle]) -&gt; List[str]\n</code></pre> <p>Parameters:</p> <ul> <li>generated_articles (List[GeneratedArticle]): List of <code>GeneratedArticle</code> to be inserted.</li> </ul> <p>Returns: List of IDs for the inserted generated articles.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#job-operations","title":"Job Operations","text":"<ul> <li>create_job</li> </ul> <pre><code>async def async def create_job(\n        self,\n        group_id: str,\n        remove_jobs: List[str],\n        optimise_jobs: List[str],\n        ignore_jobs: List[str],\n        combine_jobs: List[str],\n    ) -&gt; str\n</code></pre> <p>Description: This function is triggered upon user submission to create a new job entry in the database. It updates the associated group's job attribute to ensure that the group is linked to only the most recent job.</p> <p>Parameters:</p> <ul> <li>group_id (str): ID of group that this job is created for</li> <li>remove_jobs (List[str]): List of article IDs to be marked as removed</li> <li>optimise_jobs (List[str]): List of article IDs to be marked as optimised</li> <li>ignore_jobs (List[str]): List of article IDs to be marked as ignored</li> <li>combine_jobs (List[str]): List of article IDs to be marked as combine</li> </ul> <p>Returns: ID of newly create job</p> <ul> <li>get_job</li> </ul> <pre><code>async def get_job(self, job_id: str) -&gt; Job\n</code></pre> <p>Parameters:</p> <ul> <li>job_id (str): The ID of the job to retrieve.</li> </ul> <p>Returns: The specified <code>Job</code>.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#job-combine-operations","title":"Job Combine Operations","text":"<ul> <li>create_combine_job</li> </ul> <pre><code>async def create_combine_job(\n    self,\n    group_id: str,\n    sub_group_name: str,\n    article_ids: List[str],\n    remarks: str = \"\",\n    context: str = \"\",\n) -&gt; str\n</code></pre> <p>Parameters:</p> <ul> <li>group_id (str): ID of group that this combine job was created from</li> <li>sub_group_name (str): Name of subgroup</li> <li>article_ids (List[str]): List of article IDs to be added in this subgroup</li> <li>remarks (str): Remarks for the generated article from this job given by the user [Optional]</li> <li>context (str): Context given by the user to add on to the harmonisation process [Optional]</li> </ul> <p>Returns: ID of newly create combine job</p> <p>Note: Checks are implemented to check if a combine job with the same values are already present in the database. If so, the existing combine job ID is returned instead of creating a new one.</p> <ul> <li>get_combine_job</li> </ul> <pre><code>async def get_combine_job(self, job_combine_id) -&gt; JobCombine\n</code></pre> <p>Parameters:</p> <ul> <li>job_combine_id (str): ID of the combine job to retrieve.</li> </ul> <p>Reutrns: The specified <code>JobCombine</code>.</p> <ul> <li>get_all_combine_jobs</li> </ul> <pre><code>async def get_all_combine_jobs() -&gt; List[JobCombine]\n</code></pre> <p>Returns: A list of all <code>JobCombine</code> entries.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#job-optimise-operations","title":"Job Optimise Operations","text":"<ul> <li>create_optimise_job</li> </ul> <pre><code>    async def create_optimise_job(\n        self,\n        article_id: str,\n        optimise_title: bool,\n        optimise_meta: bool,\n        optimise_content: bool,\n        title_remarks: str = \"\",\n        meta_remarks: str = \"\",\n        content_remarks: str = \"\",\n    ) -&gt; str\n</code></pre> <p>Parameters:</p> <ul> <li>article_id (str): ID of article to be optimised</li> <li>optimise_title (bool): Flag to indicate if title should be optimised</li> <li>optimise_meta (bool): Flag to indicate if meta description should be optimised</li> <li>optimise_content (bool): Flag to indicate if content should be optimised</li> <li>title_remarks (str): Remarks for the optimised title given by the user [Optional]</li> <li>meta_remarks (str): Remarks for the optimised meta description given by the user [Optional]</li> <li>content_remarks (str): Remarks for the optimised content given by the user [Optional]</li> </ul> <p>Returns: ID of newly created optimise job</p> <p>Note: Checks are implemented to check if an optimise job with the same values are already present in the database. If so, the existing optimise job ID is returned instead of creating a new one.</p> <ul> <li>get_optimise_job</li> </ul> <pre><code>async def get_optimise_job(self, job_optimise_id) -&gt; JobOptimise\n</code></pre> <p>Parameters:</p> <ul> <li>job_optimise_id (str): ID of the optimise job to retrieve.</li> </ul> <p>Returns: The specified <code>JobOptimise</code>.</p> <ul> <li>get_all_optimise_jobs</li> </ul> <pre><code>async def get_all_optimise_jobs(self) -&gt; List[JobOptimise]:\n</code></pre> <p>Returns: A list of all <code>JobOptimise</code> entries.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#job-ignore-operations","title":"Job Ignore Operations","text":"<ul> <li>create_ignore_job</li> </ul> <pre><code>async def create_ignore_job(self, article_id: str) -&gt; str\n</code></pre> <p>Parameters:</p> <ul> <li>article_id (str): ID of article to be ignored</li> </ul> <p>Returns: ID of newly created ignore job</p> <p>Note: Checks are implemented to check if an ignore job with the same values are already present in the database. If so, the existing ignore job ID is returned instead of creating a new one.</p> <ul> <li>get_ignore_job</li> </ul> <pre><code>async def get_ignore_job(self, job_ignore_id) -&gt; JobIgnore:\n</code></pre> <p>Parameters:</p> <ul> <li>job_ignore_id (str): ID of the ignore job to retrieve.</li> </ul> <p>Returns: The specified <code>JobIgnore</code>.</p> <ul> <li>get_all_ignore_jobs</li> </ul> <pre><code>async def get_all_ignore_jobs(self) -&gt; List[JobIgnore]:\n</code></pre> <p>Returns: A list of all <code>JobIgnore</code> entries.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#job-remove-operations","title":"Job Remove Operations","text":"<ul> <li>create_remove_job</li> </ul> <pre><code>async def create_remove_job(self, article_id: str, remarks: str) -&gt; str\n</code></pre> <p>Parameters:</p> <ul> <li>article_id (str): ID of article to be removed</li> <li>remarks (str): Remarks for the removing the article given by the user</li> </ul> <p>Returns: ID of newly created remove job</p> <ul> <li>get_remove_job</li> </ul> <pre><code>async def get_remove_job(self, job_remove_id) -&gt; JobRemove\n</code></pre> <p>Parameters:</p> <ul> <li>job_remove_id (str): ID of the remove job to retrieve.</li> </ul> <p>Returns: The specified <code>JobRemove</code>.</p> <ul> <li>get_all_remove_jobs</li> </ul> <pre><code>async def get_all_remove_jobs(self) -&gt; List[JobRemove]\n</code></pre> <p>Returns: A list of all <code>JobRemove</code> entries.</p>"},{"location":"projects/genai/health-hub/webapp/backend/db/mongo/mongo-connector/#helper-functions","title":"Helper functions","text":"<ul> <li>__getArticleSimilarity</li> </ul> <pre><code>async def __getArticleSimilarity(articleDoc: ArticleDocument) -&gt; float\n</code></pre> <p>Parameters:</p> <ul> <li>articleDoc (ArticleDocument): The article document to get the edge with the highest similarity</li> </ul> <p>Returns: The highest similarity score from the edges for a given article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/overview/","title":"Overview","text":"<p><code>Pydantic</code> models are used to standardise data types within the backend. While they are used predominantly for generating the correct response schema for API endpoints, they are also used for some database interactions via <code>DbConnector</code>.</p> Relations Edge Group Articles Article ArticleMeta GeneratedArticle Jobs Job JobCombine JobIgnore JobOptimise JobRemove"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/","title":"@label(type) Article Meta","text":"<p>This datatype contains the high level attributes of articles in the system.</p> Python <pre><code>class ArticleMeta(BaseModel):\n    id: str = Field(default=\"\")\n\n    title: str\n    description: str\n    date_modified: str = Field(default=\"\")\n    similarity: float = Field(default=-1)\n\n    keywords: List[str] = Field(default=[])\n    labels: List[str] = Field(default=[])\n\n    pr_name: str\n    content_category: str\n    url: str = Field(default=\"\")\n    cover_image_url: str = Field(default=\"\")\n\n    status: str = Field(default=\"\")\n    engagement_rate: float = Field(default=-1.0)\n    number_of_views: int = Field(default=-1)\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-id","title":"@label(attr) id","text":"<p><code>string</code> Unique identifier for the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-title","title":"@label(attr) title","text":"<p><code>string</code> Title text of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-description","title":"@label(attr) description","text":"<p><code>string</code> SEO description of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-date_modified","title":"@label(attr) date_modified","text":"<p><code>string</code> The date when the article was last modified.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-similarity","title":"@label(attr) similarity","text":"<p><code>float</code> A numerical value representing how similar this article is to others.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-keywords","title":"@label(attr) keywords","text":"<p><code>List[str]</code> A list of keywords associated with the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-labels","title":"@label(attr) labels","text":"<p><code>List[str]</code> A list of labels or tags associated with the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-pr_name","title":"@label(attr) pr_name","text":"<p><code>string</code> The name of the content author for the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-content_category","title":"@label(attr) content_category","text":"<p><code>string</code> The category of content the article belongs to.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-url","title":"@label(attr) url","text":"<p><code>string</code> The URL where the article can be accessed.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-cover_image_url","title":"@label(attr) cover_image_url","text":"<p><code>string</code> The URL of the cover image for the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-status","title":"@label(attr) status","text":"<p><code>string</code> The status of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-engagement_rate","title":"@label(attr) engagement_rate","text":"<p><code>float</code> The engagement rate of the article, typically a percentage.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-meta/#labelattr-number_of_views","title":"@label(attr) number_of_views","text":"<p><code>int</code> The number of times the article has been viewed.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article-status/","title":"@label(type) Article Status","text":"Python <pre><code>class ArticleStatus(Enum):\n    COMBINE: str = \"Combined\"\n    IGNORE: str = \"Ignored\"\n    OPTIMISE: str = \"Optimise\"\n    REMOVE: str = \"Remove\"\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/","title":"@label(type) Article","text":"<p>Article datatype contains meta information (like <code>ArticleMeta</code>), together with the content of the article.</p> PythonActual Implementation <pre><code>class Article(BaseModel):\n    id: str = Field(default=\"\")\n\n    title: str\n    description: str\n    date_modified: str = Field(default=\"\")\n    similarity: float = Field(default=-1)\n\n    keywords: List[str] = Field(default=[])\n    labels: List[str] = Field(default=[])\n\n    pr_name: str\n    content_category: str\n    url: str = Field(default=\"\")\n    cover_image_url: str = Field(default=\"\")\n\n    status: str = Field(default=\"\")\n    engagement_rate: float = Field(default=-1.0)\n    number_of_views: int = Field(default=-1)\n\n    content: str = Field(default=\"\")\n</code></pre> <p>The actual implementation of this class inheirits <code>ArticleMeta</code>.</p> <pre><code>class Article(ArticleMeta):\n    content: str = Field(default=\"\")\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-id","title":"@label(attr) id","text":"<p><code>string</code> Unique identifier for the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-title","title":"@label(attr) title","text":"<p><code>string</code> Title text of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-description","title":"@label(attr) description","text":"<p><code>string</code> SEO description of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-date_modified","title":"@label(attr) date_modified","text":"<p><code>string</code> The date when the article was last modified.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-similarity","title":"@label(attr) similarity","text":"<p><code>float</code> A numerical value representing how similar this article is to others.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-keywords","title":"@label(attr) keywords","text":"<p><code>List[str]</code> A list of keywords associated with the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-labels","title":"@label(attr) labels","text":"<p><code>List[str]</code> A list of labels or tags associated with the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-pr_name","title":"@label(attr) pr_name","text":"<p><code>string</code> The name of the content author for the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-content_category","title":"@label(attr) content_category","text":"<p><code>string</code> The category of content the article belongs to.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-url","title":"@label(attr) url","text":"<p><code>string</code> The URL where the article can be accessed.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-cover_image_url","title":"@label(attr) cover_image_url","text":"<p><code>string</code> The URL of the cover image for the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-status","title":"@label(attr) status","text":"<p><code>string</code> The status of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-engagement_rate","title":"@label(attr) engagement_rate","text":"<p><code>float</code> The engagement rate of the article, typically a percentage.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-number_of_views","title":"@label(attr) number_of_views","text":"<p><code>int</code> The number of times the article has been viewed.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/article/#labelattr-content","title":"@label(attr) content","text":"<p><code>string</code> The article content extracted as a string.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/","title":"@label(type) Generated Article","text":"<p>This section documents the <code>GeneratedArticle</code> class which encapsulates all necessary details of an article generated by the system.</p> Python <pre><code>class GeneratedArticle(BaseModel):\n    id: str = Field(default=\"\")  # Will only be present when retrieving from DB\n\n    title: str = Field()\n    description: str = Field()\n    pr_name: str = Field()\n    content_category: str = Field()\n    url: str = Field(default=\"\")\n\n    status: str = Field(default=\"\")\n\n    date_modified: str = Field(default=\"\")\n\n    # Article peripheral information\n    keywords: List[str] = Field(default=[])\n    labels: List[str] = Field(default=[])\n    cover_image_url: str = Field(default=\"\")\n\n    approved: bool = Field(default=False)\n\n    content: str\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-id","title":"@label(attr) id","text":"<p><code>string</code> Unique identifier for the article, primarily used for database retrieval.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-title","title":"@label(attr) title","text":"<p><code>string</code> The title of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-description","title":"@label(attr) description","text":"<p><code>string</code> A brief description of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-pr_name","title":"@label(attr) pr_name","text":"<p><code>string</code> The name of the content author.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-content_category","title":"@label(attr) content_category","text":"<p><code>string</code> The category under which the article falls.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-url","title":"@label(attr) url","text":"<p><code>string</code> The URL where the article can be accessed.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-status","title":"@label(attr) status","text":"<p><code>string</code> The publication status of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-date_modified","title":"@label(attr) date_modified","text":"<p><code>string</code> The last date the article was modified.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-keywords","title":"@label(attr) keywords","text":"<p><code>List[str]</code> Keywords associated with the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-labels","title":"@label(attr) labels","text":"<p><code>List[str]</code> Labels associated with the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-cover_image_url","title":"@label(attr) cover_image_url","text":"<p><code>string</code> URL of the article's cover image.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-approved","title":"@label(attr) approved","text":"<p><code>bool</code> Whether the article has been approved for publication.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/articles/generated-article/#labelattr-content","title":"@label(attr) content","text":"<p><code>string</code> The full content of the article.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/","title":"<code>Job Combine</code>","text":"Python <pre><code>class JobCombine(BaseModel):\n    group_id: str\n    group_name: str\n    sub_group_name: str\n    remarks: str\n    context: str\n    original_articles: List[Article]\n    generated_article: Optional[GeneratedArticle]\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attr-group_id","title":"<code>attr</code> group_id","text":"<p><code>str</code> The unique identifier for the group associated with the job combine.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attr-group_name","title":"<code>attr</code> group_name","text":"<p><code>str</code> The name of the group associated with the job combine.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attr-sub_group_name","title":"<code>attr</code> sub_group_name","text":"<p><code>str</code> The name of the sub-group within the group.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attr-remarks","title":"<code>attr</code> remarks","text":"<p><code>str</code> Remarks or notes associated with the job combine.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attr-context","title":"<code>attr</code> context","text":"<p><code>str</code> The context or background information relevant to the job combine.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attr-original_articles","title":"<code>attr</code> original_articles","text":"<p><code>List[Article]</code> A list of original articles involved in the job combine.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-combine/#attr-generated_article","title":"<code>attr</code> generated_article","text":"<p><code>Optional[GeneratedArticle]</code> The article generated as a result of combining the original articles.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-ignore/","title":"<code>Job Ignore</code>","text":"<p>This datatype represents a job to ignore specific articles within the system.</p> Python <pre><code>class JobIgnore(BaseModel):\n    article: Article\n    remarks: str\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-ignore/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-ignore/#attr-article","title":"<code>attr</code> article","text":"<p><code>Article</code> The article associated with the ignore job.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-ignore/#attr-remarks","title":"<code>attr</code> remarks","text":"<p><code>string</code> Remarks explaining why the article is ignored.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/","title":"<code>Job Optimise</code>","text":"<p>This datatype represents a job for optimising various aspects of an article within the system.</p> Python <pre><code>class JobOptimise(BaseModel):\n    id: str\n    optimise_title: bool\n    title_remarks: str\n    optimise_meta: bool\n    meta_remarks: str\n    optimise_content: bool\n    content_remarks: str\n\n    original_article: Article\n    generated_article: Optional[GeneratedArticle]\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-id","title":"<code>attr</code> id","text":"<p><code>string</code> Unique identifier for the job.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-optimise_title","title":"<code>attr</code> optimise_title","text":"<p><code>bool</code> Indicates whether the title of the article should be optimised.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-title_remarks","title":"<code>attr</code> title_remarks","text":"<p><code>string</code> Remarks about the title optimisation.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-optimise_meta","title":"<code>attr</code> optimise_meta","text":"<p><code>bool</code> Indicates whether the metadata of the article should be optimised.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-meta_remarks","title":"<code>attr</code> meta_remarks","text":"<p><code>string</code> Remarks about the metadata optimisation.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-optimise_content","title":"<code>attr</code> optimise_content","text":"<p><code>bool</code> Indicates whether the content of the article should be optimised.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-content_remarks","title":"<code>attr</code> content_remarks","text":"<p><code>string</code> Remarks about the content optimisation.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-original_article","title":"<code>attr</code> original_article","text":"<p><code>Article</code> The original article before optimisation.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-optimise/#attr-generated_article","title":"<code>attr</code> generated_article","text":"<p><code>Optional[GeneratedArticle]</code> The article generated after optimisation, if available.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-remove/","title":"<code>Job Remove</code>","text":"<p>This datatype represents a job removal request and associated metadata within the system.</p> Python <pre><code>class JobRemove(BaseModel):\n    id: str\n    article: Article\n    remarks: str\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-remove/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-remove/#attr-id","title":"<code>attr</code> id","text":"<p><code>string</code> Unique identifier for the job removal request.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-remove/#attr-article","title":"<code>attr</code> article","text":"<p><code>Article</code> The article associated with the job removal.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job-remove/#attr-remarks","title":"<code>attr</code> remarks","text":"<p><code>string</code> Remarks or notes associated with the job removal request.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/","title":"<code>Job</code>","text":"Python <pre><code>class Job(BaseModel):\n    group_id: str\n    created_at: str\n    remove_articles: List[JobRemove] = Field(default=[])\n    ignore_articles: List[JobIgnore] = Field(default=[])\n    optimise_articles: List[JobOptimise] = Field(default=[])\n    combine_articles: List[JobCombine] = Field(default=[])\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/#attr-group_id","title":"<code>attr</code> group_id","text":"<p><code>str</code> The unique identifier for the group associated with the job.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/#attr-created_at","title":"<code>attr</code> created_at","text":"<p><code>str</code> The timestamp when the job was created.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/#attr-remove_articles","title":"<code>attr</code> remove_articles","text":"<p><code>List[JobRemove]</code> A list of articles to be removed from the job.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/#attr-ignore_articles","title":"<code>attr</code> ignore_articles","text":"<p><code>List[JobIgnore]</code> A list of articles to be ignored during the job processing.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/#attr-optimise_articles","title":"<code>attr</code> optimise_articles","text":"<p><code>List[JobOptimise]</code> A list of articles to be optimised as part of the job.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/jobs/job/#attr-combine_articles","title":"<code>attr</code> combine_articles","text":"<p><code>List[JobCombine]</code> A list of articles to be combined during the job processing.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/edge/","title":"<code>Edge</code>","text":"<p>This datatype represents a connection between two nodes in a graph, typically used to represent relationships in a network.</p> Python <pre><code>class Edge(BaseModel):\n    start: str = Field()\n    end: str = Field()\n    weight: float = Field(default=-1.0)\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/edge/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/relations/edge/#attr-start","title":"<code>attr</code> start","text":"<p><code>string</code> The starting node of the edge, this will be the <code>id</code> of an <code>Article</code> or <code>ArticleMeta</code>.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/edge/#attr-end","title":"<code>attr</code> end","text":"<p><code>string</code> The ending node of the edge, this will be the <code>id</code> of an <code>Article</code> or <code>ArticleMeta</code>.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/edge/#attr-weight","title":"<code>attr</code> weight","text":"<p><code>float</code> The weight of the edge, which can represent the strength of the connection or cost associated with the edge. Default is -1.0, indicating an unspecified weight.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/group/","title":"<code>Group</code>","text":"<p>This datatype represents a group of articles and associated metadata within the system.</p> Python <pre><code>class Group(BaseModel):\n    id: str = Field(default=\"\")\n\n    name: str = Field(default=\"\")\n    edges: List[Edge] = Field(default=[])\n\n    articles: List[ArticleMeta] = Field(default=[])  # Articles not reviewed yet\n    job: Job = Field(default=None)\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/group/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/backend/types/relations/group/#attr-id","title":"<code>attr</code> id","text":"<p><code>string</code> Unique identifier for the group.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/group/#attr-name","title":"<code>attr</code> name","text":"<p><code>string</code> Name of the group.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/group/#attr-edges","title":"<code>attr</code> edges","text":"<p><code>List[Edge]</code> A list of edges connecting this group to other entities.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/group/#attr-articles","title":"<code>attr</code> articles","text":"<p><code>List[ArticleMeta]</code> A list of articles metadata that are part of this group.</p>"},{"location":"projects/genai/health-hub/webapp/backend/types/relations/group/#attr-job","title":"<code>attr</code> job","text":"<p><code>Job</code> The job associated with this group.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/","title":"Introduction","text":"<p>The frontend was build with Angular to accommodate for isolation of app logic by using services to abstract logic away from components. Taiga UI was used as the component library.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/frontend-activity-diagram/","title":"Frontend activity diagram","text":"Front End Activity Diagram <pre><code>stateDiagram\n    state if_state &lt;&lt;choice&gt;&gt;\n    state if_state2 &lt;&lt;choice&gt;&gt;\n    state if_state3 &lt;&lt;choice&gt;&gt;\n    state fork_state &lt;&lt;fork&gt;&gt;\n    state join_state &lt;&lt;join&gt;&gt;\n\n    s1: User selects department\n    s2: A group is shown to user\n    s3: Graph view\n    s4: Table view\n    s5: Add article(s) to optimise\n    s6: Add article(s) to ignore\n    s7: Add article(s) to remove\n    s8: Add articles to combine\n    s9: User submits job\n    s10: Job is sent for processing\n    s11: Redirect to jobs page\n\n    [*] --&gt; s1\n    s1 --&gt; s2\n    s2 --&gt; if_state\n    if_state --&gt; s3: Select Graph View\n    if_state --&gt; s4: Select Table View\n    s3 --&gt; fork_state\n    s4 --&gt; fork_state\n    fork_state --&gt; s5\n    fork_state --&gt; s6\n    fork_state --&gt; s7\n    fork_state --&gt; s8\n    s5 --&gt; join_state\n    s6 --&gt; join_state\n    s7 --&gt; join_state\n    s8 --&gt; join_state\n    join_state --&gt; s9\n    s9 --&gt; s10\n    s10 --&gt; s11\n    s11 --&gt; if_state2\n    if_state2 --&gt; [*] : Job has been processed\n    if_state2 --&gt; if_state3 : Job has not been processed\n    if_state3 --&gt; [*] : Delete Job\n    if_state3 --&gt; s2 : Edit Job\n\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/frontend/pipes/date/","title":"Date","text":"<p>This pipe was introduced to format date strings using <code>Moment.js</code> within the component itself.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/pipes/date/#labelpipe-datepipe","title":"@label(pipe) DatePipe","text":"DeclarationUsage (Default)Usage (Defined Format) <pre><code>@Pipe({\n    name: 'date',\n    standalone: true\n})\n</code></pre> <pre><code>&lt;span&gt;{{ data.dateTimeAttribute | date }}&lt;/span&gt;\n</code></pre> <pre><code>&lt;span&gt;{{ data.dateTimeAttribute | date:'YYYY-MM-DD' }}&lt;/span&gt;\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/frontend/pipes/date/#methods","title":"Methods","text":""},{"location":"projects/genai/health-hub/webapp/frontend/pipes/date/#labelmeth-transform","title":"@label(meth) Transform","text":"<pre><code>transform(\n    value: Date | moment.Moment | string,\n    dateFormat: string=\"DD-MM-YYYY\"\n): string\n</code></pre> Description This method converts any datetime format string into a specified format using <code>Momemnt.js</code>. Parameters value(Date|moment.Moment|string): string that contains the original date information dateFormat(string=\"DD-MM-YYYY\"): format for <code>Moment.js</code> to follow for the output. Returns <code>string</code> of date that has been formatted."},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/","title":"Cluster","text":"<p>This service was designed to handle data between the frontend and the backend, as well as managing data for frontend consumption.</p> <p>Outdated naming convention</p> <p>Some of the terminology used in this service is outdated (e.g. <code>Clusters</code> should be refered to as <code>Groups</code>). This document will refer to them in the correct names, but methods currently retain the legacy terminology.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelservice-clusterservice","title":"@label(service) ClusterService","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelprivate-labelattr-all_clusters","title":"@label(private) @label(attr) $all_clusters","text":"<p><code>BehaviorSubject&lt;Cluster[]&gt;</code> stores all unfiltered and unsorted data fetched from the backend.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelprivate-labelattr-clusters","title":"@label(private) @label(attr) $clusters","text":"<p><code>BehaviorSubject&lt;Cluster[]&gt;</code> stores all filtered and sorted data (or is supposed to at least).</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelprivate-labelattr-filters","title":"@label(private) @label(attr) $filters","text":"<p><code>BehaviorSubject&lt;FilterGroup&gt;</code> stores all filters in a key value object.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelprivate-labelattr-sorter","title":"@label(private) @label(attr) $sorter","text":"<p><code>BehaviorSubject&lt;Sorter&gt;</code> stores the sorter that should be used.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#group-methods","title":"Group Methods","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelmeth-fetch-data","title":"@label(meth) Fetch Data","text":"<pre><code>async fetchData():Promise&lt;void&gt;\n</code></pre> Description This method instructs the service to make an API call to the backend, and updates an internal <code>BehaviorSubject</code>, which can be referenced by calling <code>CluserService.getClusters()</code>."},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelmeth-get-groups","title":"@label(meth) Get Groups","text":"<pre><code>getClusters(): BehaviorSubject&lt;Cluster[]&gt;\n</code></pre> Description Calling this method will return a reference to a private <code>BehaviorSubject</code> that keeps track of all <code>Groups</code> stored in memory. The returned <code>BehaviorSubject</code> is subject to filters that has been applied. Returns <code>BehaviorSubject&lt;Cluster[]&gt;</code> that updates whenever <code>$all_clusters</code>, <code>$filters</code>, or <code>$sorter</code> has been changed."},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelmeth-get-group-by-id","title":"@label(meth) Get Group by ID","text":"<pre><code>getCluster(id:string): BehaviorSubject&lt;Cluster&gt;\n</code></pre> Description Fetch a group from memory, by its ID. Parameters id (string): ID of the group. Returns <code>BehaviorSubject&lt;Cluster&gt;</code> which will update if and only if the data itself is changed. This will circumvent all sorts and filters. <p>One way binding</p> <p>While this method returns a <code>BehaviorSubject</code>, it does not update the global state of this cluster. A <code>BehaviorSubject</code> is used in this case so that it will hold a value.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#filter-methods","title":"Filter Methods","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelprivate-labelmeth-apply-filter-to-groups","title":"@label(private) @label(meth) Apply Filter to Groups","text":"<pre><code>private applyFilterToClusters(clusters:Cluster[], filters:FilterGroup):Cluster[]\n</code></pre> Description This method is used to apply all filters to the provided clusters. This logic has been placed in its own function so that it can be reused in the future. It is currently only used when there is a change to <code>ClusterService.$filters</code>. Parameters clusters(Cluster[]): original array of <code>Cluster</code>s (groups). filters(FilterGroup): object containing all the filters that are to be applied. Returns <code>Cluster[]</code> containing an array of residual <code>Cluster</code>s."},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelmeth-add-filter","title":"@label(meth) Add Filter","text":"<pre><code>addFilter(name:string, filter:Filter):void\n</code></pre> Description Adds a filter to a private <code>BehaviorSubject</code> to filter clusters being displayed. Parameters: name(string): Name of the filter. This will be the filter \"key.\" filter(Filter): Filter anonymous function. <p>Not fully implemented</p> <p>While the filter will be updated in its private attribute, the current implementation does not implement the filtering of <code>Group</code>s being retrieved.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelmeth-remove-filter","title":"@label(meth) Remove Filter","text":"<pre><code>removeFilter(name:string):void\n</code></pre> Description Removes a filter by name. Parameters name(string): Name of the filter, the \"key.\""},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#sort-methods","title":"Sort Methods","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/cluster/#labelmeth-update-sort","title":"@label(meth) Update Sort","text":"<pre><code>updateSort(sorter:Sorter):void\n</code></pre> Description Replaces the sorter for the service. Parameters sorter(Sorter): Sorter anonymous function to order clusters. <p>Not fully implemented</p> <p>This method (and related methods) do not appear to be fully implemented.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/","title":"Colour","text":"<p>This service was implemented to generate colour attributes for styling of components. The typical use case would be to use this for labels that are difficult to define by a type.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/#labelservice-colourservice","title":"@label(service) ColourService","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/#labelprivate-labelattr-memoizedlabelcolours","title":"@label(private) @label(attr) memoizedLabelColours","text":"<p><code>Record&lt;string, string&gt;</code> to store memoized calculated <code>hsla()</code> strings when hashing strings.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/#methods","title":"Methods","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/#labelprivate-labelmeth-string-hash","title":"@label(private) @label(meth) String Hash","text":"<pre><code>private stringHash(label:string): number\n</code></pre> Description Method to hash a string into a number. This number will be used for the <code>hue</code> in <code>hsla</code>. Parameters label(string): This will typically be the string that we are trying to create a colour for. Returns A number in the range of \\([1, 360]\\) corresponding to the <code>hue</code> in <code>hsla</code>."},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/#labelmeth-string-hsl","title":"@label(meth) String HSL","text":"<pre><code>stringHSL(label:string): string\n</code></pre> Description Method to convert a string payload into a <code>hsla</code> string for CSS. Parameters label(string): This will typically be the string that we are trying to create a colour for. Returns String that is to be used in CSS. E.g. <code>hsla(252, 20%, 60%, 20%)</code>."},{"location":"projects/genai/health-hub/webapp/frontend/services/colour/#labelmeth-intensity-hsl","title":"@label(meth) Intensity HSL","text":"<pre><code>intensityHSL(val:number, lower:number=0, upper:number=1): string\n</code></pre> Description Method to create a <code>hsl</code> string based on a numeric value, on a range of \\(h\\in[0, 120]\\) which corresponds to a range of red to green hues. Parameters val(number): The number that we are trying to generate a <code>hsla</code> for. lower(number=0): Lower bound value on the scale. upper(number=0): Upper bound value on the scale. Returns String that is to be used in CSS. E.g. <code>hsla(252, 20%, 60%, 20%)</code>."},{"location":"projects/genai/health-hub/webapp/frontend/services/job/","title":"Job","text":"<p>This service was designed to be a singleton to manage <code>GroupManager</code>s across the frontend, allowing components to access the same (and correct) <code>GroupManager</code>.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/job/#labelservice-jobservice","title":"@label(service) JobService","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/job/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/job/#labelattr-groupmanagers","title":"@label(attr) groupManagers","text":"<p><code>Record&lt;string, GroupManager&gt;</code> stores <code>GroupManager</code>s in a key value object.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/services/job/#methods","title":"Methods","text":""},{"location":"projects/genai/health-hub/webapp/frontend/services/job/#labelmeth-initialise","title":"@label(meth) Initialise","text":"<pre><code>initialise(cluster: Cluster): void\n</code></pre> Description Method to initialise a <code>GroupManager</code> and add it to <code>JobService.groupManagers</code>. Parameters cluster(Cluster): <code>Cluster</code> data type."},{"location":"projects/genai/health-hub/webapp/frontend/services/job/#labelmeth-get-group-manager","title":"@label(meth) Get Group Manager","text":"<pre><code>getGroupManager(id:string): GroupManager\n</code></pre> Description Method to get a reference to the <code>GroupManager</code> with specified key. Parameters id(string): the \"key\" that matches the <code>GroupManager</code> in <code>JobService.groupManagers</code>. Returns <code>GroupManager</code>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/","title":"Article","text":"<p>Outdated</p> <p>This type has yet to be updated to follow the changed required in V2.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labeltype-article","title":"@label(type) Article","text":"TypeScript <pre><code>export enum ArticleStatus {\n    Default = \"\",\n    Combined = \"COMBINED\",\n    Ignored = \"IGNORED\"\n}\n\nexport interface Article {\n    id: string,\n    title: string,\n    description: string,\n    pr_name: string,\n    content_category: string,\n    url: string,\n    date_modified: string,\n    status: ArticleStatus,\n    keywords: string[],\n    cover_image_url: string,\n    engagement_rate: number,\n    number_of_views: number\n}\n</code></pre> <p>!!! WARNING \"Deprecation of <code>ArticleStatus</code></p> <pre><code>Article status has been deprecated in favour of organising articles into \"sub-group\" arrays. See `Group` Pydantic type.\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-id","title":"@label(attr) Id","text":"<p><code>string</code> Unique identifier for the article.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-title","title":"@label(attr) Title","text":"<p><code>string</code> Title of the article.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-description","title":"@label(attr) Description","text":"<p><code>string</code> Brief description of the article.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-pr-name","title":"@label(attr) PR Name","text":"<p><code>string</code> Name of the public relations contact or the author.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-content-category","title":"@label(attr) Content Category","text":"<p><code>string</code> Category under which the article falls.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-url","title":"@label(attr) URL","text":"<p><code>string</code> Web address where the article can be accessed.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-date-modified","title":"@label(attr) Date Modified","text":"<p><code>string</code> Last modification date of the article.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-status","title":"@label(attr) Status","text":"<p><code>ArticleStatus</code> Status of the article, which can be Default, Combined, or Ignored.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-keywords","title":"@label(attr) Keywords","text":"<p><code>string[]</code> List of keywords associated with the article.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-cover-image-url","title":"@label(attr) Cover Image URL","text":"<p><code>string</code> URL of the cover image for the article.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-engagement-rate","title":"@label(attr) Engagement Rate","text":"<p><code>number</code> Rate of engagement that the article has received.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/article/#labelattr-number-of-views","title":"@label(attr) Number of Views","text":"<p><code>number</code> Total number of views that the article has accumulated.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/cluster/","title":"Cluster","text":"<p>Outdated terminology</p> <p>This should instead be named \"group\" but has yet to be renamed.</p> <p>Not updated</p> <p>This should mirror the <code>Group</code> Pydantic model from the backend, since that is the response model.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/cluster/#labeltype-cluster","title":"@label(type) Cluster","text":"TypeScript <pre><code>export interface Cluster {\n    id: string,\n    name: string,\n    articles: Article[],\n    edges: Edge[]\n}\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/frontend/types/cluster/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/types/cluster/#labelattr-id","title":"@label(attr) Id","text":"<p><code>string</code> identifier for the cluster.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/cluster/#labelattr-name","title":"@label(attr) Name","text":"<p><code>stirng</code> given name for the cluster.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/cluster/#labelattr-articles","title":"@label(attr) Articles","text":"<p><code>Article[]</code> array of <code>Article</code>'s that are found in the cluster.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/cluster/#labelattr-edges","title":"@label(attr) Edges","text":"<p><code>Edge[]</code> array of <code>Edge</code>'s that connect the <code>Article</code>'s within the cluster.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/edge/","title":"Edge","text":"<p>This edge data type is used in <code>Cluster</code>'s to map a bidirectional connection between two <code>Article</code>'s.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/edge/#labeltype-edge","title":"@label(type) Edge","text":"TypeScript <pre><code>export interface Edge {\n    start: string,\n    end: string,\n    weight: number\n}\n</code></pre> <p>Bidirectional</p> <p>While the <code>Edge</code> type has a <code>start</code> and <code>end</code> attribute, the intended representation is a bidirectional edge between two nodes (<code>Article</code>'s). They are given this attributes soley due to how <code>d3.js</code> handles edges.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/edge/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/types/edge/#labelattr-start","title":"@label(attr) Start","text":"<p><code>string</code> representing the ID of an <code>Article</code>.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/edge/#labelattr-end","title":"@label(attr) End","text":"<p><code>string</code> representing the ID of an <code>Article</code>.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/edge/#labelattr-weight","title":"@label(attr) Weight","text":"<p><code>number</code> weight of the connection between two <code>Article</code>'s, whereby <code>Edge.weight</code> \\(\\in[0,1]\\).</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/groups/","title":"Groups","text":"<p>This is a data type to hold articles in sub-groups, with wildcard names for user defined sub-groups.</p> <p>Outdated</p> <p>Following the direction in V2, this should be named <code>SubGroups</code> instead. Furthermore, the requirement set out by V2 required this type to be updated to facilitate the new features and expected functions.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/groups/#labeltype-groups","title":"@label(type) Groups","text":"TypeScript <pre><code>export interface Groups {\n  default: Article[],\n  combine: Article[],\n  ignore: Article[],\n  [key:string]: Article[]\n}\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/frontend/types/groups/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/types/groups/#labelattr-default","title":"@label(attr) Default","text":"<p><code>Article[]</code> articles that are to be combined by default.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/groups/#labelattr-combine","title":"@label(attr) Combine","text":"<p><code>Article[]</code> articles that have already been combined.</p> <p>Deprecate</p> <p>This should be deprecated, as the intended implementation in V2 should have <code>Article</code>'s loaded into their own respective subgroups, this is to allow the user to submit a new <code>Job</code> after editing.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/groups/#labelattr-ignore","title":"@label(attr) Ignore","text":"<p><code>Article[]</code> articles that should not be combined.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/groups/#labelattr-keystring","title":"@label(attr) [key:string]","text":"<p><code>Article[]</code> articles that belong to a user defined subgroup.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/sorter/","title":"Sorter","text":"<p>This type is used to define a method to sort clusters.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/types/sorter/#labeltype-sorter","title":"@label(type) Sorter","text":"<p>Sorter is a <code>type</code> for an anonymous function to reorder clusters.</p> TypeScript <pre><code>export type sorter = (arg0:Cluster[]) =&gt; Cluster[]\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/","title":"Group Manager","text":"<p>The core functionality of this class was designed to abstract the logic for <code>Articles</code> and their relation to \"sub-groups\" for harmonisation and marking for the various jobs.</p> <p>Incomplete</p> <p>Code in this class is incomplete due to the migration of V1 to V2. While it works for V1, it has not been updated to V2.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#labelclass-groupmanager","title":"@label(class) GroupManager","text":"TypeScriptExample <pre><code>GroupManager.constructor(cluster: Cluster)\n</code></pre> <pre><code>const myGroupManager = new GroupManager(cluster)\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#attributes","title":"Attributes","text":""},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#labelattr-groups","title":"@label(attr) $groups","text":"<p><code>BehaviorSubject&lt;Groups&gt;</code> to keep track of groups and their respective articles.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#methods","title":"Methods","text":""},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#labelmeth-get-grouping","title":"@label(meth) Get Grouping","text":"<pre><code>getGrouping(): BehaviorSubject&lt;Groups&gt;\n</code></pre> Description Method to get current (and future) groupings for articles. Returns <code>BehaviorSubject&lt;Groups&gt;</code>"},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#labelmeth-get-addable-grouping-names","title":"@label(meth) Get Addable Grouping Names","text":"<pre><code>getAddableGroupingNames(): BehaviorSubject&lt;string[]&gt;\n</code></pre> Description Method to get a <code>BehaviorSubject</code> of existing group names that articles can be added to for harmonisation. Returns <code>BehaviorSubject&lt;string[]&gt;</code>"},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#labelmeth-assign-article","title":"@label(meth) Assign Article","text":"<pre><code>assignArticle(id:string, group:string):void\n</code></pre> Description Method to assign an article to a specified sub-group and removes it from its current sub-group. This method is also used when adding the article to a new sub-group. Parameters id(string): Article ID group(string): Name of the subgroup. This includes \"remove\" and \"ignore\" <p>Outdated terminology</p> <p>Parameter <code>group</code> should be termed \"sub-group\" instead.</p>"},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#labelmeth-find-article-group","title":"@label(meth) Find Article Group","text":"<pre><code>findArticleGroup(id:string): string\n</code></pre> Description Finds the name of the group that contains the article with the specified ID. Parameters id(string): Article ID Returns <code>string</code> The name of the group containing the article, or a default status if not found."},{"location":"projects/genai/health-hub/webapp/frontend/utilities/group-manager/#labelmeth-find-article-group-behavior-subject","title":"@label(meth) Find Article Group (Behavior Subject)","text":"<pre><code>findArticleGroupBehaviourSubject(id:string): BehaviorSubject&lt;string&gt;\n</code></pre> Description Retrieves a BehaviorSubject that emits the current article group and updates when the group changes. Parameters id(string): Article ID Returns <code>BehaviorSubject&lt;string&gt;</code> BehaviorSubject emitting the current article group."},{"location":"projects/genai/health-hub/webapp/misc/mocker/","title":"Mocker","text":""},{"location":"projects/genai/health-hub/webapp/misc/mocker/#overview","title":"Overview","text":"<p>Mocker is a utility module that provides functions to generate mock data for testing purposes. It is used to create dummy data that can be used to simulate real-world scenarios in the absence of actual data. The module generates random data based on predefined schemas and can be customized to suit specific testing requirements.</p>"},{"location":"projects/genai/health-hub/webapp/misc/mocker/#labelclass-mocker","title":"@label(class) Mocker","text":""},{"location":"projects/genai/health-hub/webapp/misc/mocker/#methods","title":"Methods","text":""},{"location":"projects/genai/health-hub/webapp/misc/mocker/#labelprivate-labelmeth-create-article-ids","title":"@label(private) @label(meth) Create Article IDs","text":"<pre><code>```python\ndef __create_article_ids(self) -&gt; List[str]\n```\n</code></pre> Description Generates a list of unique article IDs. Returns A list of unique article IDs."},{"location":"projects/genai/health-hub/webapp/misc/mocker/#labelprivate-labelmeth-create-date","title":"@label(private) @label(meth) Create Date","text":"<pre><code>```python\ndef _create_date(self) -&gt; str\n```\n</code></pre> Description Generates a random date. Returns A string representing a random date in the format 'YYYY-MM-DD'."},{"location":"projects/genai/health-hub/webapp/misc/mocker/#labelprivate-labelmeth-generate-article-status","title":"@label(private) @label(meth) Generate article status","text":"<pre><code>```python\n    def __generate_article_status(self, group_size: int) -&gt; List[str]\n```\n</code></pre> Description Generates a list of article statuses based on the number of articles in a group. For Groups with More Than One Article: The possible statuses for articles include <code>Combined</code>, <code>Removed</code>, <code>Ignored</code>, or <code>Optimised</code>. It is a requirement for groups of this size to have a minimum of two articles labeled as <code>Combined</code>. For Single-Article Groups: When a group consists of only one article, the article may be assigned any of the following statuses: <code>Removed</code>, <code>Ignored</code>, or <code>Optimised</code>. The <code>Combined</code> status is excluded in this scenario as it implies the presence of multiple articles. Parameters <code>group_size</code> (int): The number of articles in the group. <p>Returns: A list of article statuses for the articles in the group (str).</p>"},{"location":"projects/genai/health-hub/webapp/misc/mocker/#labelprivate-labelmeth-create-combine-article","title":"@label(private) @label(meth) Create Combine Article","text":"<pre><code>```python\n async def __create_combine_articles(\n        self, group_id: str, combine_ids: List[str]\n    ) -&gt; None\n```\n</code></pre> Description Creates a new Combine Job with articles in the same group and subgroup, and then insert into the database. This function also ensures that every subgroup created contains at least two articles."},{"location":"projects/genai/health-hub/webapp/misc/mocker/#create-article","title":"<code>Create Article</code>","text":"<pre><code>```python\n    def __create_article(self, article_id: str, status: str) -&gt; Article\n```\n</code></pre> Description Creates an <code>Article</code> with the specified ID and status. Other attributes are generated randomly or set to default values. Returns An <code>Article</code> object."},{"location":"projects/genai/health-hub/webapp/misc/mocker/#labelmeth-create-articles","title":"@label(meth) Create Articles","text":"<pre><code>```python\n    async def create_articles(self, article_ids: List[str]) -&gt; List[Article]\n```\n</code></pre> Description Creates a list of <code>Article</code> objects with the specified IDs. This function also assigns statuses from <code>__generate_article_status()</code> randomly to the articles by keeping track of which Article ID is assigned to which status. Parameters <code>article_ids</code> (List[str]): A list of article IDs. <p>Returns: A list of <code>Article</code></p>"},{"location":"projects/genai/health-hub/webapp/misc/mocker/#labelmeth-mock","title":"@label(meth) Mock","text":"<pre><code>```python\nasync def mock(self) -&gt; None:\n```\n</code></pre> Description This is the main function that generates mock data for the database by creating <code>Documents</code> and inserting them into the database. <p>Group review status</p> <p>A <code>Group</code> can either be reviewed or not reviewed. Only if a <code>Group</code> is reviewed, it will have a <code>Job</code> associated with it and all the articles in the group will have a status.</p>"},{"location":"projects/genai/health-hub/webapp/misc/populator/","title":"Populater","text":"<p>In order to populate the database with data from the pipeline, a <code>Populater</code> class is used.</p>"},{"location":"projects/genai/health-hub/webapp/misc/populator/#labelclass-populater","title":"@label(class) Populater","text":"PythonExample <pre><code>class DBPopulater:\n    def __init__(\n        self,\n        mongo_connector: DbConnector,\n        articles_file_path: str,\n        edges_file_path: str,\n        cluster_file_path: str\n    )\n</code></pre> <p>In this example, we are using <code>MongoDb</code> as the database, therefore <code>MongoConnector</code> is being passed into the <code>DBPopulater</code>. However, as long as the class being passed in implements the methods in <code>DbConnector</code> interface, then there should be no issues.</p> <pre><code># Create database connector\nconn = MongoConnector(\n    username=os.getenv(\"MONGO_USERNAME\"),\n    password=os.getenv(\"MONGO_PASSWORD\"),\n    host=os.getenv(\"MONGO_HOST\"),\n    port=os.getenv(\"MONGO_PORT\"),\n    db_name=\"storage\",\n)\n\n# Defining paths for data files\narticles_file_path = \"path/to/merged_data.parquet\"\nedges_file_path = \"path/to/edges.pkl\"\ncluster_file_path = \"path/to/cluster.pkl\"\n\n# Instantiate `DBPopulater`\npopulater = DBPopulater(\n    conn, articles_file_path, edges_file_path, cluster_file_path\n)\n\n# Run population methods\nawait db_populator.populate_articles()\nawait db_populator.populate_edges()\nawait db_populator.populate_clusters()\n</code></pre>"},{"location":"projects/genai/health-hub/webapp/misc/populator/#initialisation","title":"Initialisation","text":""},{"location":"projects/genai/health-hub/webapp/misc/populator/#labelmeth-initialise-connection","title":"@label(meth) Initialise Connection","text":"<pre><code>```python\nasync def init_db() -&gt; None\n```\n</code></pre> Description Method to initialise database connection. This method does not need to be called explicitly."},{"location":"projects/genai/health-hub/webapp/misc/populator/#seeding","title":"Seeding","text":""},{"location":"projects/genai/health-hub/webapp/misc/populator/#labelmeth-populate-articles","title":"@label(meth) Populate Articles","text":"<pre><code>```python\nasync def populate_articles() -&gt; None\n```\n</code></pre> Description Method to populate articles into the database."},{"location":"projects/genai/health-hub/webapp/misc/populator/#labelmeth-populate-edges","title":"@label(meth) Populate Edges","text":"<pre><code>```python\nasync def populate_edges() -&gt; None\n```\n</code></pre> Description Method to populate edges into the database."},{"location":"projects/genai/health-hub/webapp/misc/populator/#labelmeth-populate-groups","title":"@label(meth) Populate Groups","text":"<pre><code>```python\nasync def populate_clusters() -&gt; None\n```\n</code></pre> <p>Must be called after `DBPopulater.populate_articles()</p> <p>With the current implementation, this method must only be called after articles have been populated into the database.</p> <p>Outdated method name</p> <p>This method's name should be updated to <code>populate_groups()</code> as the terminology for \"clusters\" was shifted to \"groups\" across the project.</p> Description Method to populate groups into the database."},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/engineering/","title":"Engineering","text":""},{"location":"blog/category/guides/","title":"Guides","text":""}]}